var tipuesearch = {"pages":[{"title":"About me","text":"Hao serves as an R&D Engineer at New H3C Technologies . In early 2017, He completed EIT Digital Dual Master Degree Programme with a major of Internet Technology and Architecture at KTH Royal Institute of Technology and a specialization of Internet of Things(IoT) at IMT Atlantique . He also minored in ICT Innovation and Entrepreneurship during his Master studies. Hao is a Cisco Certificated Internetwork Expert in Routing and Switching (CCIE R&S #40343). He is passionate about future networking technologies. His interests mainly focus on Wireless and Mobile Networking , Datacenter and Cloud Networking , and Network Intelligence(Big Data, AI, etc.) . He is highly motivated by the desire to see these technologies meet together to shape a more intelligent, efficient, and reliable networked society. His curriculum vitae is available here . You can also find him on Linkedin . 现就职于 H3C 担任研发工程师。2017年初完成欧盟 EIT Digital 双硕士学位联合培养项目，分别获得 KTH瑞典皇家理工学院 的互联网技术与架构硕士学位和 IMT Atlantique法国大西洋高等矿业电信学校 的物联网硕士学位，以及ICT创新创业商科辅修证书。2016年3月至9月在 思科 巴黎创新研究院进行硕士毕业论文实习。2014年本科毕业于 浙江大学 环境与资源学院并获得农学学士学位。 思科认证互联网络专家（CCIE R&S #40343），也是未来网络技术的狂热爱好者。兴趣主要集中在无线和移动网络，数据中心和云计算网络，以及网络大数据/人工智能等领域。期待这些技术融合后构建一个更加智能、高效和可靠的互联社会。 详细简历请戳 这里 。您也可以在 领英 上找到我。","tags":"pages","url":"https://jiang-hao.com/pages/aboutme.html","loc":"https://jiang-hao.com/pages/aboutme.html"},{"title":"Self Management","text":"1. Skill Tree 2. Weekly Schedule Slot Sunday Monday Tuesday Wednesday Thursday Friday Saturday 06:00 getup getup getup getup getup getup getup 06:30 Java Java Java Java Java Java Java 07:00 Java Java Java Java Java Java Java 07:30 Java Java Java Java Java Java Java 08:00 Algorithms OTR OTR OTR OTR OTR Algorithms 08:30 Algorithms OTR OTR OTR OTR OTR Algorithms 09:00 Algorithms Algorithms 09:30 OTR 10:00 Security 10:30 Security 11:00 Security 11:30 Security 12:00 OTR OTR OTR OTR OTR OTR OTR 12:30 AI AI AI AI AI AI 13:00 AI AI AI AI AI AI 13:30 14:00 14:30 15:00 15:30 16:00 16:30 17:00 17:30 18:00 OTR OTR OTR OTR OTR OTR 18:30 Cloud Cloud Cloud Cloud OTR 19:00 Cloud Cloud Cloud Cloud Security 19:30 Cloud Cloud Cloud Cloud Security 20:00 Cloud Cloud Cloud Cloud Security 20:30 OTR OTR OTR OTR Security 21:00 Big Data Big Data Big Data Big Data OTR 21:30 Big Data Big Data Big Data Big Data 22:00 Big Data Big Data Big Data Big Data 22:30 SHW SHW SHW SHW SHW SHW SHW","tags":"pages","url":"https://jiang-hao.com/pages/management.html","loc":"https://jiang-hao.com/pages/management.html"},{"title":"Publications","text":"论文 2019 \"A JSON-Based Fast and Expressive Access Control Policy Framework\". H. Jiang and A. Bouabdallah. Advanced Data Modeling and Processing With JSON. To be published by IGI Global in 2019. 2017 \"JACPoL: A Simple but Expressive JSON-based Access Control Policy Language\". H. Jiang and A. Bouabdallah. Wistp 2017: International Conference on Information Security Theory and Practice, Springer Verlag, 28-29 September 2017. \"Towards a JSON-Based Fast Policy Evaluation Framework\". H. Jiang and A. Bouabdallah. In OTM Confederated International Conferences \"On the Move to Meaningful Internet Systems\", pp. 22-30. Springer, Cham, 2017. \"Controlled Replication for Higher Reliability and Predictability in Industrial IoT Networks\". H. Jiang , Z. Brodard, T.F. Chang, A. Bouabdallah, N. Montavont, G. Texier, P. Thubert, T. Watteyne, G. Z. Papadopoulos. In Proceedings of the 2017 International Conference on Embedded Wireless Systems and Networks (EWSN), Dependability Competition, ACM, Uppsala, Sweden, February 20-22, 2017. 2016 \"Rover: Poor (but Elegant) Man's Testbed\". Z. Brodard, H. Jiang , T.F. Chang, T. Watteyne, X. Vilajosana, P. Thubert, G. Texier. In Proceedings of the 13th ACM Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, and Ubiquitous Networks (PE-WASUN 2016). pp. 61-65. ACM. November 17, 2016. \"A Secure Multi-Tenant Framework for SDN\". H. Jiang , A. Bouabdallah, A. Aflatoonian, J. M. Bonnin, K. Guillouard. In Proceedings of the 9th International Conference on Security of Information and Networks(SIN 2016). pp. 40-44. ACM, July 20, 2016. 专利 2016 \"Timeslot Shifting for Lower-Priority Packets in a Time Slotted Network\". P. Thubert, Z. Brodard, H. Jiang . U.S.Patent 15/207,621 filed 12-Jul-2016. 标准 2016 \"A 6loRH for Bit Strings\". P. Thubert, Z. Brodard, H. Jiang , & G. Texier. IETF Internet draft. Version: draft-thubert-6lo-bier-dispatch-01. IETF 6lo WG. June 29, 2016. \"BIER-TE-based OAM, Replication & Elimination\". P. Thubert, Z. Brodard, H. Jiang . IETF Internet draft. Version: draft-thubert-bier-replication-elimination-00. IETF BIER WG. September 14, 2016. ​ 其它 2016 \"Software-defined IoT: 6TiSCH Centralized Scheduling and Multipath Construction\". H. Jiang . Internship report (Master Thesis). Cisco Paris Innovation and Research Lab, September 21, 2016. \"A Secure Multi-tenant Framework on the Northbound Side of SDN\". H. Jiang . Innovation project report. Department of Network, Security and Multimedia, Telecom Bretagne, March 07, 2016. 2014 未来互联网试验床资源管控系统的设计与实现/ Design and Implementation of Resource Management and Control System for Future Internet Testbed (in Chinese). H. Jiang . Bachelor thesis. Next Generation Network Technology Laboratory (NGNT Lab), College of Computer Science and Technology, Zhejiang University, June 10, 2014. 2013 CCIE笔记-路由交换理论和实战/ CCIE Notes - Routing and Switching (in Chinese). H. Jiang . August 27, 2013.","tags":"pages","url":"https://jiang-hao.com/pages/publications.html","loc":"https://jiang-hao.com/pages/publications.html"},{"title":"Resume","text":"Last Updated: Feb 25, 2018 Hao JIANG Research & Development Engineer, New H3C Technologies Co., Limited Email: jiang DOT haoa AT h3c DOT com Address: 466 Changhe Road, Binjiang District, 310052 Hangzhou SUMMARY A 2-year-old master graduate with double degrees in Internet Technology and Architecture & Internet of Things(IoT) from EIT Digital Program, and a minor certificate in Innovation and Entrepreneurship . Possess extensive knowledge in IoT Data Communication and Management & Datacenter and Cloud Networking technologies. Understand deeply IP network architecture, protocols, and popular techniques. Master common system programming languages, e.g., Java, Python, C/C++. EDUCATION M.Sc. in Internet of Things, IMT Atlantique, GPA: 3.85/3.9, 2015/2016 M.Sc. in Internet Technology and Architecture, KTH Royal Institute of Technology, GPA: 4.61/5.0, 2014/2015 B.Sc. in Agricultural Resources and Environment, Zhejiang University, GPA: 3.66/4.0, 2010-2014 SELECTED HONORS & AWARDS Excellence Scholarship, 1000€/month+3000€ mobility allowance, sponsored by EIT Digital, 09/2014 - 08/2016 Outstanding Collegiate Volunteer, awarded by Chinese Society for Environmental Sciences (CSES), 03/2013 National Endeavor Scholarship, 5000¥, sponsored by Ministry of Education of China, 12/2012 Excellent Student Awards, awarded by Zhejiang University, 12/2012 Outstanding Student Leader Awards, Top 6%, awarded by Zhejiang University, 10/2012 Academic Excellence Scholarship, Top 15%, sponsored by Zhejiang University, 10/2012 Outstanding Student Scholarship, sponsored by Zhejiang University, 10/2011 Scholarship for Outstanding Students, Top 1‰, sponsored by Yifeng Middle School of Jiangxi, China, 09/2007 - 06/2010 R&D EXPERIENCE R&D Engineer at New H3C Technologies Co., Limited, from 11/2017 Topic: SDN Research and Development R&D Engineer at Telecom Bretagne, 11/2016 - 08/2017 Topic: Trustful Hyper-linked Entities in Dynamic Networks Participated in the reThink project under the European Horizon 2020 Programme. Designed and developed JACPoL: a scalable, expressive but lightweight JSON-based access control policy language. Prototyped a performant policy evaluation engine associated with JACPoL adopting PEP/PDP architecture. Published 2 papers. Research Intern (Master Thesis) at Cisco Paris Innovation and Research Lab, 03/2016 - 09/2016 Topic: Software Defined Internet of Things (SDIoT) - 6TiSCH Centralized Scheduling and Multipath Construction Developed SDN-based routing and resource allocation schemes for deterministic IoT Low-power Lossy Networks (LLNs). Designed, implemented, and evaluated a multipath forwarding and control mechanism based on IPv6 over the TSCH mode of IEEE 802.15.4e (6TiSCH). Co-authored 3 papers, 2 Internet drafts at Internet Engineering Task Force (IETF), and 1 patent. Contributed actively to OpenWSN open-source projects. Independent Study at Telecom Bretagne, 11/2015 - 02/2016 Topic: A Secure Northbound Multi-tenant Framework for Software-defined Networks (SDN) Designed and implemented a novel multi-tenant framework with AAA, MySQL, and RESTful web services on top of OpenDaylight controller. Published the research and brought up a new concept of Software Defined Multi-tenant Networking (SDMTN). Research Intern (Bachelor Thesis) at Laboratory of Next Generation Network Technology (NGNT Lab), Zhejiang University, 02/2014 - 06/2014 Topic: Resource Management and Control for a Large-scale SDN Testbed Designed and implemented virtual-to-physical network mapping and resource allocation mechanisms for the data plane. Summer Intern at Institute of Agricultural Remote Sensing and Information Technology, Zhejiang University, 06/2013 - 08/2013 Topic: Greenhouse Environment Monitoring and Automatic Control Programmed on wireless sensor nodes with TinyOS/nesC. Conducted Matlab simulations for greenhouse energy-efficiency analysis. EXTRACURRICULAR ACTIVITIES Member of the Preparatory Committee of EU-China Youth Innovation & Entrepreneurship Forum 2017, 11/2016 - 06/2017 Participating actively in the design and preparation of the forum to promote cooperation and exchange between Chinese and European investors and start-up companies. Director of EIT CSSA (Chinese Students and Scholars Association) France, 10/2015 - 09/2016 Organized academic and recreational activities among EIT Digital students over European countries. Teaching Assistant at OpenLab IT Education, Inc., Hangzhou, 08/2013 - 01/2014 Offered technical courses on routing, switching, and troubleshooting technologies. Performed periodical maintenance of teaching materials and translation of technical documents. Director of General Affairs Department of Students' Union, Zhejiang University, 09/2011 - 09/2012 Organized a variety of campus and volunteer activities. Received Outstanding Student Leader Awards from Zhejiang University. English Tutor for a junior middle school student, 09/2011 - 02/2012 Student Technician of IT Support Center, Zhejiang University, 09/2010 - 06/2011 Supported students and faculty in solving computer and network problems. Figured out and solved the problem of DHCP failure once in a campus wireless network paralysis. TECHNICAL COURSE PROJECTS Multitasking and Event Scheduling on Wireless Sensor Networks , 01/2016-02/2016 UVDECX101-Distributed Architectures and Embedded Systems, Télécom Bretagne Developed smart LED lighting control using networked Contiki motes with distributed sensing and actuation. IoT Data Stream Processing and Analytics , 11/2015-12/2015 UVDECX501-Internet of Things and Intelligent Transport, Télécom Bretagne Analysed real-time data stream from campus wireless sensor network using Apache Storm. Performance Analysis of Backoff Algorithms in WiFi Networks , 01/2015-03/2015 IK2217-Advanced Internetworking II, KTH Royal Institute of Technology Evaluated and improved the backoff mechanism in CSMA wireless networks to optimize throughput performance through NS3 simulation. 5G Wireless System with Massive MIMO , 11/2014-01/2015 EP2950-Wireless Networks, KTH Royal Institute of Technology Investigated novel techniques of massive MIMO as a key enabler for 5G based on extensive literature research. Advanced ISP (Internet Service Provider) Networking , 09/2014-11/2014 IK2215-Advanced Internetworking, KTH Royal Institute of Technology Designed and implemented high availability inter/intra-domain routing functions, IP multicast, along with a suite of DNS, DHCP, Web, FTP, Mail, VPN, Firewall and IPS/IDS services. Traffic Light Control Based on PLC (Programmable Logic Controller) , 11/2012-01/2013 101C0020-Electrical and Electronic Experiment, Zhejiang University Designed and implemented a traffic light PLC program through ladder logic using LogixPro Simulator. BUSINESS COURSE PROJECTS An Assessment of the Business Opportunity in Telehealth Industry , 09/2016 Minor Thesis, EIT Digital Master Programme Investigated extensively key technologies and market environment for health monitoring wearable products. Proposed a novel business model based on open and user innovation paradigm. Intellitest - Loved by Everyone Except Cheaters , 07/2015-08/2015 ME2078-Summer School: Security & Privacy in Digital Life, University of Trento Designed a smart anti-cheating system integrating machine learning capabilities to make online exams more trustful. Received the top 3 best entrepreneurial team prize. Locate - Locate Things Easily , 04/2015-05/2015 ME2073-Business Development Lab of Entrepreneurship Engineers, KTH Designed, validated and developed a complete business plan with a focus on the value proposition and customer validation of personal Internet of Things products. GreenCoating , 10/2012-09/2013 National Student Research Training Program (SRTP), Zhejiang University Led the development of a plant-derived antibacterial coating additive based on mentor's patents, in cooperation with Hangzhou Risun Chemical Technology Co., LTD. Received sponsorship also from National College Student Entrepreneurship Training Program(SIETP). CCIE CERTIFICATION TRACKS CCIE (Cisco Certificated Internetwork Expert) Data Center Written Exam, Score: 984/1000, Stockholm 05/2015 CCIE Routing and Switching Lab Exam, PASS, License #40343, Beijing 08/2013 CCIE Routing and Switching Written Exam, Score: 972/1000, Hangzhou 03/2013 SKILLS Programming: Python, Java, C/C++, JavaScript, HTML, CSS, Shell, SQL Networking: TCP/IP, Software-defined Networking, Wireless and Mobile Networking, Multimedia Networking Tools: JetBrains IDEs, Microsoft Office, Adobe Creative Suite, MySQL Platforms: Linux, Mac OS, Windows Languages: Chinese (native), English (professional), French (elementary) VOLUNTEER EXPERIENCE Environmental Volunteer of Hangzhou scenic areas, 03/2014 Kept the scenic environment clean, and the gardens out of damage. Inspired the environmental awareness of tourists. Lead Volunteer of Public Environmental Education, Anji, Zhejiang Province, China, 07/2012 - 08/2012 Organized a set of public environmental education activities with topics on plant protection, waste classification, and energy conservation with 30 volunteers. Presented as a good example and received Outstanding Collegiate Volunteer awards in the annual conference of Chinese Society for Environmental Sciences. Teaching Volunteer in Shilian Primary School of Suichang, Zhejiang Province, China, 07/2011 – 08/2011 Served as a Chinese teacher for more than 20 pupils during the summer holiday. PUBLICATION \"JACPoL: A Simple but Expressive JSON-based Access Control Policy Language\". H. Jiang and A. Bouabdallah. Wistp 2017: International Conference on Information Security Theory and Practice, Springer Verlag, 28-29 September 2017. \"Towards a JSON-Based Fast Policy Evaluation Framework\". H. Jiang and A. Bouabdallah. In OTM Confederated International Conferences \"On the Move to Meaningful Internet Systems\", pp. 22-30. Springer, Cham, 2017. \"Controlled Replication for Higher Reliability and Predictability in Industrial IoT Networks\". H. Jiang , Z. Brodard, T.F. Chang, A. Bouabdallah, N. Montavont, G. Texier, P. Thubert, T. Watteyne, G. Z. Papadopoulos. In Proceedings of the 2017 International Conference on Embedded Wireless Systems and Networks (EWSN), Dependability Competition, ACM, Uppsala, Sweden​, February 20-22, 2017. \"Rover: Poor (but Elegant) Man's Testbed\". Z. Brodard, H. Jiang , T.F. Chang, T. Watteyne, X. Vilajosana, P. Thubert, G. Texier. In Proceedings of the 13th ACM Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, and Ubiquitous Networks (PE-WASUN 2016). pp. 61-65. ACM. November 17, 2016. \"A Secure Multi-Tenant Framework for SDN\". H. Jiang , A. Bouabdallah, A. Aflatoonian, J. M. Bonnin, K. Guillouard. In Proceedings of the 9th International Conference on Security of Information and Networks(SIN 2016). pp. 40-44. ACM, July 20, 2016. \"Timeslot Shifting for Lower-Priority Packets in a Time Slotted Network\". P. Thubert, Z. Brodard, H. Jiang . U.S.Patent 15/207,621 filed 12-Jul-2016. \"A 6loRH for Bit Strings\". P. Thubert, Z. Brodard, H. Jiang , & G. Texier. IETF Internet draft. Version: draft-thubert-6lo-bier-dispatch-01. IETF 6lo WG. June 29, 2016. \"BIER-TE-based OAM, Replication & Elimination\". P. Thubert, Z. Brodard, H. Jiang . IETF Internet draft. Version: draft-thubert-bier-replication-elimination-00. IETF BIER WG. September 14, 2016.","tags":"pages","url":"https://jiang-hao.com/pages/resume.html","loc":"https://jiang-hao.com/pages/resume.html"},{"title":"Search Results","text":"","tags":"pages","url":"https://jiang-hao.com/pages/search.html","loc":"https://jiang-hao.com/pages/search.html"},{"title":"数据结构与算法——插入排序（扑克牌排序）","text":"算法原理 插入排序的代码实现虽然没有冒泡排序和选择排序那么简单粗暴，但它的原理应该是最容易理解的了，因为只要打过扑克牌的人都应该能够秒懂。插入排序是一种最简单直观的排序算法，它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。（有点像扑克牌在手上排序的过程） 插入排序和冒泡排序一样，也有一种优化算法，叫做拆半插入。 排序步骤 将待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。） 在其实现过程使用双层循环，外层循环对除了第一个元素之外的所有元素，内层循环对当前元素前面有序表进行待插入位置查找，并进行移动。 动图演示 代码实现 public static int [] insert_sort_original ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int valuationCnt = 0 ; // 赋值操作计数 int comparisonCnt = 0 ; // 比较操作计数 for ( int i = 1 ; i < nums . length ; i ++ ) { int target = arr [ i ] ; int j ; for ( j = i ; j > 0 && target < arr [ j - 1 ] ; j -- ) { valuationCnt ++ ; comparisonCnt ++ ; arr [ j ] = arr [ j - 1 ] ; } arr [ j ] = target ; } System . out . println ( comparisonCnt + \",\" + valuationCnt ); return arr ; } 复杂度分析 时间复杂度 在插入排序中，当待排序数组是有序时，是最优的情况，只需当前数跟前一个数比较一下就可以了，这时一共需要比较N- 1次，时间复杂度为O(N)。 最坏的情况是待排序数组是逆序的，此时需要比较次数最多，总次数记为：1+2+3+…+N-1，所以，插入排序最坏情况下的时间复杂度为O(N&#94;2)。 空间复杂度 插入排序的空间复杂度为常数阶O(1)。 总结 平均时间复杂度 最坏时间复杂度 最优时间复杂度 空间复杂度 稳定性 稳定 算法优化 折半插入（二分查找） 二分查找插入排序的原理：是直接插入排序的一个变种，区别是：在有序区中查找新元素插入位置时，为了减少元素比较次数提高效率，采用二分查找算法进行插入位置的确定。 public static int [] insert_sort_binary_search ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int valuationCnt = 0 ; int comparisonCnt = 0 ; for ( int i = 1 ; i < nums . length ; i ++ ) { int target = arr [ i ] ; int left = 0 ; int right = i ; while ( left < right ) { comparisonCnt ++ ; int middle = left + ( right - left ) / 2 ; if ( arr [ middle ] > target ) { right = middle ; } else { left = middle + 1 ; } } int j ; for ( j = i ; j > left ; j -- ) { valuationCnt ++ ; arr [ j ] = arr [ j - 1 ] ; } arr [ j ] = target ; } System . out . println ( comparisonCnt + \",\" + valuationCnt ); return arr ; } 优化结果 运行直接插入排序代码和二分插入排序代码，使用数据集https://leetcode-cn.com/submissions/detail/114474973/testcase/测试运行，得结果如下： 622443661 , 622443661 // 直接插入排序 711424 , 622443661 // 二分插入排序 可见二分插入排序大大降低了元素的比较次数，其时间复杂度如下： 最好情况 ：查找的位置是有序区的最后一位后面一位，则无须进行后移赋值操作，其比较次数为：log2n 。即O(log2N)。 最坏情况 ：查找的位置是有序区的第一个位置，则需要的比较次数为：log2n，需要的赋值操作次数为n(n-1)/2加上 (n-1) 次。即O(N&#94;2)。 平均时间复杂度 ：O(N&#94;2)。 从实现原理可知，二分查找插入排序是在原输入数组上进行后移赋值操作的（称\"就地排序\"），所需开辟的辅助空间跟输入数组规模无关，所以 空间复杂度 为：O(1)。","tags":"Algorithms","url":"https://jiang-hao.com/articles/2020/algorithms-algorithms-insert-sort.html","loc":"https://jiang-hao.com/articles/2020/algorithms-algorithms-insert-sort.html"},{"title":"数据结构与算法——选择排序","text":"排序思想 首先，找到数组中最小的那个元素，其次，将它和数组的第一个元素交换位置(如果第一个元素就是最小元素那么它就和自己交换)。其次，在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置。如此往复，直到将整个数组排序。这种方法我们称之为 选择排序 。选择排序是一种简单直观的排序算法，无论什么数据进去都是 O(n²) 的时间复杂度。所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。 那如何选出最小的一个元素呢？ 很容易想到：先随便选一个元素假设它为最小的元素（默认为无序区间第一个元素），然后让这个元素与无序区间中的每一个元素进行比较，如果遇到比自己小的元素，那更新最小值下标，直到把无序区间遍历完，那最后的最小值就是这个无序区间的最小值。 算法性能 选择排序是不稳定的排序方法。 时间复杂度 选择排序的交换操作介于 0 和 (n - 1)次之间。选择排序的比较操作为 n(n - 1)/2 次。选择排序的赋值操作介于 0 和 3(n - 1) 次之间，1次交换对应三次赋值。 比较次数O(n&#94;2) ，比较次数与关键字的初始状态无关，总的比较次数N=(n-1) + (n-2) + ... +1 = n*(n-1)/2。 交换次数比 冒泡排序 少多了，由于交换所需CPU时间比比较所需的CPU时间多，n值较小时，选择排序比冒泡排序快。选择排序每交换一对元素，它们当中至少有一个将被移到其最终位置上，因此对n个元素的表进行排序总共进行至多(n-1)次交换。在所有的完全依靠交换去移动元素的排序方法中，选择排序属于非常好的一种。 最好时间复杂度：最好情况是输入序列已经升序排列，需要比较n (n-1)/2次，但不需要交换元素，即交换次数为：0；所以 最好时间复杂度 *为О(n²)。 最坏时间复杂度：最坏情况是输入序列是逆序的，则每一趟都需要交换。即需要比较n (n-1)/2次，元素交换次数为：n-1次。所以 最坏时间复杂度 还是 О(n²)。 平均时间复杂度：О(n²) 空间复杂度：只用到一个临时变量，所以 空间复杂度 为 O(1) ； 原地操作几乎是选择排序的唯一优点，当空间复杂度要求较高时，可以考虑选择排序；选择排序实际适用的场合非常罕见。 稳定性 选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果一个元素比当前元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中两个5的相对前后顺序就被破坏了，所以选择排序是一个不稳定的排序算法。 代码实现 单向选择 单向选择的排序算法也就是最传统简单的选择排序。其Java实现如下： public static int [] selection_sort_original ( int [] nums ) { // 关键性能指标计数 int loopCnt = 0 , compareCnt = 0 , swapCnt = 0 ; int [] arr = Arrays . copyOf ( nums , nums . length ); // 总共要经过 N-1 轮比较 for ( int i = 0 ; i < arr . length - 1 ; i ++ ) { loopCnt ++ ; int minIndex = i ; // 每轮需要比较的次数 N-i for ( int j = i + 1 ; j < arr . length ; j ++ ) { compareCnt ++ ; if ( arr [ j ]< arr [ minIndex ] ) { // 遍历找出每轮剩下元素中最小元素的下标 minIndex = j ; } } // 将找到的最小值和i位置所在的值进行交换 if ( minIndex != i ) { swapCnt ++ ; int tmp = arr [ i ] ; arr [ i ] = arr [ minIndex ] ; arr [ minIndex ] = tmp ; } } System . out . println ( loopCnt + \",\" + compareCnt + \",\" + swapCnt ); return arr ; } 双向选择 单向选择方案中的主要思路是，每次遍历剩余元素，找出其中最小值，只排定最小值。对于此，有人提出了一种优化方法，即每次遍历剩余元素的时候，找出其中最小值和最大值，并排定最小值和最大值，把最大的放到最右边（降序相反），把最小的放到最左边（降序相反）。这样遍历的次数会减少一半。 public static int [] selection_sort_bidirectional ( int [] nums ) { // 关键性能指标计数 int loopCnt = 0 , compareCnt = 0 , swapCnt = 0 ; int [] arr = Arrays . copyOf ( nums , nums . length ); int minIndex , maxIndex , tmp ; for ( int left = 0 , right = arr . length - 1 ; left < right ; left ++ , right -- ) { minIndex = left ; maxIndex = right ; loopCnt ++ ; for ( int i = left ; i <= right ; i ++ ) { compareCnt += 2 ; if ( arr [ minIndex ] > arr [ i ] ) minIndex = i ; if ( arr [ maxIndex ] < arr [ i ] ) maxIndex = i ; } // 将最小值交换到 left 的位置 if ( minIndex != left ) { swapCnt ++ ; tmp = arr [ left ] ; arr [ left ] = arr [ minIndex ] ; arr [ minIndex ] = tmp ; } //此处是先排最小值的位置，所以得考虑最大值（arr[max]）在最小位置（left）的情况。 if ( left == maxIndex ) maxIndex = minIndex ; // 将最大值交换到 right 的位置 if ( maxIndex != right ) { swapCnt ++ ; tmp = arr [ right ] ; arr [ right ] = arr [ maxIndex ] ; arr [ maxIndex ] = tmp ; } } System . out . println ( loopCnt + \",\" + compareCnt + \",\" + swapCnt ); return arr ; } 运行结果 使用数据集https://leetcode-cn.com/submissions/detail/114474973/testcase/测试运行，得结果如下： 49999 , 1249975000 , 49983 //单向选择 25000 , 1250050000 , 49987 //双向选择 由结果可知，两种方式除外层循环次数双向比单向少一半之外，在关键性能指标（比较次数和交换次数）上并无差异。因此，对于许多人所提出的双向选择的排序方式，只能算是选择排序的一个变种，并无实质上的优化。","tags":"Algorithms","url":"https://jiang-hao.com/articles/2020/algorithms-algorithms-selection-sort.html","loc":"https://jiang-hao.com/articles/2020/algorithms-algorithms-selection-sort.html"},{"title":"数据结构与算法——冒泡排序","text":"定义 冒泡排序（Bubble Sort），是一种 计算机科学 领域的较简单的 排序算法 。它重复地走访过要排序的元素列，依次比较两个相邻的元素，如果顺序（如从大到小、首字母从Z到A）错误就把他们交换过来。走访元素的工作是重复地进行直到没有相邻元素需要交换，也就是说该元素列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢\"浮\"到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名\"冒泡排序\"。 算法原理 冒泡 排序算法 的原理如下： 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素做同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 算法复杂度是 O(n&#94;2)，空间复杂度是常数 O(1)。但可以记录一个不需要交换的位置，把最好情况的时间复杂度降到 O(n)。详细可以参考下文优化部分的实现。 算法实现 public static int [] bubble_sort_original ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int count = 0 , swap_count = 0 ; for ( int i = 0 ; i < arr . length - 1 ; i ++ ) { for ( int j = 0 ; j < arr . length - 1 - i ; j ++ ) { count ++ ; if ( arr [ j ] > arr [ j + 1 ] ) { int tmp = arr [ j ] ; arr [ j ] = arr [ j + 1 ] ; arr [ j + 1 ] = tmp ; swap_count ++ ; } } } System . out . println ( \"bubble_sort_original: run \" + count + \", swap \" + swap_count + \", isSorted: \" + isSorted ( arr )); //打印运行次数、交换次数，以及排序检验 return arr ; } 助记码 i ∈ [ 0 , N - 1 ) //循环N-1遍 j ∈ [ 0 , N - 1 - i ) //每遍循环要处理的无序部分 swap ( j , j + 1 ) //两两排序（升序/降序） 算法优化 优化1：一轮遍历未发生交换可提前结束 数据的顺序排好之后，冒泡算法仍然会继续进行下一轮的比较，直到arr.length-1次，后面的比较没有意义的。 设置标志位flag，如果发生了交换flag设置为true；如果没有交换就设置为false。 这样当一轮比较结束后如果flag仍为false，即：这一轮没有发生交换，说明数据的顺序已经排好，没有必要继续进行下去。 public static int [] bubble_sort_quit_if_sorted ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int tmp ; int count = 0 , swap_count = 0 ; for ( int i = 0 ; i < arr . length - 1 ; i ++ ) { boolean head_sorted = true ; for ( int j = 0 ; j < arr . length - 1 - i ; j ++ ) { count ++ ; if ( arr [ j ] > arr [ j + 1 ] ) { tmp = arr [ j ] ; arr [ j ] = arr [ j + 1 ] ; arr [ j + 1 ] = tmp ; head_sorted = false ; swap_count ++ ; } } if ( head_sorted ) break ; } System . out . println ( \"bubble_sort_quit_if_sorted: run \" + count + \", swap \" + swap_count + \", isSorted: \" + isSorted ( arr )); return arr ; } 优化2：记录上一轮最后一次交换的位置 在传统的实现中有序区的长度和排序的轮数是相等的。比如第一轮排序过后的有序区长度是1，第二轮排序过后的有序区长度是2 ......实际上，数列真正的有序区可能会大于这个长度，比如有可能在第二轮，后面5个元素实际都已经属于有序区。因此后面的许多次元素比较是没有意义的。 我们可以在每一轮排序的最后，记录下最后一次元素交换的位置，那个位置也就是无序数列的边界，再往后就是有序区了。 public static int [] bubble_sort_mark_last_swap ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int count = 0 , swap_count = 0 ; int sorted_border = arr . length ; int tmp ; while ( sorted_border > 1 ) { int last_swap = 0 ; for ( int i = 0 ; i < sorted_border - 1 ; i ++ ) { count ++ ; if ( arr [ i ] > arr [ i + 1 ] ) { tmp = arr [ i ] ; arr [ i ] = arr [ i + 1 ] ; arr [ i + 1 ] = tmp ; last_swap = i + 1 ; swap_count ++ ; } } sorted_border = last_swap ; } System . out . println ( \"bubble_sort_mark_last_swap: run \" + count + \", swap \" + swap_count + \", isSorted: \" + isSorted ( arr )); return arr ; } 上述代码中维护了一个已排好序的序列： [sorted_border,N) （N是数组大小），每次冒泡会记录最大的那个泡泡的位置作为 sorted_border 。 直到 sorted_border == 1 时，说明整个序列已经排好。 因为冒泡排序中每次冒泡都相当于选最大值放到序列结尾，所以 [sorted_border,N) 不仅是有序的，而且位置是正确的。 所以 sorted_border == 1 时， [1,N) 已经获得了正确的位置，那么元素0的位置自然就确定了（它已经没得选了）。 优化3：鸡尾酒排序(双向冒泡排序) 鸡尾酒排序也就是\"定向冒泡排序\"、\"双向冒泡排序\"和\"改进冒泡排序\", 鸡尾酒搅拌排序, 搅拌排序 (也可以视作选择排序的一种变形), 涟漪排序, 来回排序 or 快乐小时排序, 是冒泡排序的一种变形。此算法与冒泡排序的不同处在于排序时是以双向在序列中进行排序。算法先找到最小的数字，把他放到第一位，然后找到最大的数字放到最后一位。然后再找到第二小的数字放到第二位，再找到第二大的数字放到倒数第二位。以此类推，直到完成排序。 （1）时间复杂度 ：鸡尾酒排序的效率还是很低的，两层循环，时间复杂度为 O(n&#94;2) 。 （2）空间复杂度 ：由于只需要几个临时变量，所以空间复杂度为 O(1) 。 那么何以见得鸡尾酒排序比冒泡排序好一点呢？ 考虑这样的一个序列：(2,3,4,5,1) 。如果使用鸡尾酒排序，一个来回就可以搞定；而冒泡排序则需要跑四趟。 其 根本原因 在于冒泡是单向的，如果从左向右冒泡，对于小数靠后就会很不利（一趟只能挪一个位置，那就需要多次循环。这种数又被称之为乌龟）；相应的，如果从右向左冒泡，对于大数靠前又会很不利（靠前的一只大乌龟）。鸡尾酒排序的优点就在于这里，由于在序列中左右摇摆（为此鸡尾酒排序又称之为 shaker sort），两种较差的局面就能得到规避，以此在性能上带来一些提升。 public static int [] cocktail_sort_original ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int i , tmp , left = 0 , right = arr . length - 1 ; int count = 0 , swap_count = 0 ; while ( left < right ) { for ( i = left ; i < right ; i ++ ) { count ++ ; if ( arr [ i ] > arr [ i + 1 ] ) { tmp = arr [ i ] ; arr [ i ] = arr [ i + 1 ] ; arr [ i + 1 ] = tmp ; swap_count ++ ; } } right -- ; for ( i = right ; i > left ; i -- ) { count ++ ; if ( arr [ i - 1 ] > arr [ i ] ) { tmp = arr [ i ] ; arr [ i ] = arr [ i - 1 ] ; arr [ i - 1 ] = tmp ; swap_count ++ ; } } left ++ ; } System . out . println ( \"cocktail_sort_original: run \" + count + \", swap \" + swap_count + \", isSorted: \" + isSorted ( arr )); return arr ; } 对于鸡尾酒排序，算法的时间复杂度与空间复杂度并没有改进。 不同的是排序的交换次数。某些情况下鸡尾酒排序比普通冒泡排序的交换次数少。总体上，鸡尾酒排序可以获得比冒泡排序稍好的性能。但是完全逆序时，鸡尾酒排序与冒泡排序的效率都非常差。 优化4：一轮遍历未发生交换可提前结束的双向冒泡排序 public static int [] cocktail_sort_quit_if_sorted ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int i , tmp , left = 0 , right = arr . length - 1 ; int count = 0 , swap_count = 0 ; while ( left < right ) { boolean middle_sorted = true ; for ( i = left ; i < right ; i ++ ) { count ++ ; if ( arr [ i ] > arr [ i + 1 ] ) { tmp = arr [ i ] ; arr [ i ] = arr [ i + 1 ] ; arr [ i + 1 ] = tmp ; middle_sorted = false ; swap_count ++ ; } } if ( middle_sorted ) break ; right -- ; for ( i = right ; i > left ; i -- ) { count ++ ; if ( arr [ i - 1 ] > arr [ i ] ) { tmp = arr [ i ] ; arr [ i ] = arr [ i - 1 ] ; arr [ i - 1 ] = tmp ; swap_count ++ ; } } left ++ ; } System . out . println ( \"cocktail_sort_quit_if_sorted: run \" + count + \", swap \" + swap_count + \", isSorted: \" + isSorted ( arr )); return arr ; } 优化5：记录上一轮最后一次交换的位置的双向冒泡排序 public static int [] cocktail_sort_mark_last_swap ( int [] nums ) { int [] arr = Arrays . copyOf ( nums , nums . length ); int i , tmp , left = 0 , right = arr . length - 1 ; int count = 0 , swap_count = 0 , last_swap = left ; while ( left < right ) { for ( i = left ; i < right ; i ++ ) { count ++ ; if ( arr [ i ] > arr [ i + 1 ] ) { tmp = arr [ i ] ; arr [ i ] = arr [ i + 1 ] ; arr [ i + 1 ] = tmp ; last_swap = i + 1 ; swap_count ++ ; } } right = last_swap ; for ( i = right ; i > left ; i -- ) { count ++ ; if ( arr [ i - 1 ] > arr [ i ] ) { tmp = arr [ i ] ; arr [ i ] = arr [ i - 1 ] ; arr [ i - 1 ] = tmp ; last_swap = i - 1 ; swap_count ++ ; } } left = last_swap ; } System . out . println ( \"cocktail_sort_mark_last_swap: run \" + count + \", swap \" + swap_count + \", isSorted: \" + isSorted ( arr )); return arr ; } 两个方向都同时跳着走，是目前可以想到的效果最好的优化。 优化性能测试 通过运行力扣测试数据集https://leetcode-cn.com/submissions/detail/114474973/testcase/，得到各个变形的结果如下： bubble_sort_original: run 1249975000 , swap 622443661 , isSorted : true bubble_sort_quit_if_sorted: run 1249928029 , swap 622443661 , isSorted : true bubble_sort_mark_last_swap: run 1249543883 , swap 622443661 , isSorted : true cocktail_sort_original: run 1249975000 , swap 622443661 , isSorted : true cocktail_sort_quit_if_sorted: run 934706395 , swap 622443661 , isSorted : true cocktail_sort_mark_last_swap: run 828009788 , swap 622443661 , isSorted : true 优化5所进行的运算量最少。大多数运算都有效进行了元素交换（排序），而排除了大量无效的循环比较。","tags":"Algorithms","url":"https://jiang-hao.com/articles/2020/algorithms-algorithms-bubble-sort.html","loc":"https://jiang-hao.com/articles/2020/algorithms-algorithms-bubble-sort.html"},{"title":"数据结构与算法——链表","text":"定义 相比数组，链表是一种稍微复杂一点的数据结构。对于两者，我们常常将会放到一块儿来比较。 从图中我们看到，数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。 而链表恰恰相反，它并不需要一块连续的内存空间，它通过\"指针\"将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。 链表结构五花八门，主要有三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。我们首先来看最简单、最常用的单链表。 单向链表 我们刚刚讲到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的\"结点\"。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作后继指针 next。 其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。 与数组一样，链表也支持数据的查找、插入和删除操作。 我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。 针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。 但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。 你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。 循环链表 循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作\"循环\"链表。 和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的 约瑟夫问题 。尽管用单链表也可以实现，但是用循环链表实现的话，代码就会简洁很多。 双向链表 单链表和循环链表是不是都不难？接下来我们再来看一个稍微复杂的，在实际的软件开发中，也更加常用的链表结构：双向链表。 单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。 双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。那相比单链表，双向链表适合解决哪种问题呢？ 从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。 你可能会说，我刚讲到单链表的插入、删除操作的时间复杂度已经是 O(1) 了，双向链表还能再怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法书籍中都会这么讲，但是这种说法实际上是不准确的，或者说是有先决条件的。 我们先来看删除操作。 在实际的软件开发中，从链表中删除一个数据无外乎这两种情况： 删除结点中\"值等于某个给定值\"的结点； 删除给定指针指向的结点。 对于第一种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过前面讲的指针操作将其删除。 尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。 对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。 但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！ 同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 现在，你有没有觉得双向链表要比单链表更加高效呢？这就是为什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉 Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。 实际上，这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。 缓存实际上就是利用了空间换时间的设计思想。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。 所以总结一下，对于执行较慢的程序，可以通过消耗更多的内存（空间换时间）来进行优化；而消耗过多内存的程序，可以通过消耗更多的时间（时间换空间）来降低内存的消耗。 双向循环链表 了解了循环链表和双向链表，如果把这两种链表整合在一起就是一个新的版本：双向循环链表。 链表VS数组 通过前面内容的学习，你应该已经知道，数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。 不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，也就是CPU缓存存在的意义:为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。 比如为了充分利用CPU的高速缓存的高速访问，Java的开源项目 Disruptor （Disruptor 可谓是将硬件用到了极致，线程和CPU 核心之间的亲和性都考虑到了）就是通过缓存行填充这个策略来保持数据保持在CPU的高速缓存中。得益于CPU缓存从内存中加载数据是按块加载（也可以说一整个缓存行，看操作系统位数决定），数组的连续地址空间会一并加载到CPU的高速缓存中，访问速度和内存不是一个量级。 对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到CPU缓存这样执行速度会快于存储空间不连续的链表存储。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致\"内存不足（out of memory）\"。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组 最大的区别 。 你可能会说，我们 Java 中的 ArrayList 容器，也可以支持动态扩容啊？我们上一节课讲过，当我们往支持动态扩容的数组中插入一个数据时，如果数组中没有空闲空间了，就会申请一个更大的空间，将数据拷贝过去，而数据拷贝的操作是非常耗时的。 举一个稍微极端的例子。如果我们用 ArrayList 存储了了 1GB 大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList 会申请一个 1.5GB 大小的存储空间，并且把原来那 1GB 的数据拷贝到新申请的空间上。听起来是不是就很耗时？ 除此之外，如果代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 所以，在我们实际的开发中，针对不同类型的项目，要根据具体情况，权衡究竟是选择数组还是链表。 基于链表实现 LRU 缓存淘汰算法 缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。 缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。 如何基于链表实现 LRU 缓存淘汰算法？思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此结点直接插入到链表的头部； 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。 这样我们就用链表实现了一个 LRU 缓存。 现在我们来看下缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。 实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。 单链表的回文字符串判断 如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的题目就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？你有什么好的解决思路呢？相应的时间空间复杂度又是多少呢？ 我们可以使用快慢两个指针找到链表中点，慢指针每次前进一步，快指针每次前进两步。在慢指针前进的过程中，同时修改其 next 指针，使得链表前半部分反序。最后比较中点两侧的链表是否相等。 /** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode(int x) { val = x; } * } */ class Solution { public boolean isPalindrome ( ListNode head ) { if ( head == null || head . next == null ) { return true ; } ListNode prev = null ; ListNode slow = head ; ListNode fast = head ; while ( fast != null && fast . next != null ) { fast = fast . next . next ; ListNode next = slow . next ; slow . next = prev ; prev = slow ; slow = next ; } if ( fast != null ) { slow = slow . next ; } while ( slow != null ) { if ( slow . val != prev . val ) { return false ; } slow = slow . next ; prev = prev . next ; } return true ; } } 时间复杂度：O(n) 空间复杂度：O(1) 关于空间复杂度是O(1)而不是O(n)的说明：要看为解决问题而开支的额外的内存消耗，不是看链表本身存储需要多少空间。 链表配合栈也可以完成，不过空间复杂度就O(n)了。 如何写好链表代码 想要写好链表代码并不是容易的事儿，尤其是那些复杂的链表操作，比如链表反转、有序链表合并等，写的时候非常容易出错。一般情况下，往往能把\"链表反转\"这几行代码写对的人不足 10%。 为什么链表代码这么难写？究竟怎样才能比较轻松地写出正确的链表代码呢？ 只要愿意投入时间，大多数人都是可以学会的。比如说，如果你真的能花上一个周末或者一整天的时间，就去写链表反转这一个代码，多写几遍，一直练到能毫不费力地写出 Bug free 的代码。这个坎还会很难跨吗？ 当然，自己有决心并且付出精力是成功的先决条件，除此之外，我们还需要一些方法和技巧。下面总结了几个写链表代码技巧。如果你能熟练掌握这几个技巧，加上你的主动和坚持，轻松拿下链表代码完全没有问题。 技巧一：理解指针或引用的含义 事实上，看懂链表的结构并不是很难，但是一旦把它和指针混在一起，就很容易让人摸不着头脑。所以，要想写对链表代码，首先就要理解好指针。我们知道，有些语言有\"指针\"的概念，比如 C 语言；有些语言没有指针，取而代之的是\"引用\"，比如 Java、Python。不管是\"指针\"还是\"引用\"，实际上，它们的意思都是一样的，都是存储所指对象的内存地址。接下来，我会拿 C 语言中的\"指针\"来讲解，如果你用的是 Java 或者其他没有指针的语言也没关系，你把它理解成\"引用\"就可以了。实际上，对于指针的理解，你只需要记住下面这句话就可以了： 将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。 这句话听起来还挺拗口的，你可以先记住。我们回到链表代码的编写过程中，我来慢慢给你解释。在编写链表代码的时候，我们经常会有这样的代码：p->next=q。这行代码是说，p 结点中的 next 指针存储了 q 结点的内存地址。还有一个更复杂的，也是我们写链表代码经常会用到的：p->next=p->next->next。这行代码表示，p 结点的 next 指针存储了 p 结点的下下一个结点的内存地址。 掌握了指针或引用的概念，你应该可以很轻松地看懂链表代码。 技巧二：警惕指针丢失和内存泄漏 不知道你有没有这样的感觉，写链表代码的时候，指针指来指去，一会儿就不知道指到哪里了。所以，我们在写的时候，一定注意不要弄丢了指针。 指针往往都是怎么弄丢的呢？我们拿上图表中的单链表的插入操作为例来分析一下。 假设我们希望在结点 a 和相邻的结点 b 之间插入结点 x，假设当前指针 p 指向结点 a。如果我们将代码实现变成下面这个样子，就会发生指针丢失和内存泄露。 p -> next = x ; // 将p的next指针指向x结点； x -> next = p -> next ; // 将x的结点的next指针指向b结点； 初学者经常会在这儿犯错。p->next 指针在完成第一步操作之后，已经不再指向结点 b 了，而是指向结点 x。第 2 行代码相当于将 x 赋值给 x->next，自己指向自己。因此，整个链表也就断成了两半，从结点 b 往后的所有结点都无法访问到了。 对于有些语言来说，比如 C 语言，内存管理是由程序员负责的，如果没有手动释放结点对应的内存空间，就会产生内存泄露。所以，我们插入结点时，一定要注意操作的顺序，要先将结点 x 的 next 指针指向结点 b，再把结点 a 的 next 指针指向结点 x，这样才不会丢失指针，导致内存泄漏。所以，对于刚刚的插入代码，我们只需要把第 1 行和第 2 行代码的顺序颠倒一下就可以了。 同理，删除链表结点时，也一定要记得手动释放内存空间，否则，也会出现内存泄漏的问题。当然，对于像 Java 这种虚拟机自动管理内存的编程语言来说，就不需要考虑这么多了。 技巧三：利用哨兵简化实现难度 首先，我们先来回顾一下单链表的插入和删除操作。如果我们在结点 p 后面插入一个新的结点，只需要下面两行代码就可以搞定。 new_node -> next = p -> next ; p -> next = new_node ; 但是，当我们要向一个空链表中插入第一个结点，刚刚的逻辑就不能用了。我们需要进行下面这样的特殊处理，其中 head 表示链表的头结点。所以，从这段代码，我们可以发现，对于单链表的插入操作，第一个结点和其他结点的插入逻辑是不一样的。 if ( head == null ) { head = new_node ; } 我们再来看单链表结点删除操作。如果要删除结点 p 的后继结点，我们只需要一行代码就可以搞定。 p -> next = p -> next -> next ; 但是，如果我们要删除链表中的最后一个结点，前面的删除代码就不 work 了。跟插入类似，我们也需要对于这种情况特殊处理。写成代码是这样子的： if ( head -> next == null ) { head = null ; } 从前面的一步一步分析，我们可以看出，针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。这样代码实现起来就会很繁琐，不简洁，而且也容易因为考虑不全而出错。如何来解决这个问题呢？ 哨兵就要登场了。哨兵，解决的是国家之间的边界问题。同理，这里说的哨兵也是解决\"边界问题\"的，不直接参与业务逻辑。 还记得如何表示一个空链表吗？head=null 表示链表中没有结点了。其中 head 表示头结点指针，指向链表中的第一个结点。 如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。 如下图画了一个带头链表，你可以发现，哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。 实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、归并排序、动态规划等。这些内容我们后面才会讲，现在为了让你感受更深，我再举一个非常简单的例子。代码我是用 C 语言实现的，不涉及语言方面的高级语法，很容易看懂，你可以类比到你熟悉的语言。 代码一： // 在数组a中，查找key，返回key所在的位置 // 其中，n表示数组a的长度 int find ( char * a , int n , char key ) { // 边界条件处理，如果a为空，或者n<=0，说明数组中没有数据，就不用while循环比较了 if ( a == null || n <= 0 ) { return - 1 ; } int i = 0 ; // 这里有两个比较操作：i<n和a[i]==key. while ( i < n ) { if ( a [ i ] == key ) { return i ; } ++ i ; } return - 1 ; } 代码二： // 在数组a中，查找key，返回key所在的位置 // 其中，n表示数组a的长度 // 我举2个例子，你可以拿例子走一下代码 // a = {4, 2, 3, 5, 9, 6} n=6 key = 7 // a = {4, 2, 3, 5, 9, 6} n=6 key = 6 int find ( char * a , int n , char key ) { if ( a == null || n <= 0 ) { return - 1 ; } // 这里因为要将a[n-1]的值替换成key，所以要特殊处理这个值 if ( a [ n - 1 ] == key ) { return n - 1 ; } // 把a[n-1]的值临时保存在变量tmp中，以便之后恢复。tmp=6。 // 之所以这样做的目的是：希望find()代码不要改变a数组中的内容 char tmp = a [ n - 1 ]; // 把key的值放到a[n-1]中，此时a = {4, 2, 3, 5, 9, 7} a [ n - 1 ] = key ; int i = 0 ; // while 循环比起代码一，少了i<n这个比较操作 while ( a [ i ] != key ) { ++ i ; } // 恢复a[n-1]原来的值,此时a= {4, 2, 3, 5, 9, 6} a [ n - 1 ] = tmp ; if ( i == n - 1 ) { // 如果i == n-1说明，在0...n-2之间都没有key，所以返回-1 return - 1 ; } else { // 否则，返回i，就是等于key值的元素的下标 return i ; } } 对比两段代码，在字符串 a 很长的时候，比如几万、几十万，你觉得哪段代码运行得更快点呢？答案是代码二，因为两段代码中执行次数最多就是 while 循环那一部分。第二段代码中，我们通过一个哨兵 a[n-1] = key，成功省掉了一个比较语句 i<n，不要小看这一条语句，当累积执行万次、几十万次时，累积的时间就很明显了。 当然，这只是为了举例说明哨兵的作用，你写代码的时候千万不要写第二段那样的代码，因为可读性太差了。大部分情况下，我们并不需要如此追求极致的性能。 哨兵可以理解为它可以减少特殊情况的判断，比如判空，比如判越界，比如减少链表插入删除中对空链表的判断，比如例子中对i越界的判断。 空与越界可以认为是小概率情况，所以代码每一次操作都走一遍判断，在大部分情况下都会是多余的。 哨兵的巧妙就是提前将这种情况去除，比如给一个哨兵结点，以及将key赋值给数组末元素，让数组遍历不用判断越界也可以因为相等停下来。 使用哨兵的指导思想应该是将小概率需要的判断先提前扼杀，比如提前给他一个值让他不为null，或者提前预设值，或者多态的时候提前给个空实现，然后在每一次操作中不必再判断以增加效率。 技巧四：重点留意边界条件处理 软件开发中，代码在一些边界或者异常情况下，最容易产生 Bug。链表代码也不例外。要实现没有 Bug 的链表代码，一定要在编写的过程中以及编写完成之后，检查边界条件是否考虑全面，以及代码在边界条件下是否能正确运行。 经常用来检查链表代码是否正确的边界条件有这样几个： 如果链表为空时，代码是否能正常工作？ 如果链表只包含一个结点时，代码是否能正常工作？ 如果链表只包含两个结点时，代码是否能正常工作？ 代码逻辑在处理头结点和尾结点的时候，是否能正常工作？ 当你写完链表代码之后，除了看下你写的代码在正常的情况下能否工作，还要看下在上面我列举的几个边界条件下，代码仍然能否正确工作。如果这些边界条件下都没有问题，那基本上可以认为没有问题了。 当然，边界条件不止我列举的那些。针对不同的场景，可能还有特定的边界条件，这个需要你自己去思考，不过套路都是一样的。 实际上，不光光是写链表代码，你在写任何代码时，也千万不要只是实现业务正常情况下的功能就好了，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮！ 技巧五：举例画图，辅助思考 对于稍微复杂的链表操作，比如前面我们提到的单链表反转，指针一会儿指这，一会儿指那，一会儿就被绕晕了。总感觉脑容量不够，想不清楚。所以这个时候就要使用大招了，举例法和画图法。 你可以找一个具体的例子，把它画在纸上，释放一些脑容量，留更多的给逻辑思考，这样就会感觉到思路清晰很多。 技巧六：多写多练，没有捷径 如果你已经理解并掌握了我前面所讲的方法，但是手写链表代码还是会出现各种各样的错误，也不要着急。把常见的链表操作都自己多写几遍，出问题就一点一点调试，熟能生巧！下面精选了 5 个常见的链表操作。你只要把这几个操作都能写熟练，不熟就多写几遍，我保证你之后再也不会害怕写链表代码。 单链表反转 链表中环的检测 两个有序的链表合并 删除链表倒数第 n 个结点 求链表的中间结点 写链表代码是最考验逻辑思维能力的。因为，链表代码到处都是指针的操作、边界条件的处理，稍有不慎就容易产生 Bug。链表代码写得好坏，可以看出一个人写代码是否够细心，考虑问题是否全面，思维是否缜密。所以，这也是很多面试官喜欢让人手写链表代码的原因。 链表相关练习题LeetCode对应编号：206，141，21，19，876。可以多多练习！","tags":"Algorithms","url":"https://jiang-hao.com/articles/2020/algorithms-data-struct-linkedlist.html","loc":"https://jiang-hao.com/articles/2020/algorithms-data-struct-linkedlist.html"},{"title":"数据结构与算法——数组","text":"定义 数组（Array）是一种 线性表 数据结构。它用一组 连续的内存空间 ，来存储一组具有 相同类型 的数据。 这个定义里有几个关键词，理解了这几个关键词，我想你就能彻底掌握数组的概念了。 首先是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。 而与它相对立的概念是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。 第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称\"杀手锏\"的特性：\"随机访问\"。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。 随机访问 我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10]来举例。在下面这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。 我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址： $$ a[i]\\_address = base\\_address + i * data\\_type\\_size $$ 其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。 这里要特别纠正一个\"错误\"。在面试的时候，常常会问数组和链表的区别，很多人都回答说，\"链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)\"。 实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。 低效的\"插入\"和\"删除\" 前面概念部分我们提到，数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。现在我们就来详细说一下，究竟为什么会导致低效？又有哪些改进方法呢？ 插入操作 设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。 如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。 如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。 为了更好地理解，我们举一个例子。假设数组 a[10]中存储了如下 5 个元素：a，b，c，d，e。 我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2]赋值为 x 即可。最后，数组中的元素如下： a，b，x，d，e，c。 利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到。 删除操作 跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。 和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。 实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？ 我们继续来看例子。数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。 为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。 如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。 警惕数组的访问越界问题 首先，我请你来分析一下这段 C 语言代码的运行结果： int main ( int argc , char * argv []){ int i = 0 ; int arr [ 3 ] = { 0 }; for (; i <= 3 ; i ++ ){ arr [ i ] = 0 ; printf ( \"hello world \\n \" ); } return 0 ; } 这段代码的运行结果并非是打印三行\"hello word\"，而是会无限打印\"hello world\"，这是为什么呢？ 因为，数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i<=3 而非 i<3，所以当 i=3 时，数组 a[3]访问越界。 我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。 对此处的无限循环有疑问的话，可以去查函数调用的栈桢结构细节（操作系统或计算机体系结构的教材应该会讲到）。函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为。 数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。 这种情况下，一般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例子，debug 的难度非常的大。而且，很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。 但并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做，像 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 java.lang.ArrayIndexOutOfBoundsException。 int [] a = new int [ 3 ] ; a [ 3 ] = 10 ; 容器能否完全替代数组？ 针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？ ArrayList 最大的优势就是可以将很多数组操作的 细节封装 起来。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是支持 动态扩容 。 数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。 如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。 不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。 比如我们要从数据库中取出 10000 条数据放入 ArrayList。我们看下面这几行代码，你会发现，相比之下，事先指定数据大小可以省掉很多次内存申请和数据搬移操作。 ArrayList < User > users = new ArrayList ( 10000 ); for ( int i = 0 ; i < 10000 ; ++ i ) { users . add ( xxx ); } 作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，在以下场景，用数组可能会更合适些： Java ArrayList 无法存储基本类型 ，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则 有一定的性能消耗 ，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 当要表示 多维数组时，用数组往往会更加直观 。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList > array。 总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。 为什么数组要从 0 开始编号，而不是从 1 开始？ 从数组存储的内存模型上来看，\"下标\"最确切的定义应该是\"偏移（offset）\"。前面也讲到，如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式： $$ a[k]\\_address = base\\_address + k * type\\_size $$ 但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为： $$ a[k]\\_address = base\\_address + (k-1)*type\\_size $$ 对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。 数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。 除此之外，更主要的原因可能是历史原因。 C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。 内容小结 数组可以说是最基础、最简单的数据结构了。数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。","tags":"Algorithms","url":"https://jiang-hao.com/articles/2020/algorithms-data-struct-array.html","loc":"https://jiang-hao.com/articles/2020/algorithms-data-struct-array.html"},{"title":"数据结构与算法——复杂度分析","text":"概述 从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。 数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。 想要学习数据结构与算法，首先要掌握一个数据结构与算法中最重要的概念——复杂度分析。它几乎占了数据结构和算法这门课的半壁江山，是数据结构和算法学习的精髓。 数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和资源消耗的方法，这就是复杂度分析方法。 下图几乎涵盖了所有数据结构和算法书籍中都会讲到的知识点： 但是，作为初学者，或者一个非算法工程师来说，并不需要掌握图里面的所有知识点。下面总结了 20 个最常用的、最基础数据结构与算法，不管是应付面试还是工作需要，其实只要集中精力逐一攻克这 20 个知识点就足够了： 10 个数据结构： 数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树 ； 10 个算法： 递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法 ； 在学习数据结构和算法的过程中，也要注意，不要只是死记硬背，不要为了学习而学习，而是要学习它的\"来历\"\"自身的特点\"\"适合解决的问题\"以及\"实际的应用场景\"。 时间复杂度分析 数据结构和算法本身解决的是\"快\"和\"省\"的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。 大 O 复杂度表示法 关键结论： 假设每行代码执行的时间都一样，为 \\(unitTime\\) ，则所有代码的执行时间 T(n) 与每行代码的执行次数成正比。 我们可以把这个规律总结成一个公式： 其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。 按照这个分析思路，我们再来看这段代码。 int cal ( int n ) { int sum = 0 ; int i = 1 ; int j = 1 ; for (; i <= n ; ++ i ) { j = 1 ; for (; j <= n ; ++ j ) { sum = sum + i * j ; } } } 第 2、3、4 行代码，每行都需要 1 个 \\(unit Time\\) 的执行时间，第 5、6 行代码循环执行了 \\(n\\) 遍，需要 \\( 2n * unitTime\\) 的执行时间，第 7、8 行代码循环执行了 \\(n&#94;2\\) 遍，所以需要 \\(2n&#94;2* unitTime\\) 的执行时间。所以，整段代码总的执行时间 \\(T(n) = O(2n&#94;2+2n+3)\\) 。 大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是 表示代码执行时间随数据规模增长的变化趋势 ，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。 当 n 很大时，你可以把它想象成 10000、100000。而公式中的 低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以 了，如果用大 O 表示法表示刚讲的那段代码的时间复杂度，就可以记为： \\(T(n) = O(n&#94;2)\\) 。 时间复杂度分析 如何分析一段代码的时间复杂度？我们有三个比较实用的方法。 只关注循环执行次数最多的一段代码 大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。 这里我要再强调一下，即便某段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。 多段同级代码的总复杂度等于量级最大的那段代码的复杂度 抽象成公式就是： $$ 如果 T_1(n)=O(f(n))，T_2(n)=O(g(n))；那么 T(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))). $$ 多个嵌套循环代码的复杂度等于嵌套内外代码复杂度的乘积 抽象成公式就是： $$ 如果 T_1(n)=O(f(n))，T_2(n)=O(g(n))；那么 T(n)=T_1(n)*T_2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)). $$ 举个例子： int cal ( int n ) { int ret = 0 ; int i = 1 ; for (; i < n ; ++ i ) { ret = ret + f ( i ); } } int f ( int n ) { int sum = 0 ; int i = 1 ; for (; i < n ; ++ i ) { sum = sum + i ; } return sum ; } 我们单独看 \\(cal()\\) 函数。假设 \\(f()\\) 只是一个普通 \\(O(1)\\) 的操作，那第 4～6 行的时间复杂度就是， \\(T_1(n) = O(n)\\) 。但 \\(f()\\) 函数本身不是一个简单的操作，它的时间复杂度是 \\(T_2(n) = O(n)\\) ，所以，整个 \\(cal()\\) 函数的时间复杂度就是， \\(T(n) = T_1(n) * T_2(n) = O(n*n) = O(n&#94;2)\\) 。 几种常见时间复杂度实例分析 虽然代码千差万别，但是常见的复杂度量级并不多。我稍微总结了一下，这些复杂度量级几乎涵盖了你今后可以接触的所有代码的复杂度量级。 对于以上罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个： \\(O(2&#94;n)\\) 和 \\(O(n!)\\) 。 我们把时间复杂度为非多项式量级的算法问题叫作 NP（Non-Deterministic Polynomial，非确定多项式）问题。 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我们就不展开讲了。我们主要来看几种常见的多项式时间复杂度。 O(1) 首先必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。 int i = 8 ; int j = 6 ; int sum = i + j ; 总结一下，只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。 O(logn)、O(nlogn) 对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我们通过一个例子来说明一下。 i = 1 ; while ( i <= n ) { i = i * 2 ; } 根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。 从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的： 所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 \\(2&#94;x=n\\) 求解 x 这个问题我们想高中应该就学过了，我就不多说了。 \\(x=log_2n\\) ，所以，这段代码的时间复杂度就是 \\(O(log_2n)\\) 。 现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？ i = 1 ; while ( i <= n ) { i = i * 3 ; } 根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 \\(O(log_3n)\\) 。 实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 \\(O(logn)\\) 。为什么呢？ 我们知道，对数之间是可以互相转换的， \\(log_3n\\) 就等于 \\(log_32 * log_2n\\) ，所以 \\(O(log_3n) = O(C * log_2n)\\) ，其中 \\(C=log_32\\) 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 \\(O(Cf(n)) = O(f(n))\\) 。所以， \\(O(log_2n)\\) 就等于 \\(O(log_3n)\\) 。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的\"底\"，统一表示为 \\(O(logn)\\) 。 如果你理解了我前面讲的 \\(O(logn)\\) ，那 \\(O(nlogn)\\) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 \\(O(logn)\\) ，我们循环执行 n 遍，时间复杂度就是 \\(O(nlogn)\\) 了。而且， \\(O(nlogn)\\) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 \\(O(nlogn)\\) 。 O(m+n)、O(m*n) 再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定。 int cal ( int m , int n ) { int sum_1 = 0 ; int i = 1 ; for (; i < m ; ++ i ) { sum_1 = sum_1 + i ; } int sum_2 = 0 ; int j = 1 ; for (; j < n ; ++ j ) { sum_2 = sum_2 + j ; } return sum_1 + sum_2 ; } 从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。 针对这种情况，原来的法则就不正确了，我们需要将规则改为： \\(T_1(m) + T_2(n) = O(f(m) + g(n))\\) 。但是对于嵌套循环来说的乘法法则继续有效： \\(T_1(m)*T_2(n) = O(f(m) * f(n))\\) 。 最好、最坏情况时间复杂度 分析一下这段代码的时间复杂度。 // n表示数组array的长度 int find ( int [] array , int n , int x ) { int i = 0 ; int pos = - 1 ; for (; i < n ; ++ i ) { if ( array [ i ] == x ) pos = i ; } return pos ; } 你应该可以看出来，这段代码要实现的功能是，在一个无序的数组（array）中，查找变量 x 出现的位置。如果没有找到，就返回 -1。按照上节课讲的分析方法，这段代码的复杂度是 O(n)，其中，n 代表数组的长度。 我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为有可能中途找到就可以提前结束循环了。但是，这段代码写得不够高效。我们可以这样优化一下这段查找代码。 // n表示数组array的长度 int find ( int [] array , int n , int x ) { int i = 0 ; int pos = - 1 ; for (; i < n ; ++ i ) { if ( array [ i ] == x ) { pos = i ; break ; } } return pos ; } 这个时候，问题就来了。我们优化完之后，这段代码的时间复杂度还是 O(n) 吗？很显然，咱们上一节讲的分析方法，解决不了这个问题。 因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。 为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。 顾名思义，最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。就像我们刚刚讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。 同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。就像刚举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。 平均情况时间复杂度 我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：平均情况时间复杂度，后面我简称为平均时间复杂度。平均时间复杂度又该怎么分析呢？我还是借助刚才查找变量 x 的例子来解释。 要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即： 我们知道，时间复杂度的大 O 标记法中，可以省略掉系数、低阶、常量，所以，咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 O(n)。这个结论虽然是正确的，但是计算过程稍微有点儿问题。究竟是什么问题呢？我们刚讲的这 n+1 种情况，出现的概率并不是一样的。 我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，为了方便你理解，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。 因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样： 这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。 引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。 实际上，在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况。像我们上一节课举的那些例子那样，很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。 均摊时间复杂度 均摊时间复杂度，听起来跟平均时间复杂度有点儿像。对于初学者来说，这两个概念确实非常容易弄混。 平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。 借助一个具体的例子: // array表示一个长度为n的数组 // 代码中的array.length就等于n int [] array = new int [ n ]; int count = 0 ; void insert ( int val ) { if ( count == array . length ) { int sum = 0 ; for ( int i = 0 ; i < array . length ; ++ i ) { sum = sum + array [ i ]; } array [ 0 ] = sum ; count = 1 ; } array [ count ] = val ; ++ count ; } 这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。 那这段代码的时间复杂度是多少呢？你可以先用我们刚讲到的三种时间复杂度的分析方法来分析一下。 最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。 那平均时间复杂度是多少呢？答案是 O(1)。我们还是可以通过前面讲的概率论的方法来分析。 假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。除此之外，还有一种\"额外\"的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是： 至此为止，前面的最好、最坏、平均时间复杂度的计算，理解起来应该都没有问题。但是这个例子里的平均复杂度分析其实并不需要这么复杂，不需要引入概率论的知识。这是为什么呢？我们先来对比一下这个 insert() 的例子和前面那个 find() 的例子，你就会发现这两者有很大差别。 首先，find() 函数在极端情况下，复杂度才为 O(1)。但 insert() 在大部分情况下，时间复杂度都为 O(1)。只有个别情况下，复杂度才比较高，为 O(n)。这是 insert()第一个区别于 find() 的地方。 我们再来看第二个不同的地方。对于 insert() 函数来说，O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入操作，循环往复。 所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。 针对这种特殊的场景，我们引入了一种更加简单的分析方法：摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字，叫均摊时间复杂度。 那究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？ 我们还是继续看在数组中插入数据的这个例子。每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。你都理解了吗？ 均摊时间复杂度和摊还分析应用场景比较特殊，所以我们并不会经常用到。为了方便你理解、记忆，我这里简单总结一下它们的应用场景。如果你遇到了，知道是怎么回事儿就行了。 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。 尽管很多数据结构和算法书籍都花了很大力气来区分平均时间复杂度和均摊时间复杂度，但其实我个人认为，均摊时间复杂度就是一种特殊的平均时间复杂度，我们没必要花太多精力去区分它们。你最应该掌握的是它的分析方法，摊还分析。至于分析出来的结果是叫平均还是叫均摊，这只是个说法，并不重要。 空间复杂度分析 前面我讲过，时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。看下面的例子： void print ( int n ) { int i = 0 ; int [] a = new int [ n ]; for ( i ; i < n ; ++ i ) { a [ i ] = i * i ; } for ( i = n - 1 ; i >= 0 ; -- i ) { print out a [ i ] } } 跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。 我们常见的空间复杂度就是 O(1)、O(n)、O(n2)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，掌握以上述的这些内容已经足够了。 内容小结 什么是复杂度分析？ 数据结构和算法解决是\"如何让计算机更快时间、更省空间的解决问题\"。 因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。 分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度。 复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。 为什么要进行复杂度分析？ 和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。 掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。 如何进行复杂度分析？ 大O表示法 算法的执行时间与每行代码的执行次数成正比，用T(n) = O(f(n))表示，其中T(n)表示算法执行总时间，f(n)表示每行代码执行总次数，而n往往表示数据的规模。以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势，所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项。 复杂度分析法则 1）单段代码看高频：比如循环。 2）多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。 3）嵌套代码求乘积：比如递归、多重循环等 4）多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。 为了表示代码在不同情况下的不同时间复杂度，引入最好情况时间复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度。在引入这几个概念之后，我们可以更加全面地表示一段代码的执行效率。而且，这几个概念理解起来都不难。最好、最坏情况下的时间复杂度分析起来比较简单，但平均、均摊两个复杂度分析相对比较复杂。如果你觉得理解得还不是很深入，不用担心，在后续具体的数据结构和算法学习中，我们可以继续慢慢实践！ 常用的复杂度级别 ？ 多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括， $$ O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n&#94;2)（平方阶）、O(n&#94;3)（立方阶） $$ 非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括， $$ O(2&#94;n)（指数阶）、O(n!)（阶乘阶） $$ 性能测试和复杂度分析的关系？ 有人说，我们项目之前都会进行性能测试，再做代码的时间复杂度、空间复杂度分析，是不是多此一举呢？而且，每段代码都分析一下时间复杂度、空间复杂度，是不是很浪费时间呢？事实上，渐进时间，空间复杂度分析为我们提供了一个很好的理论分析的方向，并且它是宿主平台无关的，能够让我们对我们的程序或算法有一个大致的认识，让我们知道，比如在最坏的情况下程序的执行效率如何，同时也为我们交流提供了一个不错的桥梁，我们可以说，算法1的时间复杂度是O(n)，算法2的时间复杂度是O(logN)，这样我们立刻就对不同的算法有了一个\"效率\"上的感性认识。 当然，渐进式时间，空间复杂度分析只是一个理论模型，只能提供给粗略的估计分析，我们不能直接断定就觉得O(logN)的算法一定优于O(n), 针对不同的宿主环境，不同的数据集，不同的数据量的大小，在实际应用上面可能真正的性能会不同.针对不同的实际情况，进而进行一定的性能基准测试也是很有必要的，比如在统一在某一批型号手机上(同样的硬件，系统等等)进行横向基准测试，进而选择适合特定应用场景下的最优算法。 综上所述，渐进式时间，空间复杂度分析与性能基准测试并不冲突，而是相辅相成的，但是一个低阶的时间复杂度程序有极大的可能性会优于一个高阶的时间复杂度程序，所以在实际编程中，时刻关心理论时间，空间度模型是有助于产出效率高的程序的，同时，因为渐进式时间，空间复杂度分析只是提供一个粗略的分析模型，因此也不会浪费太多时间，重点在于在编程时，要具有这种复杂度分析的思维。 发散思考 ： 算法分析中，通常分析最坏情况还是平均情况？","tags":"Algorithms","url":"https://jiang-hao.com/articles/2020/algorithms-data-structure-n-algorithm-1.html","loc":"https://jiang-hao.com/articles/2020/algorithms-data-structure-n-algorithm-1.html"},{"title":"VxLAN协议详解","text":"VxLAN简介 背景 任何技术的产生，都有其特定的时代背景与实际需求，VXLAN正是为了解决云计算时代虚拟化中的一系列问题而产生的一项技术。那么我们先看看 VXLAN 到底要解决哪些问题。 虚拟机规模受网络设备表项规格的限制 对于同网段主机的通信而言，报文通过查询MAC表进行二层转发。服务器虚拟化后，数据中心中VM的数量比原有的物理机发生了数量级的增长，伴随而来的便是虚拟机网卡MAC地址数量的空前增加。一般而言，接入侧二层设备的规格较小，MAC地址表项规模已经无法满足快速增长的VM数量。 传统网络的隔离能力有限 虚拟化（虚拟机和容器）的兴起使得一个数据中心会有动辄上万的机器需要通信，而传统的 VLAN 技术在标准定义中只有12比特，也就只能支持 4096 个网络上限，已经显然满足不了不断扩展的数据中心规模。 虚拟机迁移范围受限 虚拟机迁移，顾名思义，就是将虚拟机从一个物理机迁移到另一个物理机，但是要求在迁移过程中业务不能中断。要做到这一点，需要保证虚拟机迁移前后，其IP地址、MAC地址等参数维持不变。这就决定了，虚拟机迁移必须发生在一个二层域中。而传统数据中心网络的二层域，将虚拟机迁移限制在了一个较小的局部范围内。此外，解决这个问题同时还需保证二层的广播域不会过分扩大，这也是云计算网络的要求。 传统\"二层+三层\"的网络在应对这些要求时变得力不从心，虽然通过很多改进型的技术比如堆叠、SVF、TRILL等可以构建物理上的大二层网络，可以将虚拟机迁移的范围扩大。但是，构建物理上的大二层，难免需要对原来的网络做大的改动，并且大二层网络的范围依然会受到种种条件的限制。 为了解决这些问题，有很多方案被提出来，VxLAN就是其中之一。VxLAN 是 VMware、Cisco 等一众大型企业共同推出的，目前标准文档在 RFC7348 。 定义 在介绍完VxLAN要解决的问题也就是技术背景之后，接下来正式阐述一下VxLAN的定义，也就是它到底是什么。 VXLAN 全称是 Virtual eXtensible Local Area Network ，虚拟可扩展的局域网。它是一种 Overlay 技术，采用L2 over L4（MAC-in-UDP）封装方式，是NVO3（Network Virtualization over Layer 3）中的一种网络虚拟化技术，将二层报文用三层协议进行封装，可实现虚拟的二层网络在三层范围内进行扩展，同时满足数据中心大二层虚拟迁移和多租户的需求。RFC7348上的介绍是这样的： A framework for overlaying virtualized layer 2 networks over lay 3 networks. 意义 针对大二层网络，VxLAN技术的出现很好的解决了云计算时代背景下数据中心在物理网络基础设施上实施服务器虚拟化的隔离和可扩展性问题： 通过24比特的VNI可以支持多达16M的VXLAN段的网络隔离，对用户进行隔离和标识不再受到限制，可满足海量租户。 除VXLAN网络边缘设备，网络中的其他设备不需要识别虚拟机的MAC地址，减轻了设备的MAC地址学习压力，提升了设备性能。 通过采用MAC in UDP封装来延伸二层网络，实现了物理网络和虚拟网络解耦，租户可以规划自己的虚拟网络，不需要考虑物理网络IP地址和广播域的限制，大大降低了网络管理的难度。 VxLAN组网模型 VxLAN主要用于数据中心网络。VxLAN技术将已有的三层物理网络作为Underlay网络，在其上构建出虚拟的二层网络，即Overlay网络。Overlay网络通过Mac-in-UDP封装技术、利用Underlay网络提供的三层转发路径，实现租户二层报文跨越三层网络在不同的站点间传递。对于租户来说，Underlay网络是透明的，同一租户的不同站点就像是工作在一个局域网中。同时，在同一个物理网络上可以构建多个VxLAN网络，每个VxLAN网络由唯一的VNI标识，不同VxLAN之间互不影响，从而实现租户网络之间的隔离。 如上图所示，VxLAN的典型网络模型中主要包含以下几个基本元素： VM (Virtual Machine): 虚拟机。在一台服务器上可以创建多台虚拟机，不同的虚拟机可以属于不同的 VXLAN。处于相同VxLAN的虚拟机处于同一个逻辑二层网络，彼此之间二层互通；属于不同VxLAN的虚拟机之间二层隔离。 VxLAN Tunnel: VxLAN隧道。\"隧道\"是一个逻辑上的概念，它并不新鲜，比如大家熟悉的GRE。说白了就是将原始报文\"变身\"下，加以\"包装\"，好让它可以在承载网络（比如IP网络）上传输。从主机的角度看，就好像原始报文的起点和终点之间，有一条直通的链路一样。而这个看起来直通的链路，就是\"隧道\"。顾名思义，\"VXLAN隧道\"便是用来传输经过VXLAN封装的报文的，它是建立在两个VTEP之间的一条虚拟通道。Vxlan 通信双方（图中的虚拟机）认为自己是通过二层VSI直接通信，并不知道底层网络的存在。 VTEP (VxLAN Tunnel Endpoints): VXLAN隧道端点。VXLAN网络的边缘设备，是VXLAN隧道的起点和终点，VXLAN报文的封装和解封装处理均在这上面进行。VTEP可以理解为Overlay网络立足于Underlay物理网络之上的支脚点，分配有物理网络的IP地址，该地址与虚拟网络无关。VXLAN报文中源IP地址为隧道一端节点的VTEP地址，目的IP地址为隧道另一端节点的VTEP地址，一对VTEP地址就对应着一个VXLAN隧道。VTEP 可以是一个独立的网络设备（比如交换机），也可以是一台物理服务器（比如虚拟机所在的宿主机）。 VNI (VXLAN Network Identifier): VXLAN 网络标识符。以太网数据帧中VLAN只占了12比特的空间，这使得VLAN的隔离能力在数据中心网络中力不从心。而VNI的出现，就是专门解决这个问题的。VNI是一种类似于VLAN ID的用户标示，一个VNI代表了一个租户，即使多个终端用户属于同一个VNI，也表示一个租户。VNI 由24比特组成，支持多达16M的租户。属于不同VNI的虚拟机之间不能直接进行二层通信。VXLAN报文封装时，给VNI分配了足够的空间使其可以支持海量租户的隔离。 IP核心设备/隧道中间设备: 网络中普通的路由/转发设备，不参与VxLAN处理，仅需根据封装后的VxLAN报文的目的VTEP IP地址沿着VxLAN隧道路径进行普通的三层转发。 VSI (Virtual Switch Instance): 虚拟交换实例。VTEP上为每个VxLAN提供二层交换服务的虚拟交换实例。VSI可以看做是VTEP上的一台针对某个VxLAN内的数据帧进行二层转发的虚拟交换机，它具有传统以太网交换机的所有功能，包括源MAC地址学习、MAC地址老化、泛洪等。VSI与VxLAN一一对应。 VSI-Interface: VSI的虚拟三层接口。类似于Vlan-Interface，用来处理跨VNI即跨VXLAN的流量。VSI-Interface与VSI一一对应，在没有跨VNI流量时可以没有VSI-Interface。 VxLAN报文格式 VXLAN是MAC in UDP的网络虚拟化技术，所以其报文封装是在原始以太报文之前添加了一个UDP头及VXLAN头封装：VTEP会将VM发出的原始报文封装成一个新的UDP报文，并使用物理网络的IP和MAC地址作为外层头，对网络中的其他设备只表现为封装后的参数。也就是说，网络中的其他设备看不到VM发送的原始报文。 如果服务器作为VTEP，那从服务器发送到接入设备的报文便是经过封装后的报文，这样，接入设备就不需要学习VM的MAC地址了，它只需要根据外层封装的报文头负责基本的三层转发就可以了。因此，虚拟机规模就不会受网络设备表项规格的限制了。 当然，如果网络设备作为VTEP，它还是需要学习VM的MAC地址。但是，从对报文进行封装的角度来说，网络设备的性能还是要比服务器强很多。 下图是 VxLAN 协议的报文，白色的部分是虚拟机发出的原始报文（二层帧，包含了 MAC 头部、IP 头部和传输层头部的报文），前面加了VxLAN 头部用来专门保存 VxLAN 相关的内容，再前面是标准的 UDP 协议头部（UDP 头部、IP 头部和 MAC 头部）用来在物理网路上传输报文。 从这个报文中可以看到三个部分： 最外层的 UDP 协议报文用来在底层物理网络上传输，也就是 VTEP 之间互相通信的基础； 中间是 VXLAN 头部，VTEP 接受到报文之后，去除前面的 UDP 协议部分，根据这部分来处理 VxLAN 的逻辑，主要是根据 VNI 发送到最终的虚拟机； 最里面是原始的二层帧，也就是虚拟机所见的报文内容。 VxLAN报文各个部分解释如下： Outer Ethernet/MAC Header: 外层以太头。14字节，如果有VLAN TAG则为18字节。 SA：发送报文的虚拟机所属VTEP的MAC地址。 DA：到达目的VTEP的路径上下一跳设备的MAC地址。 VLAN Type：可选字段，当报文中携带VLAN Tag时，该字段取值为0x8100。 Ethernet Type：以太报文类型，IP协议报文该字段取值为0x0800。 Outer IP Header: 外层IP头。20字节。其中，源IP地址（Outer Src. IP）为源VM所属VTEP的IP地址，目的IP地址（Outer Dst. IP）为目的VM所属VTEP的IP地址。IP协议号（Protocol）为17（0x11），指示内层封装的是UDP报文。 Outer UDP Header: 外层UDP头。8字节。其中，UDP目的端口号（UDP Destination Port）固定为4789，指示内层封装报文为VxLAN报文。UDP源端口号（UDP Source Port）为原始以太帧通过哈希算法计算后的随机任意值，可以用于VxLAN网络VTEP节点之间ECMP负载均衡。 VxLAN Header: VxLAN头。8字节。 Flags: 8比特，RRRRIRRR。\"I\"位为1时，表示VXLAN头中的VXLAN ID有效；为0，表示VXLAN ID无效。\"R\"位保留未用，设置为0。 VxLAN ID (VNI): 24比特，用于标识一个单独的VXLAN网络。这也是 VxLAN 能支持千万租户的地方。 Reserved: 两个保留字段，分别为24比特和8比特。 Original L2 Frame: 原始以太网报文。 从报文的封装可以看出，VXLAN头和原始二层报文是作为UDP报文的载荷存在的。在VTEP之间的网络设备，只需要根据Outer MAC Header和Outer IP Header进行转发，利用UDP Source Port进行负载分担，这一过程，与转发普通的IP报文完全相同。这样，除了VTEP设备，现网的大量设备无需更换或升级即可支持VXLAN网络。 VxLAN协议比原始报文多出50字节的内容，这会降低网络链路传输有效数据的比例。此外，新增加的VXLAN报文封装也引入了一个问题，即MTU值的设置。一般来说，虚拟机的默认MTU为1500 Bytes，也就是说原始以太网报文最大为1500字节。这个报文在经过VTEP时，会封装上50字节的新报文头（VXLAN头8字节+UDP头8字节+外部IP头20字节+外部MAC头14字节），这样一来，整个报文长度达到了1550字节。而现有的VTEP设备，一般在解封装VXLAN报文时，要求VXLAN报文不能被分片，否则无法正确解封装。这就要求VTEP之间的所有网络设备的MTU最小为 1550字节。如果中间设备的MTU值不方便进行更改，那么设置虚拟机的MTU值为1450，也可以暂时解决这个问题。 VxLAN头部最重要的是VNID字段，其他的保留字段主要是为了未来的扩展，很多厂商都会加以运用来实现自己组网的一些特性。 VxLAN运行机制 隧道建立 网络中存在多个VTEP，那么这其中哪些VTEP间需要建立VXLAN隧道呢？如前所述，通过VXLAN隧道，\"二层域\"可以突破物理上的界限，实现大二层网络中VM之间的通信。所以，连接在不同VTEP上的VM之间如果有\"大二层\"互通的需求，这两个VTEP之间就需要建立VXLAN隧道。换言之，同一大二层域内的VTEP之间都需要建立VXLAN隧道。 一般而言，隧道的建立不外乎手工方式和自动方式两种。 手工方式 这种方式需要用户手动指定VXLAN隧道的源和目的IP地址分别为本端和对端VTEP的IP地址，也就是人为的在本端VTEP和对端VTEP之间建立静态VXLAN隧道。以华为CE系列交换机为例，以上配置是在NVE（Network Virtualization Edge）接口下完成的。配置过程如下： # interface Nve1 //创建逻辑接口NVE 1 source 1.1.1.1 //配置源VTEP的IP地址（推荐使用Loopback接口的IP地址） vni 5000 head-end peer-list 2.2.2.2 vni 5000 head-end peer-list 2.2.2.3 # 其中，vni 5000 head-end peer-list 2.2.2.2和vni 5000 head-end peer-list 2.2.2.3的配置，表示属于VNI 5000的对端VTEP有两个，IP地址分别为2.2.2.2和2.2.2.3。根据这两条配置，VTEP上会生成如下所示的一张表： <HUAWEI> display vxlan vni 5000 verbose BD ID : 10 State : up NVE : 288 Source : 1.1.1.1 UDP Port : 4789 BUM Mode : head-end Group Address : - Peer List : 2.2.2.2 2.2.2.3 根据上表中的Peer List，本端VTEP就可以知道属于同一VNI的对端VTEP都有哪些，这也就决定了同一大二层广播域的范围。当VTEP收到BUM（Broadcast&Unknown-unicast&Multicast，广播&未知单播&组播）报文时，会将报文复制并发送给Peer List中所列的所有对端VTEP（这就好比广播报文在VLAN内广播）。因此，这张表也被称为\"头端复制列表\"。当VTEP收到已知单播报文时，会根据VTEP上的MAC表来确定报文要从哪条VXLAN隧道走。而此时Peer List中所列的对端，则充当了MAC表中\"出接口\"的角色。在后面的报文转发流程中，你将会看到头端复制列表是如何在VXLAN网络中指导报文进行转发的。 自动方式 自动方式下VXLAN隧道的建立需要借助于其他的协议，例如通过BGP/EVPN(Ethernet Virtual Private Network)或ENDP(Enhanced Neighbor Discovery Protocol)发现远端VTEP后，自动在本端和远端VTEP之间建立VXLAN隧道。 二层MAC学习 通过上节的内容，我们大致了解 VxLAN 报文的发送过程。概括地说就是虚拟机的报文通过 VTEP 添加上 VxLAN 以及外部的UDP/IP报文头，然后发送出去，对方 VTEP 收到之后拆除 VxLAN 头部然后根据 VNI 把原始报文发送到目的虚拟机。 这个过程是双方已经知道所有通信所需信息的情况下的转发流程，但是在第一次通信之前还有很多问题有解决： VTEP是如何对报文进行封装？ 发送方虚拟机怎么知道对方的 MAC 地址？ VTEP怎么知道目的虚拟机在哪一台宿主机上？ 要回答这些问题，我们还是回到 VxLAN 协议报文上，看看一个完整的 VxLAN 报文需要哪些信息。 内层报文：通信的虚拟机双方要么直接使用 IP 地址，要么通过 DNS 等方式已经获取了对方的 IP 地址。因此网络层的源和目的地址已经知道。同一个网络的虚拟机需要通信，还需要知道对方虚拟机的 MAC 地址， VxLAN需要一个机制来实现类似传统网络 ARP 的功能 。 VxLAN 头部：只需要知道 VNI，这一般是直接配置在 VTEP 上的，要么是提前规划固定的，要么是根据内部报文自动生成的，也不需要担心。 UDP 头部：最重要的是源端口和目的端口，源端口是系统生成并管理的，目的端口也是固定的，比如 IANA 规定的 4789 端口，这部分也不需要担心。 外层IP头部：外层IP头部关心的是隧道两端VTEP的IP地址，源地址可以很简单确定，目的地址是 目的虚拟机所在宿主机关联的VTEP IP 地址 ，这个也需要由某种方式来确定。 外层MAC头部：如果目的VTEP 的 IP 地址确定了，根据路由表查找到下一跳的MAC 地址可以通过经典的 ARP 方式来获取，毕竟 VTEP 网络在同一个三层，经典网络架构那一套就能直接用了。 总结一下，一个 VxLAN 报文需要确定两个地址信息：目的虚拟机的 MAC 地址和目的 VTEP 的 IP 地址，如果 VNI 也是动态感知的，那么 VTEP 就需要一个三元组： (内层目的虚机MAC, VNI, 外层目的VTEP IP) 组成为控制平面的表来记录对端地址可达情况。VXLAN有着与传统以太网非常相似的MAC学习机制，当VTEP接收到VXLAN报文后，会记录源VTEP的IP、虚拟机MAC和VNI到本地MAC表中，这样当VTEP接收到目的MAC为此虚拟机的MAC时，就可以进行VXLAN封装并转发。VXLAN学习地址的时候仍然保存着二层协议的特征，节点之间不会周期性的交换各自的转发表。对于不认识的MAC地址，VXLAN一般依靠组播或控制中心来获取路径信息。组播的概念是同个 VxLAN 网络的 VTEP 加入到同一个组播网络，如果需要知道以上信息，就在组内发送多播来查询；控制中心的概念是在某个集中式的地方保存了所有虚拟机的上述信息，自动化告知 VTEP 它需要的信息。 组播方式 每个多播组对应一个多播IP地址，vtep 建立的时候会通过配置加入到多播组（具体做法取决于实现），往这个多播IP地址发送的报文会发给多播组的所有主机。为什么要使用多播？因为vxlan的底层网络是三层的，广播地址无法穿越三层网络，要给vxlan 网络所有vtep发送报文只能通过多播。 通过组播的方式承载ARP的广播报文可以实现整个VxLAN网络下的地址解析以及VSI的MAC地址学习，在这个过程中，只需要有一次多播，因为VTEP有自动学习的能力，后续的报文都是通过单播直接发送的。也可以看到，多播报文非常浪费，每次的多播其实只有一个报文是有效的，如果某个多播组的 vtep 数量很多，这个浪费是非常大的。但是多播组也有它的实现起来比较简单，不需要中心化的控制，只要底层网络支持多播，只需配置好多播组就能自动发现了。因为并不是所有的网络设备都支持多播，再加上多播方式带来的报文浪费，在实际生产中这种方式很少用到。综上，VXLAN和传统VLAN网络数据平面一样，数据经过未知单播泛洪->MAC表项及ARP表项建立->单播转发的过程，我们称之为自学习模式。但自学习方式过于简单，其大量的泛洪报文以及无法智能调整的缺点，使得这样的控制平面构建方式不适合SDN网络。 控制器方式 VTEP发送报文最关键的就是知道对方虚拟机的 MAC 地址和虚拟机所在主机的 VTEP IP 地址，如果实现知道这两个信息，那么就不需要多播了。SDN最大的特点就是转控分离，集中控制。按照这个指导思想，将控制功能单独剥离出来成为一个单独的设备便是很自然的事了。这个设备就是 Controller。Controller可以是一个或者一组硬件设备，也可以是一套软件。Controller与网络中所有设备建立连接，整个VXLAN网络的数据转发都由Controller来管理。Controller与设备连接的接口称为南向接口，可以使用OpenFlow、Netconf等协议；对用户提供服务的接口称为北向接口，也可以提供API以便与其他管理平台对接或进行深度开发。基于Controller的南向接口，可以通过OpenFlow或OVSDB协议的方式向VTEP设备下发远端MAC地址表项。具体不在这里进行展开讲述。 BUM报文转发 前面描述的报文转发过程都是已知单播报文转发，如果VTEP收到一个未知地址的BUM报文如何处理呢。与传统以太网BUM报文转发类似，VTEP会通过泛洪的方式转发流量。BUM（Broadcast, Unknown-unicast, Multicast）即广播、未知单播、组播流量。根据对泛洪流量的复制方式不同可分为单播路由方式（头端复制）和组播路由方式（核心复制）两种。 单播路由方式泛洪（头端复制） 在头端复制方式下，VTEP负责复制报文，采用单播方式将复制后的报文通过本地接口发送给本地站点，并通过VXLAN隧道发送给VXLAN内的所有远端VTEP。 如下图所示，当VTEP 1上的VM 1发出BUM报文后，VTEP 1判断数据所属的VXLAN，通过该VXLAN内所有本地接口和VXLAN Tunnel转发报文。通过VXLAN Tunnel转发报文时，封装VXLAN头、UDP头和IP头，将泛洪报文封装于单播报文中，发送到VXLAN内的所有远端VTEP。 远端VTEP收到VXLAN报文后，解封装报文，将原始数据在本地站点的VXLAN内泛洪。为避免环路，远端VTEP从VXLAN隧道上接收到报文后，不会再将其泛洪到其他的VXLAN隧道。 通过头端复制完成BUM报文的广播，不需要依赖组播路由协议。 组播路由方式泛洪（核心复制） 组播路由方式的组网中同一个VXLAN内的所有VTEP都加入同一个组播组，利用组播路由协议（如PIM）在IP网络上为该组播建立组播转发表项，VTEP上相应生成一个组播隧道。 与头端复制方式不同，当VTEP 1上的VM 1发出BUM报文后，VTEP 1不仅在本地站点内泛洪，还会为其封装组播目的IP地址，封装后的报文根据已建立的组播转发表项转发到IP网络。 在组播报文到达IP网络中的中间设备时，该设备根据已建立的组播表项对报文进行复制并转发。 远端VTEP（VTEP 2和VTEP 3）接收到报文后，解封装报文，将原始的数据帧在本地站点的指定VXLAN泛洪。为了避免环路，远端VTEP从VXLAN隧道上接收到报文后，不会再将其泛洪到其他的VXLAN隧道。 由于泛洪流量使用了组播技术，所以整个组网中的网络设备需要支持组播路由协议（如PIM等）来建立组播路径以便组播报文转发。 参考文献 vxlan 协议原理简介 华为悦读汇技术发烧友：认识VXLAN 华为VxLAN技术白皮书","tags":"Networking","url":"https://jiang-hao.com/articles/2020/networking-vxlan-in-depth.html","loc":"https://jiang-hao.com/articles/2020/networking-vxlan-in-depth.html"},{"title":"深入理解大数据之——事务及其ACID特性","text":"事务简介 事物的定义 事务（Transaction）是由一系列对系统中数据进行访问或更新的操作所组成的一个程序执行逻辑单元（Unit）。在计算机术语中，事务通常就是指数据库事务 。 在数据库管理系统（DBMS）中，事务是数据库恢复和并发控制的基本单位。它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。 例如，银行转帐工作：从源帐号扣款并使目标帐号增款，这两个操作必须要么全部执行，要么都不执行，否则就会出现该笔金额平白消失或出现的情况。所以，应该把他们看成一个事务。 在现代数据库中，事务还可以实现其他一些事情，例如，确保你不能访问别人写了一半的数据；但是基本思想是相同的——事务是用来确保 无论发生什么情况，你使用的数据都将处于一个合理的状态 ： transactions are there to ensure, that no matter what happens, the data you work with will be in a sensible state. 它保证在任何情况下都不会出现在转账后从一个帐户中扣除了资金，而未将其存入另一个帐户的情况。 事务的目的 数据库事务通常包含了一个序列的对数据库的读/写操作。包含有以下两个目的： 为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。 当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。 当事务被提交给了DBMS，则DBMS需要确保该事务中的所有操作都成功完成且其结果被永久保存在数据库中，如果事务中有的操作没有成功完成，则事务中的所有操作都需要回滚，回到事务执行前的状态；同时，该事务对数据库或者其他事务的执行无影响，所有的事务都好像在独立的运行。 Martin Kleppmann在他的《Designing Data-Intensive Applications》一书中有提到： Transactions are not a law of nature; they were created with a purpose, namely to simplify the programming model for applications accessing a database. By using transactions, the application is free to ignore certain potential error scenarios and concurrency issues, because the database takes care of them instead (we call these safety guarantees). 在现实情况下，失败的风险很高。在一个数据库事务的执行过程中，有可能会遇上事务操作失败、数据库系统或操作系统出错，甚至是存储介质出错等情况。而上述Martin的话说明了事务的存在，就是为了能够简化我们的编程模型，不需要我们去考虑各种各样的潜在错误和并发问题 。我们在实际使用事务时，不需要考虑数据库宕机，网络异常，并发修改等问题，整个事务要么提交，要么回滚，非常方便。所以本质上来说， 事务的出现了是为了应用层服务的，而不是数据库系统本身的需要 。 事务的状态 因为事务具有原子性，所以从外部看的话，事务就是密不可分的一个整体，事务的状态也只有三种：Active、Commited 和 Failed，事务要不就在执行中，要不然就是成功或者失败的状态。 进一步放大看，事物内部还有部分提交这个中间状态，其对外是不可见的。 所以，具体来说，事务有以下几种可能的状态： Active：事务的初始状态，表示事务正在执行； Partially Committed：在最后一条语句执行之后； Failed：发现事务无法正常执行之后； Aborted：事务被回滚并且数据库恢复到了事务进行之前的状态之后； Committed：成功执行整个事务。 我们也可以看到，事务在执行之后只会以Aborted或者Committed状态作为结束。 事务的ACID属性 ACID简介 为了保持数据库的一致性，在事务处理之前和之后，都遵循某些属性，也就是大家耳熟能详的ACID属性： 原子性（Atomicity）：即不可分割性，事务中的操作要么全不做，要么全做 一致性（Consistency）：一个事务在执行前后，数据库都必须处于正确的状态，满足 完整性约束 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行 持久性（Durability）：事务处理完成后，对数据的修改就是永久的，即便系统故障也不会丢失 并非任意的对数据库的操作序列都是数据库事务。ACID属性是一系列操作组成事务的必要条件。总体而言，ACID属性提供了一种机制，使每个事务都\"作为一个单元，完成一组操作，产生一致结果，事务彼此隔离，更新永久生效\"，从而来确保数据库的正确性和一致性。 原子性（Atomicity） 原子性也被称为\"全有或全无规则\"。它非常好理解，即整个事务要么完整发生，要么根本不发生，不会部分发生。它涉及以下两个操作： 中止 ：如果事务中止，则看不到对数据库所做的更改。 提交 ：如果事务提交，则所做的更改可见。 拿之前转账的例子来说，用户A给用户B转账，至少要包含两个操作，用户A钱数减少，用户B钱数增加，增加和减少的操作要么全部成功，要么全部失败，是一个原子操作。如下图，如果事务在 T1 完成之后但在 T2 完成之前失败，将导致数据库状态不正确。 一致性（Consistency） 一致性是指，一个事务必须使数据库从一个一致性状态变换到另一个一致性状态（执行成功），或回滚到原始的一致性状态（执行失败）。这意味着必须维护完整性约束，以使在事务之前和之后数据库保持一致性和正确性。 参考上面的示例，假设用户A和用户B两者的钱加起来一共是700，那么不管A和B之间如何转账，转几次账，这一约束都得成立，即事务结束后两个用户的钱相加起来还得是700，这就是事务的一致性。 如果转账过程中，仅完成A扣款或B增款两个操作中的一个，即未保证原子性，那么结果数据如上述完整性约束也就无法得到维护，一致性也就被打破。可以看出，事务的一致性和原子性是密切相关的，原子性的破坏可能导致数据库的不一致。 但数据的一致性问题并不都和原子性有关。比如转账的过程中，用户A扣款了100，而用户B只收款了50，那么该过程可以符合原子性，但是数据的一致性就出现了问题。 一致性既是事务的属性，也是事务的目的 。也正如本文开篇所提到的，\"事务是用来确保无论发生什么情况，你使用的数据都将处于一个合理的状态\"，这里所说的合理/正确，也就是指满足完整性约束。 总的来说， 一致性是事务ACID四大特性中最重要的属性，而原子性、隔离性和持久性，都是作为保障一致性的手段。事务作为这些性质的载体，实现了这种由ACID保障C的机制。 ACID和CAP中C（一致性）的区别 请注意，我们一直在讨论的一致性，即ACID中的C，是指单一实体内部的正确状态在时间维度上的一致性，进一步说，是通过维护数据的完整性约束，来保持数据库在时间上（比如事务前后）保持一致的正确状态。因为是描述单一实体的内部状态，故又称\"内部一致性\"。 而CAP原则中的一致性是指在分布式系统中，空间维度上，某一特定时刻，多个实体中不同数据备份之间值的一致性，又称\"外部一致性\"。具体我们会在另文CAP原则相关内容中做详细介绍。 隔离性（Isolation） 隔离性是指，并发执行的各个事务之间不能互相干扰，即一个事务内部的操作及使用的数据，对并发的其他事务是隔离的。此属性确保并发执行一系列事务的效果等同于以某种顺序串行地执行它们，也就是要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。这要求两件事: 在一个事务执行过程中，数据的中间的（可能不一致）状态不应该被暴露给所有的其他事务。 两个并发的事务应该不能操作同一项数据。数据库管理系统通常使用锁来实现这个特征。 还是拿转账来说，在A向B转账的整个过程中，只要事务还没有提交（commit），查询A账户和B账户的时候，两个账户里面的钱的数量都不会有变化。如果在A给B转账的同时，有另外一个事务执行了C给B转账的操作，那么当两个事务都结束的时候，B账户里面的钱必定是A转给B的钱加上C转给B的钱再加上自己原有的钱。 如此，隔离性防止了多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。以上4个级别的隔离性依次增强，分别解决不同的问题。 事务隔离级别越高，就越能保证数据的完整性和一致性，但同时对并发性能的影响也越大 。 持久性（Durability） 事务的持久性又称为永久性（Permanency），是指一个事务一旦提交，对数据库中对应数据的状态变更就应该是 永久性 的。即使发生系统崩溃或机器宕机等故障，只要数据库能够重新启动，那么一定能够根据事务日志对未持久化的数据重新进行操作，将其 恢复 到事务成功结束的状态。持久性意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会因为系统故障而被回滚。（完成的事务是系统永久的部分，对系统的影响是永久性的） 许多数据库通过引入 预写式日志 （Write-ahead logging，缩写 WAL）机制，来保证事务持久性和数据完整性，同时又很大程度上避免了基于事务直接刷新数据的频繁IO对性能的影响。 在使用WAL的系统中，所有的修改都先被写入到日志中，然后再被应用到系统状态中。假设一个程序在执行某些操作的过程中机器掉电了。在重新启动时，程序可能需要知道当时执行的操作是成功了还是部分成功或者是失败了。如果使用了WAL，程序就可以检查log文件，并对突然掉电时计划执行的操作内容跟实际上执行的操作内容进行比较。在这个比较的基础上，程序就可以决定是撤销已做的操作还是继续完成已做的操作，或者是保持原样。 总结 事务（Transaction）是由一系列对系统中数据进行访问或更新的操作所组成的一个程序执行逻辑单元（Unit）。在事务的ACID特性中，C即一致性是事务的根本追求，而对数据一致性的破坏主要来自两个方面： 事务的并发执行 事务故障或系统故障 数据库系统是通过并发控制技术和日志恢复技术来避免这种情况发生的。 并发控制技术保证了事务的隔离性，使数据库的一致性状态不会因为并发执行的操作被破坏。 日志恢复技术保证了事务的原子性，使一致性状态不会因事务或系统故障被破坏。同时使已提交的对数据库的修改不会因系统崩溃而丢失，保证了事务的持久性。 我们将另文对以上两种技术进行详细介绍。 参考文献 What is a database transaction? (2019). Retrieved November 5, 2019, from Stack Overflow website: https://stackoverflow.com/questions/974596/what-is-a-database-transaction Communcations and Information Processing: First International Conference, ICCIP 2012, Aveiro, Portugal, March 7-11, 2012, Proceedings, 第 2 部分 Designing Data-Intensive Applications: The Big Ideas Behind Reliable, Scalable, and Maintainable Systems, 第25节 ACID Properties in DBMS - GeeksforGeeks. (2016, August 7). Retrieved November 5, 2019, from GeeksforGeeks website: https://www.geeksforgeeks.org/acid-properties-in-dbms/ 维基百科. (2011, July 25). 预写式日志. Retrieved November 5, 2019, from Wikipedia.org website: https://zh.wikipedia.org/wiki/%E9%A2%84%E5%86%99%E5%BC%8F%E6%97%A5%E5%BF%97 数据库事务的概念及其实现原理 - takumiCX - 博客园. (2018). Retrieved November 5, 2019, from Cnblogs.com website: https://www.cnblogs.com/takumicx/p/9998844.html 浅入深出MySQL中事务的实现. (2017, August 20). Retrieved November 5, 2019, from 面向信仰编程 website: https://draveness.me/mysql-transaction ‌","tags":"Backend","url":"https://jiang-hao.com/articles/2019/backend-transactions-acid.html","loc":"https://jiang-hao.com/articles/2019/backend-transactions-acid.html"},{"title":"Flink 词汇表","text":"Flink应用程序集群 Flink应用程序集群是指仅执行一个 Flink作业 专用的 Flink集群 。该 Flink集群 的生命周期与对应Flink作业的生命周期相同。在 工作模式下， 以前的Flink应用程序集群也称为Flink集群。点击查看与 Flink Session Cluster 的比较。 Flink集群 一种分布式系统，通常由一个 Flink Master 和一个或多个 Flink TaskManager 进程组成。 事件 事件是有关由应用程序建模的域的状态更改的声明。事件可以是流或批处理应用程序的输入和/或输出。事件是特殊类型的 记录 。 执行图 见 物理图 函数 函数由用户实现，并封装Flink程序的应用程序逻辑。大多数函数由相应的 算子 包装 。 实例 术语 实例 用于描述在运行期间特定类型的特定实例（通常是 算子 或 函数 ）。由于Apache Flink主要是用Java编写的，因此它对应于Java中的 Instance 或 Object 的定义。在Apache Flink的上下文中，术语\" 并行实例\" 也经常用来强调相同 算子 或 函数 类型的多个实例正在并行运行。 Flink作业 Flink作业是Flink程序的运行时表示形式。Flink作业既可以提交到长期运行的 Flink会话集群 ，也可以作为独立的 Flink应用程序集群启动 。 作业图 请参阅 逻辑图 Flink JobManager JobManager是 Flink Master中 运行的组件之一。JobManager负责监督单个作业的 任务 执行。历史上，整个 Flink Master 都称为JobManager。 逻辑图 逻辑图是描述流处理程序的高级逻辑的有向图。节点是 算子 ，边指示输入/输出关系或数据流或数据集。 受管状态 受管状态描述了已在框架中注册的应用程序状态。对于受管状态，Apache Flink将特别关注持久性和可伸缩性。 Flink Master Flink Master是 Flink群集 的Master。它包含三个不同的组件：Flink Resource Manager（资源管理器），Flink Dispatcher（FLink 调度器）和每个运行的 Flink Job 的 Flink JobManager 。 算子 逻辑图的 节点。算子执行某种操作，通常由 Function 执行。Source和SInk是用于数据摄取和数据出口的特殊算子。 算子链 一个算子链由两个或多个连续的 算子 组成，中间没有任何重新分配（rebalance）。同一算子链中的算子无需经过序列化或Flink的网络堆栈即可直接将记录彼此转发。 分区 分区是整个数据流或数据集的独立子集。通过将每个 记录 分配给一个或多个分区，将数据流或数据集划分为多个分区。 任务 在运行时消费数据流或数据集的分区。改变数据流或数据集分区方式的转换通常称为重新分区（repartitioning）。 物理图 物理图是转换 逻辑图 以在分布式运行时中执行的结果。节点是 任务 ，边指示数据流或数据集的输入/输出关系或 分区 。 记录 记录是数据集或数据流的组成元素。 算子 和 函数 接收记录作为输入，并发出记录作为输出。 Flink会话集群 长期运行的 Flink群集 ，它接受多个 Flink作业 来执行。此Flink群集的生存期未绑定到任何Flink作业的生存期。以前，Flink群集在 会话模式下 也称为Flink会话群集。与 Flink应用程序集群 进行比较 。 状态后端 对于流处理程序， Flink作业 的状态后端确定如何在每个TaskManager（TaskManager的Java堆或（嵌入式）RocksDB）上存储其 状态 ，以及在检查点上写入状态的位置（ Flink Master 或文件系统的Java堆） ）。 子任务 子任务是负责处理数据流 分区 的 任务 。术语\"子任务\"强调针对同一 算子 或 算子链 有多个并行任务 。 任务 物理图的 节点。任务是基本工作单元，由Flink的运行时执行。任务恰好封装了 算子 或 算子链 的一个并行实例 。 Flink任务管理器 TaskManager是 Flink群集 的工作进程。 Tasks 安排在TaskManager中执行。它们彼此通信以在连续的任务之间交换数据。 转换 将转换应用于一个或多个数据流或数据集，并产生一个或多个输出数据流或数据集。转换可能会更改数据流或数据集的每个记录，但也可能仅更改其分区或执行聚合。虽然 算子 和 函数 是Flink API的\"物理\"部分，但转换只是API概念。具体来说，大多数（但不是全部）转换是由某些 算子 实现的。","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-flink-glossary.html","loc":"https://jiang-hao.com/articles/2019/big-data-flink-glossary.html"},{"title":"大陆访问Vultr各节点VPS网速测试综合报告","text":"限时福利 Vultr新用户赠送$50活动入口 测试方法 采用以下方法： 本地Ping测试 腾讯云主机Ping测试 本地下载测试 腾讯云主机下载测试 站长工具综合测试 节点列表 Location Looking Glass Download Test File: IPv4 Frankfurt, DE fra-de-ping.vultr.com 100MB 1GB Amsterdam, NL ams-nl-ping.vultr.com 100MB 1GB Paris, France par-fr-ping.vultr.com 100MB 1GB London, UK lon-gb-ping.vultr.com 100MB 1GB Singapore sgp-ping.vultr.com 100MB 1GB Tokyo, Japan hnd-jp-ping.vultr.com 100MB 1GB New York (NJ) nj-us-ping.vultr.com 100MB 1GB Toronto, Canada tor-ca-ping.vultr.com 100MB 1GB Chicago, Illinois il-us-ping.vultr.com 100MB 1GB Atlanta, Georgia ga-us-ping.vultr.com 100MB 1GB Seattle, Washington wa-us-ping.vultr.com 100MB 1GB Miami, Florida fl-us-ping.vultr.com 100MB 1GB Dallas, Texas tx-us-ping.vultr.com 100MB 1GB Silicon Valley, California sjo-ca-us-ping.vultr.com 100MB 1GB Los Angeles, California lax-ca-us-ping.vultr.com 100MB 1GB Sydney, Australia syd-au-ping.vultr.com 100MB 1GB 测试结果 电信 优选节点： Toronto New York Chicago Los Angeles Atlanta Dallas Sillicon Valley 联通 优选节点： New York Chicago Atlanta Los Angeles Toronto Dallas 移动 优选节点： New York Atlanta Seattle Amsterdam Paris Sillicon Valley 多线 优选节点： New York Chicago Toronto Los Angeles Atlanta Dallas","tags":"Tools","url":"https://jiang-hao.com/articles/2019/tools-Vultr-Nodes-Speed-Tests.html","loc":"https://jiang-hao.com/articles/2019/tools-Vultr-Nodes-Speed-Tests.html"},{"title":"Flink DataStream API教程","text":"在本文中，我们将从头开始，介绍从设置Flink项目到在Flink集群上运行流分析程序。 Wikipedia提供了一个IRC频道，其中记录了对Wiki的所有编辑。我们将在Flink中读取此通道，并计算每个用户在给定时间窗口内编辑的字节数。这很容易使用Flink在几分钟内实现，但它将为您提供一个良好的基础，从而开始自己构建更复杂的分析程序。 设置Maven项目 我们将使用Flink Maven Archetype来创建我们的项目结构。有关此内容的更多详细信息，请参阅 Java API快速入门 。出于我们的目的，运行命令是这样的： $ mvn archetype:generate \\ -DarchetypeGroupId = org.apache.flink \\ -DarchetypeArtifactId = flink-quickstart-java \\ -DarchetypeVersion = 1 .8.0 \\ -DgroupId = wiki-edits \\ -DartifactId = wiki-edits \\ -Dversion = 0 .1 \\ -Dpackage = wikiedits \\ -DinteractiveMode = false 您可以编辑 groupId ， artifactId 而 package 如果你喜欢。使用上面的参数，Maven将创建一个如下所示的项目结构： $ tree wiki-edits wiki-edits/ ├── pom.xml └── src └── main ├── java │ └── wikiedits │ ├── BatchJob.java │ └── StreamingJob.java └── resources └── log4j.properties 我们的 pom.xml 文件已经在根目录中添加了Flink依赖项，并且有几个示例Flink程序 src/main/java 。我们可以删除示例程序，因为我们将从头开始： $ rm wiki-edits/src/main/java/wikiedits/*.java 作为最后一步，我们需要将Flink Wikipedia连接器添加为依赖关系，以便我们可以在我们的程序中使用它。编辑 dependencies 部分 pom.xml ，使其看起来像这样： <dependencies> <dependency> <groupId> org.apache.flink </groupId> <artifactId> flink-java </artifactId> <version> ${flink.version} </version> </dependency> <dependency> <groupId> org.apache.flink </groupId> <artifactId> flink-streaming-java_2.11 </artifactId> <version> ${flink.version} </version> </dependency> <dependency> <groupId> org.apache.flink </groupId> <artifactId> flink-clients_2.11 </artifactId> <version> ${flink.version} </version> </dependency> <dependency> <groupId> org.apache.flink </groupId> <artifactId> flink-connector-wikiedits_2.11 </artifactId> <version> ${flink.version} </version> </dependency> </dependencies> 注意添加的依赖项 flink-connector-wikiedits_2.11 。（此示例和Wikipedia连接器的灵感来自Apache Samza 的 Hello Samza 示例。） 写一个Flink程序 接下来是编码。启动你喜欢的IDE并导入Maven项目或打开文本编辑器并创建文件 src/main/java/wikiedits/WikipediaAnalysis.java ： package wikiedits ; public class WikipediaAnalysis { public static void main ( String [] args ) throws Exception { } } 该程序现在还非常基础，但我们会慢慢填充。请注意，我不会在此处提供import语句，因为IDE可以自动添加它们。在本文结尾将给出包括import语句的完整的代码。 Flink程序的第一步是创建一个 StreamExecutionEnvironment （或者 ExecutionEnvironment ，如果您正在编写批处理作业）。这可用于设置执行参数并创建从外部系统读取的源。所以让我们继续把它添加到main方法中： StreamExecutionEnvironment see = StreamExecutionEnvironment . getExecutionEnvironment (); 接下来，我们将创建一个从Wikipedia IRC日志中读取的源： DataStream < WikipediaEditEvent > edits = see . addSource ( new WikipediaEditsSource ()); 这创建了我们可以进一步处理的一个包含 WikipediaEditEvent 元素的 DataStream 。出于本示例的目的，我们感兴趣的是确定每个用户在特定时间窗口中添加或删除的字节数，比如说五秒。为此，我们首先要对流以用户名进行键值化，也就是说此流上的操作应考虑用户名。在我们的例子中，窗口中编辑的字节的总和应该是基于每个唯一的用户分别进行统计。对流进行键值化，我们必须提供一个 KeySelector ，如下所示： KeyedStream < WikipediaEditEvent , String > keyedEdits = edits . keyBy ( new KeySelector < WikipediaEditEvent , String > () { @Override public String getKey ( WikipediaEditEvent event ) { return event . getUser (); } }); 这为我们提供了一个具有 String 类型用户名键的 WikipediaEditEvent 数据流。我们现在可以指定我们希望在此流上加上窗口，并根据这些窗口中的元素计算结果。窗口定义了要在其上执行计算的数据流的一个切片。在无限的元素流上计算聚合时需要Windows。在我们的例子中，我们将说我们想要每五秒聚合一次编辑的字节总和： DataStream < Tuple2 < String , Long >> result = keyedEdits . timeWindow ( Time . seconds ( 5 )) . aggregate ( new AggregateFunction < WikipediaEditEvent , Tuple2 < String , Long > , Tuple2 < String , Long >> () { @Override public Tuple2 < String , Long > createAccumulator () { return new Tuple2 <> ( \"\" , 0 L ); } @Override public Tuple2 < String , Long > add ( WikipediaEditEvent value , Tuple2 < String , Long > accumulator ) { accumulator . f0 = value . getUser (); accumulator . f1 += value . getByteDiff (); return accumulator ; } @Override public Tuple2 < String , Long > getResult ( Tuple2 < String , Long > accumulator ) { return accumulator ; } @Override public Tuple2 < String , Long > merge ( Tuple2 < String , Long > a , Tuple2 < String , Long > b ) { return new Tuple2 <> ( a . f0 , a . f1 + b . f1 ); } }); 第一个调用 .timeWindow() 表示我们希望有五秒钟的翻滚（不重叠）窗口。第二个调用为每个Key在每个窗口切片上指定 聚合转换 。在我们的例子中，我们从一个初始值 (\"\", 0L) 开始，并在该时间窗口中为用户添加每次编辑的字节差。现在，输出流中将包含每个用户对应一个每五秒钟发出一次的 Tuple2<String, Long> 。 剩下要做的就是将流打印到控制台并开始执行： result . print (); see . execute (); 最后一个调用是启动实际Flink工作所必需的。所有操作（例如创建源Source，转换Transformation和接收器Sink）仅构建内部操作的图形。只有在 execute() 被调用时才会提交到集群上或在本地计算机上执行此操作图。 到目前为止完整的代码是这样的： package wikiedits ; import org.apache.flink.api.common.functions.AggregateFunction ; import org.apache.flink.api.java.functions.KeySelector ; import org.apache.flink.api.java.tuple.Tuple2 ; import org.apache.flink.streaming.api.datastream.DataStream ; import org.apache.flink.streaming.api.datastream.KeyedStream ; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment ; import org.apache.flink.streaming.api.windowing.time.Time ; import org.apache.flink.streaming.connectors.wikiedits.WikipediaEditEvent ; import org.apache.flink.streaming.connectors.wikiedits.WikipediaEditsSource ; public class WikipediaAnalysis { public static void main ( String [] args ) throws Exception { StreamExecutionEnvironment see = StreamExecutionEnvironment . getExecutionEnvironment (); DataStream < WikipediaEditEvent > edits = see . addSource ( new WikipediaEditsSource ()); KeyedStream < WikipediaEditEvent , String > keyedEdits = edits . keyBy ( new KeySelector < WikipediaEditEvent , String > () { @Override public String getKey ( WikipediaEditEvent event ) { return event . getUser (); } }); DataStream < Tuple2 < String , Long >> result = keyedEdits . timeWindow ( Time . seconds ( 5 )) . aggregate ( new AggregateFunction < WikipediaEditEvent , Tuple2 < String , Long > , Tuple2 < String , Long >> () { @Override public Tuple2 < String , Long > createAccumulator () { return new Tuple2 <> ( \"\" , 0 L ); } @Override public Tuple2 < String , Long > add ( WikipediaEditEvent value , Tuple2 < String , Long > accumulator ) { accumulator . f0 = value . getUser (); accumulator . f1 += value . getByteDiff (); return accumulator ; } @Override public Tuple2 < String , Long > getResult ( Tuple2 < String , Long > accumulator ) { return accumulator ; } @Override public Tuple2 < String , Long > merge ( Tuple2 < String , Long > a , Tuple2 < String , Long > b ) { return new Tuple2 <> ( a . f0 , a . f1 + b . f1 ); } }); result . print (); see . execute (); } } 您可以使用Maven在IDE或命令行上运行此示例： $ mvn clean package $ mvn exec:java -Dexec.mainClass = wikiedits.WikipediaAnalysis 第一个命令构建我们的项目，第二个命令执行我们的主类。输出应该类似于： 1 > ( Fenix down,114 ) 6 > ( AnomieBOT,155 ) 8 > ( BD2412bot,-3690 ) 7 > ( IgnorantArmies,49 ) 3 > ( Ckh3111,69 ) 5 > ( Slade360,0 ) 7 > ( Narutolovehinata5,2195 ) 6 > ( Vuyisa2001,79 ) 4 > ( Ms Sarah Welch,269 ) 4 > ( KasparBot,-245 ) 每行前面的数字告诉你输出是由哪个打印Sink的并行实例产生的。 要了解更多信息，您可以查看我们的 基本概念 指南和 DataStream API 。如果您想了解如何在自己的机器上设置Flink群集并将结果写入 Kafka ，请坚持参加奖励练习。 额外练习：在群集上运行并写入Kafka 请按照我们的 本地安装教程 在您的计算机上设置Flink分发，并在继续之前参考 Kafka快速入门 以设置Kafka安装。 作为第一步，我们必须添加Flink Kafka连接器作为依赖，以便我们可以使用Kafka Sink。将其添加到 pom.xml dependency 部分： <dependency> <groupId> org.apache.flink </groupId> <artifactId> flink-connector-kafka-0.11_2.11 </artifactId> <version> ${ flink . version } </version> </dependency> 接下来，我们需要修改我们的程序。我们将移除 print() Sink，而是使用Kafka Sink。新代码如下所示： result .map(new MapFunction<Tuple2<String,Long>, String>() { @Override public String map(Tuple2<String, Long> tuple) { return tuple.toString(); } }) .addSink(new FlinkKafkaProducer011<>(\"localhost:9092\", \"wiki-result\", new SimpleStringSchema())); 还需要导入相关的类： import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer011 ; import org.apache.flink.api.common.serialization.SimpleStringSchema ; import org.apache.flink.api.common.functions.MapFunction ; 注意我们是如何在一开始的时候使用MapFunction转换 Tuple2<String, Long> 流为 String 流。我们这样做是因为将简单字符串写入Kafka更容易。然后，我们创建了一个Kafka Sink。您须先修改使主机名和端口对应您的设置。 \"wiki-result\" 是在我们运行程序之前我们将要创建的Kafka流的名称。使用Maven构建项目，因为我们需要jar文件在集群上运行： $ mvn clean package 生成的jar文件将位于 target 子文件夹中： target/wiki-edits-0.1.jar 。我们稍后会用到它。 现在我们准备启动Flink集群并运行写入Kafka的程序。转到安装Flink的位置并启动本地群集： $ cd my/flink/directory $ bin/start-cluster.sh 我们还必须创建Kafka主题，以便我们的程序可以写入它： $ cd my/kafka/directory $ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic wiki-results 现在我们准备在本地Flink集群上运行我们的jar文件： $ cd my/flink/directory $ bin/flink run -c wikiedits.WikipediaAnalysis path/to/wikiedits-0.1.jar 如果一切按计划进行，那么该命令的输出应该与此类似： 03/08/2016 15:09:27 Job execution switched to status RUNNING. 03/08/2016 15:09:27 Source: Custom Source(1/1) switched to SCHEDULED 03/08/2016 15:09:27 Source: Custom Source(1/1) switched to DEPLOYING 03/08/2016 15:09:27 Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, AggregateFunction$3, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/1) switched from CREATED to SCHEDULED 03/08/2016 15:09:27 Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, AggregateFunction$3, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/1) switched from SCHEDULED to DEPLOYING 03/08/2016 15:09:27 Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, AggregateFunction$3, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/1) switched from DEPLOYING to RUNNING 03/08/2016 15:09:27 Source: Custom Source(1/1) switched to RUNNING 您可以看到各个算子如何开始运行。我们这里只有两个，因为 window 之后的算子由于性能原因而折叠成一个操作。在Flink，我们称之为 算子链 。 您可以通过使用 Kafka console consumer 检查Kafka Topic来观察程序的输出： bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic wiki-result 您还可以查看在 http：// localhost：8081上 运行的Flink仪表板。您将看到群集资源和正在运行的作业的概述： 如果单击正在运行的作业，您将获得一个视图，您可以在其中检查单个操作，例如，查看已处理元素的数量：","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-flink-datastream-api.html","loc":"https://jiang-hao.com/articles/2019/big-data-flink-datastream-api.html"},{"title":"深入理解大数据之——Lambda架构","text":"传统系统的问题 \"我们正在从IT时代走向DT时代(数据时代)。IT和DT之间，不仅仅是技术的变革，更是思想意识的变革，IT主要是为自我服务，用来更好地自我控制和管理，DT则是激活生产力，让别人活得比你好\" ——阿里巴巴董事局主席马云。 数据量从M的级别到G的级别到现在T的级、P的级别。数据量的变化数据管理系统（DBMS）和数仓系统（DW）也在悄然的变化着。 传统应用的数据系统架构设计时，应用直接访问数据库系统。当用户访问量增加时，数据库无法支撑日益增长的用户请求的负载时，从而导致数据库服务器无法及时响应用户请求，出现超时的错误。出现这种情况以后，在系统架构上就采用下图的架构，在数据库和应用中间过一层缓冲隔离，缓解数据库的读写压力。 然而，当用户访问量持续增加时，就需要考虑读写分离技术（Master－Slave）架构则如下图，分库分表技术。现在，架构变得越来越复杂了，增加队列、分区、复制等处理逻辑。应用程序需要了解数据库的schema，才能访问到正确的数据。 商业现实已经发生了变化，所以现在更快做出的决定更有价值。除此之外，技术也在不断发展。Kafka，Storm，Trident，Samza，Spark，Flink，Parquet，Avro，Cloud providers等都是工程师和企业广泛采用的流行语。因此，现代基于Hadoop的M/R管道（使用Kafka，Avro和数据仓库等现代二进制格式，即Amazon Redshift，用于临时查询）可能采用以下方式： 这看起来相当不错，但它仍然是一种传统的批处理方式，具有所有已知的缺点，主要原因是客户端的数据在批处理花费大量时间完成之前的数据处理时，新的数据已经进入而导致数据过时。 Lambda架构简介 对低成本规模化的需求促使人们开始使用分布式文件系统，例如 HDFS和基于批量数据的计算系统（MapReduce 作业）。但是这种系统很难做到低延迟。用 Storm 开发的实时流处理技术可以帮助解决延迟性的问题，但并不完美。其中的一个原因是，Storm 不支持 exactly-once 语义，因此不能保证状态数据的正确性，另外它也不支持基于事件时间的处理。有以上需求的用户不得不在自己的应用程序代码中加入这些功能。后来出现了一种混合分析的方法，它将上述两个方案结合起来，既保证低延迟，又保障正确性。这个方法被称作 Lambda 架构，它通过批量 MapReduce作业提供了虽有些延迟但是结果准确的计算，同时通过Storm将最新数据的计算结果初步展示出来。 Lambda架构是由Storm的作者Nathan Marz提出的一个实时大数据处理框架。Marz在Twitter工作期间开发了著名的实时大数据处理框架Storm，Lambda架构是其根据多年进行分布式大数据系统的经验总结提炼而成。Lambda架构的目标是设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。Lambda架构整合离线计算和实时计算，融合不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，可集成Hadoop，Kafka，Storm，Spark，Hbase等各类大数据组件。 Lambda架构关键特性 Marz认为大数据系统应具有以下的关键特性： Robust and fault-tolerant（容错性和鲁棒性）：对大规模分布式系统来说，机器是不可靠的，可能会当机，但是系统需要是健壮、行为正确的，即使是遇到机器错误。除了机器错误，人更可能会犯错误。在软件开发中难免会有一些Bug，系统必须对有Bug的程序写入的错误数据有足够的适应能力，所以比机器容错性更加重要的容错性是人为操作容错性。对于大规模的分布式系统来说，人和机器的错误每天都可能会发生，如何应对人和机器的错误，让系统能够从错误中快速恢复尤其重要。 Low latency reads and updates（低延时）：很多应用对于读和写操作的延时要求非常高，要求对更新和查询的响应是低延时的。 Scalable（横向扩容）：当数据量/负载增大时，可扩展性的系统通过增加更多的机器资源来维持性能。也就是常说的系统需要线性可扩展，通常采用scale out（通过增加机器的个数）而不是scale up（通过增强机器的性能）。 General（通用性）：系统需要能够适应广泛的应用，包括金融领域、社交网络、电子商务数据分析等。 Extensible（可扩展）：需要增加新功能、新特性时，可扩展的系统能以最小的开发代价来增加新功能。 Allows ad hoc queries（方便查询）：数据中蕴含有价值，需要能够方便、快速的查询出所需要的数据。 Minimal maintenance（易于维护）：系统要想做到易于维护，其关键是控制其复杂性，越是复杂的系统越容易出错、越难维护。 Debuggable（易调试）：当出问题时，系统需要有足够的信息来调试错误，找到问题的根源。其关键是能够追根溯源到每个数据生成点。 数据系统的本质 为了设计出能满足前述的大数据关键特性的系统，我们需要对数据系统有本质性的理解。我们可将数据系统简化为： 数据系统 = 数据 + 查询 从而从数据和查询两方面来认识大数据系统的本质。 数据的特性： when & what 我们先从\"数据\"的特性谈起。数据是一个不可分割的单位，数据有两个关键的性质：When和What。 When 是指数据是与时间相关的，数据一定是在某个时间点产生的。比如Log日志就隐含着按照时间先后顺序产生的数据，Log前面的日志数据一定先于Log后面的日志数据产生；消息系统中消息的接受者一定是在消息的发送者发送消息后接收到的消息。相比于数据库，数据库中表的记录就丢失了时间先后顺序的信息，中间某条记录可能是在最后一条记录产生后发生更新的。对于分布式系统，数据的时间特性尤其重要。分布式系统中数据可能产生于不同的系统中，时间决定了数据发生的全局先后顺序。比如对一个值做算术运算，先+2，后 3，与先 3，后+2，得到的结果完全不同。数据的时间性质决定了数据的全局发生先后，也就决定了数据的结果。 What 是指数据的本身。由于数据跟某个时间点相关，所以数据的本身是不可变的(immutable)，过往的数据已经成为事实（Fact），你不可能回到过去的某个时间点去改变数据事实。这也就意味着对数据的操作其实只有两种：读取已存在的数据和添加更多的新数据。采用数据库的记法，CRUD就变成了CR，Update和Delete本质上其实是新产生的数据信息，用C来记录。 数据的存储：Store Everything Rawly and Immutably 根据上述对数据本质特性的分析，Lamba架构中对数据的存储采用的方式是：数据不可变，存储所有数据。 通过采用不可变方式存储所有的数据，可以有如下好处： 简单。采用不可变的数据模型，存储数据时只需要简单的往主数据集后追加数据即可。相比于采用可变的数据模型，为了Update操作，数据通常需要被索引，从而能快速找到要更新的数据去做更新操作。 应对人为和机器的错误。前述中提到人和机器每天都可能会出错，如何应对人和机器的错误，让系统能够从错误中快速恢复极其重要。不可变性（Immutability）和重新计算（Recomputation）则是应对人为和机器错误的常用方法。采用可变数据模型，引发错误的数据有可能被覆盖而丢失。相比于采用不可变的数据模型，因为所有的数据都在，引发错误的数据也在。修复的方法就可以简单的是遍历数据集上存储的所有的数据，丢弃错误的数据，重新计算得到Views。重新计算的关键点在于利用数据的时间特性决定的全局次序，依次顺序重新执行，必然能得到正确的结果。 当前业界有很多采用不可变数据模型来存储所有数据的例子。比如分布式数据库Datomic，基于不可变数据模型来存储数据，从而简化了设计。分布式消息中间件Kafka，基于Log日志，以追加append-only的方式来存储消息。 查询的本质 查询是个什么概念？Marz给查询如下一个简单的定义： Query = Function(All Data) 该等式的含义是：查询是应用于数据集上的函数。该定义看似简单，却几乎囊括了数据库和数据系统的所有领域：RDBMS、索引、OLAP、OLTP、MapReduce、EFL、分布式文件系统、NoSQL等都可以用这个等式来表示。 让我们进一步深入看一下函数的特性，从而挖掘函数自身的特点来执行查询。 有一类称为Monoid特性的函数应用非常广泛。Monoid的概念来源于范畴学（Category Theory），其一个重要特性是满足结合律。如整数的加法就满足Monoid特性： (a+b)+c=a+(b+c) 不满足Monoid特性的函数很多时候可以转化成多个满足Monoid特性的函数的运算。如多个数的平均值Avg函数，多个平均值没法直接通过结合来得到最终的平均值，但是可以拆成分母除以分子，分母和分子都是整数的加法，从而满足Monoid特性。 Monoid的结合律特性在分布式计算中极其重要，满足Monoid特性意味着我们可以将计算分解到多台机器并行运算，然后再结合各自的部分运算结果得到最终结果。同时也意味着部分运算结果可以储存下来被别的运算共享利用（如果该运算也包含相同的部分子运算），从而减少重复运算的工作量。 Lambda的三层架构 有了上面对数据系统本质的探讨，下面我们来讨论大数据系统的关键问题：如何实时地在任意大数据集上进行查询？大数据再加上实时计算，问题的难度比较大。 最简单的方法是，根据前述的查询等式 Query = Function(All Data) ，在全体数据集上在线运行查询函数得到结果。但如果数据量比较大，该方法的计算代价太大了，所以不现实。 Lambda架构通过分解的三层架构来解决该问题：Batch Layer，Speed Layer和Serving Layer。 Batch Layer 理想状态下，任何数据访问都可以从表达式Query= function(all data)开始，但是，若数据达到相当大的一个级别（例如PB），且还需要支持实时查询时，就需要耗费非常庞大的资源。一个解决方式是预运算查询函数（precomputed query function）。书中将这种预运算查询函数称之为Batch View（A），这样当需要执行查询时，可以从Batch View中读取结果。这样一个预先运算好的View是可以建立索引的，因而可以支持随机读取（B）。于是系统就变成： （A）batch view = function(all data) （B）query = function(batch view) 在Lambda架构中，实现（A）batch view =function(all data)的部分称之为Batch Layer。Batch Layer的功能主要有两点： 存储master dataset, 这是一个不变的持续增长的数据集 在master dataset上预先计算查询函数，构建查询所对应的View 存储数据集 根据前述对数据When&What特性的讨论，Batch Layer采用不可变模型存储所有的数据。因为数据量比较大，可以采用HDFS之类的大数据储存方案。如果需要按照数据产生的时间先后顺序存放数据，可以考虑如InfluxDB之类的时间序列数据库（TSDB）存储方案。 构建查询View 上面说到根据等式Query = Function(All Data)，在全体数据集上在线运行查询函数得到结果的代价太大。但如果我们预先在数据集上计算并保存查询函数的结果，查询的时候就可以直接返回结果（或通过简单的加工运算就可得到结果）而无需重新进行完整费时的计算了。这儿可以把Batch Layer看成是一个数据预处理的过程。我们把针对查询预先计算并保存的结果称为View，View是Lambda架构的一个核心概念，它是针对查询的优化，通过View即可以快速得到查询结果。 显然，batch view是一个批处理过程，如采用Hadoop或spark支持的map－reduce方式。采用这种方式计算得到的每个view都支持再次计算，且每次计算的结果都相同。Batch Layer的工作可以简单的用如下伪码表示： 该工作看似简单，实质非常强大。任何人为或机器发生的错误，都可以通过修正错误后重新计算来恢复得到正确结果。 对View的理解 View是一个和业务关联性比较大的概念，View的创建需要从业务自身的需求出发。一个通用的数据库查询系统，查询对应的函数千变万化，不可能穷举。但是如果从业务自身的需求出发，可以发现业务所需要的查询常常是有限的。Batch Layer需要做的一件重要的工作就是根据业务的需求，考察可能需要的各种查询，根据查询定义其在数据集上对应的Views。 Batch Layer的Immutable data模型和Views 如下图agent id＝50023的人，在10:00:06分的时候，状态是calling，在10:00:10的时候状态为waiting。在传统的数据库设计中，直接后面的纪录覆盖前面的纪录，而在Immutable数据模型中，不会对原有数据进行更改，而是采用插入修改纪录的形式更改历史纪录。 上文所提及的View是上图中预先计算得到的相关视图，例如： 2016-06-21 当天所有上线的agent数，每条热线、公司下上线的Agent数。根据业务需要，预先计算出结果。此过程相当于传统数仓建模的应用层，应用层也是根据业务场景，预先加工出的view。 Speed Layer Batch Layer可以很好的处理离线数据，但有很多场景数据不断实时生成，并且需要实时查询处理。Speed Layer正是用来处理增量的实时数据。 Speed Layer和Batch Layer比较类似，对数据进行计算并生成Realtime View，其主要区别在于： Speed Layer处理的数据是最近的增量数据流，Batch Layer处理的全体数据集 Speed Layer为了效率，接收到新数据时不断更新Realtime View，而Batch Layer根据全体离线数据集直接得到Batch View。Speed Layer是一种增量计算，而非重新计算（recomputation） Speed Layer因为采用增量计算，所以延迟小，而Batch Layer是全数据集的计算，耗时比较长 综上所诉，Speed Layer是Batch Layer在实时性上的一个补充。Speed Layer可总结为： （C）realtime view＝function(realtime view，new data) 注意，realtime view是基于新数据和已有的realtime view。 Lambda架构将数据处理分解为Batch Layer和Speed Layer有如下优点： 容错性。Speed Layer中处理的数据也不断写入Batch Layer，当Batch Layer中重新计算的数据集包含Speed Layer处理的数据集后，当前的Realtime View就可以丢弃，这也就意味着Speed Layer处理中引入的错误，在Batch Layer重新计算时都可以得到修正。这点也可以看成是CAP理论中的最终一致性（Eventual Consistency）的体现。 复杂性隔离。Batch Layer处理的是离线数据，可以很好的掌控。Speed Layer采用增量算法处理实时数据，复杂性比Batch Layer要高很多。通过分开Batch Layer和Speed Layer，把复杂性隔离到Speed Layer，可以很好的提高整个系统的鲁棒性和可靠性。 如前所述，任何传入查询都必须通过合并来自批量视图和实时视图的结果来得到答案，因此这些视图需要满足Monoid的结合律特性。需要注意的一点是，实时视图是以前的实时视图和新数据增量的函数，因此可以使用增量算法。批处理视图是所有数据的函数，因此应该在那里使用重算算法。 Serving Layer Lambda架构的Serving Layer用于响应用户的查询请求，合并Batch View和Realtime View中的结果数据集到最终的数据集。 这儿涉及到数据如何合并的问题。前面我们讨论了查询函数的Monoid性质，如果查询函数满足Monoid性质，即满足结合律，只需要简单的合并Batch View和Realtime View中的结果数据集即可。否则的话，可以把查询函数转换成多个满足Monoid性质的查询函数的运算，单独对每个满足Monoid性质的查询函数进行Batch View和Realtime View中的结果数据集合并，然后再计算得到最终的结果数据集。另外也可以根据业务自身的特性，运用业务自身的规则来对Batch View和Realtime View中的结果数据集合并。 综上所诉，Serving Layer采用如下等式表示： （D）query ＝ function(batch view, realtime view) Lambda架构组件选型 上面分别讨论了Lambda架构的三层：Batch Layer，Speed Layer和Serving Layer。总结下来，Lambda架构就是如下的三个等式： batch view = function(all data) realtime view = function(realtime view, new data) query = function(batch view, realtime view) 下图给出了Lambda架构的一个完整视图和流程。 数据流进入系统后，同时发往Batch Layer和Speed Layer处理。Batch Layer以不可变模型离线存储所有数据集，通过在全体数据集上不断重新计算构建查询所对应的Batch Views。Speed Layer处理增量的实时数据流，不断更新查询所对应的Realtime Views。Serving Layer响应用户的查询请求，合并Batch View和Realtime View中的结果数据集到最终的数据集。 组件选型 下图给出了Lambda架构中各组件在大数据生态系统中和阿里集团的常用组件。数据流存储选用不可变日志的分布式系统Kafka、TT、Metaq；BatchLayer数据集的存储选用Hadoop的HDFS或者阿里云的ODPS；BatchView的加工采用MapReduce；BatchView数据的存储采用Mysql（查询少量的最近结果数据）、Hbase（查询大量的历史结果数据）。SpeedLayer采用增量数据处理Storm、Flink；RealtimeView增量结果数据集采用内存数据库Redis。 另一个实现版本： 根据batch layer的特点，具备存储(HDFS)和计算(MapReduce)的Hadoop显然是第一人选，而batch view 可以是hadoop本身的hdfs 或者基于hdfs的所构建的类似hive那样的仓库，speed layer因为时效性的影响，采用实时流式处理系统，例如strom或者spark streaming, 而speed view 可以存在HBase 或者其他类似的Nosql数据库。server layer 提供用户查询的方法，采用facebook 开源的Impala，统一入口查询。或者自己实现hive和HBase统一查询。这是两年前的文章，当时spark 还没那么火，现在看来spark可以直接作为batch和speed层的替代者了。 选型原则 Lambda架构是个通用框架，各个层选型时不要局限时上面给出的组件，特别是对于View的选型。从我对Lambda架构的实践来看，因为View是个和业务关联性非常大的概念，View选择组件时关键是要根据业务的需求，来选择最适合查询的组件。不同的View组件的选择要深入挖掘数据和计算自身的特点，从而选择出最适合数据和计算自身特点的组件，同时不同的View可以选择不同的组件。 总结 在过去Lambda数据架构成为每一个公司大数据平台必备的架构，它解决了一个公司大数据批量离线处理和实时数据处理的需求。一个典型的Lambda架构如下： 数据从底层的数据源开始，经过各种各样的格式进入大数据平台，在大数据平台中经过Kafka、Flume等数据组件进行收集，然后分成两条线进行计算。一条线是进入流式计算平台（例如 Storm、Flink或者Spark Streaming），去计算实时的一些指标；另一条线进入批量数据处理离线计算平台（例如Mapreduce、Hive，Spark SQL），去计算T+1的相关业务指标，这些指标需要隔日才能看见。 Lambda架构经历多年的发展，其优点是稳定，对于实时计算部分的计算成本可控，批量处理可以用晚上的时间来整体批量计算，这样把实时计算和离线计算高峰分开，这种架构支撑了数据行业的早期发展，但是它也有一些致命缺点，并在大数据3.0时代越来越不适应数据分析业务的需求。缺点如下： 实时与批量计算结果不一致引起的数据口径问题 ：因为批量和实时计算走的是两个计算框架和计算程序，算出的结果往往不同，经常看到一个数字当天看是一个数据，第二天看昨天的数据反而发生了变化。 批量计算在计算窗口内无法完成 ：在IOT时代，数据量级越来越大，经常发现夜间只有4、5个小时的时间窗口，已经无法完成白天20多个小时累计的数据，保证早上上班前准时出数据已成为每个大数据团队头疼的问题。 开发和维护的复杂性问题 ：Lambda 架构需要在两个不同的 API（application programming interface，应用程序编程接口）中对同样的业务逻辑进行两次编程：一次为批量计算的ETL系统，一次为流式计算的Streaming系统。针对同一个业务问题产生了两个代码库，各有不同的漏洞。这种系统实际上非常难维护 服务器存储大 ：数据仓库的典型设计，会产生大量的中间结果表，造成数据急速膨胀，加大服务器存储压力。 也就是由于Lambda架构的以上局限性，Kappa应运而生，它比Lambda架构更加灵活和精简，具体将另文介绍。 Kappa架构：","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-lambda-architecture.html","loc":"https://jiang-hao.com/articles/2019/big-data-lambda-architecture.html"},{"title":"Flink 分布式运行时环境","text":"Tasks and Operator Chains 对于分布式执行，Flink将多个算子子任务链串联成任务。每个任务由一个线程执行。将算子链接到任务是一项有用的优化：它可以减少线程到线程切换和缓冲的开销，并在降低延迟的同时提高整体吞吐量。可以配置链接行为; 有关详细信息，请参阅 链接文档 。 下图中的示例数据流由五个子任务执行，因此具有五个并行线程。 Job Managers, Task Managers, Clients Flink运行时包含两种类型的进程： JobManagers （也称为 masters ）协调分布式执行。他们安排任务，协调检查点，协调故障恢复等。 Job Manager总是至少有一个。高可用性设置将具有多个JobManagers，其中一个始终是 领导者 ，其他处于 待机状态 。 TaskManagers （也叫 workers ）执行dataflow的 任务 （或者更具体地说应该是子任务），以及缓冲和交换data streams 。 必须始终至少有一个TaskManager。 JobManagers和TaskManagers可以通过多种方式启动：作为 独立集群 直接在计算机上，在容器中，或由 YARN 或 Mesos 等资源框架管理。TaskManagers连接到JobManagers，宣布自己可用，并被分配工作。 Client 不是运行时和程序执行的一部分，而是被用来准备和发送dataflow到JobManager。之后，客户端可以断开连接或保持连接以接收进度报告。客户端既可以作为触发执行的Java / Scala程序的一部分运行，也可以在命令行进程 ./bin/flink run ... 中运行。 Task Slots and Resources 每个worker（TaskManager）都是一个 JVM进程 ，可以在不同的线程中执行一个或多个子任务。为了控制一个worker接受的任务数量，每个worker都有所谓的 task slots （至少一个）。 每个 task slot 代表TaskManager的一个固定资源子集。例如，具有3个task slot的TaskManager会将其1/3的托管内存分配于每个task slot。资源切片意味着子任务不会与来自托管内存的其他作业的子任务竞争资源，相反其具有一定量的预留托管内存。请注意，这里没有CPU隔离; 当前task slots只分隔任务的托管内存。 通过调整task slot的数量，用户可以定义子任务如何相互隔离。每个TaskManager有一个slot意味着每个任务组在一个单独的JVM中运行（比如也就可以在一个单独的容器中启动）。拥有多个slots意味着更多子任务共享同一个JVM。同一JVM中的任务共享TCP连接（通过多路复用）和心跳消息。它们还可以共享数据集和数据结构，从而减少每任务开销。 默认情况下，Flink允许子任务共享slots，即使它们是不同任务的子任务，只要它们来自同一个job。结果是一个slot可以承载某个job的整个pipeline。允许这种 slot 共享有两个主要好处： Flink集群需要与job中使用的最高并行度一样多的task slot。无需计算程序总共包含多少任务（具有不同的并行性）。 更容易获得更好的资源利用率。没有slot共享，非密集 source/ map（） 子任务将占用与资源密集型 window 子任务一样多的资源。通过slot共享，将示例中的基本并行性从2增加到6可以充分利用切片后的资源，同时确保繁重的子任务在TaskManagers之间公平分配。 该API还包括可用于防止不期望的slot共享发生的 resource group 机制。 根据经验，一个很好的默认task slots数就是CPU核心数。使用超线程，每个slot则需要2个或更多硬件线程上下文。 State Backends 存储键/值索引的确切数据结构取决于所选的 状态后端 。一种状态后端将数据存储在内存中的hash map中，另一种状态后端使用 RocksDB 作为键/值存储。除了定义保存状态的数据结构之外，状态后端还实现逻辑以获取键/值状态的时间点快照，并将该快照存储为一个checkpoint的一部分。 Savepoints 用Data Stream API编写的程序可以从 savepoint 恢复执行。savepoint允许更新程序和Flink群集，而不会丢失任何状态。 savepoints 是 手动触发的checkpoints ，它 捕获 程序的快照并将其写入状态后端。他们依靠常规的checkpointing机制。在执行期间，程序会定期在工作节点上创建快照并生成检查点。对于恢复，仅需要最后完成的检查点；并且一旦完成新检查点就可以安全地丢弃旧检查点。 保存点与这些定期检查点类似，不同之处在于它们 由用户触发， 并且在较新的检查点完成时 不会自动过期 。可以 从命令行 创建保存点，也可以在通过 REST API 取消作业时创建。","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-flink-distributed-runtime.html","loc":"https://jiang-hao.com/articles/2019/big-data-flink-distributed-runtime.html"},{"title":"Flink FAQ","text":"Apache Flink仅用于（近）实时处理用例吗？ Flink是一个非常通用的系统，用于数据处理和数据驱动的应用程序， 数据流 作为核心构建块。这些数据流可以是实时数据流或存储的历史数据流。例如，在Flink的视图中，文件是存储的字节流。因此，Flink支持实时数据处理和应用程序，以及批处理应用程序。 流可以是 无界的 （没有结束，事件不断发生）或受 限制 （流有开始和结束）。例如，来自消息队列的Twitter馈送或事件流通常是无界的流，而来自文件的字节流是有界流。 如果一切都是流，为什么Flink中有DataStream和DataSet API？ 有界流通常比无界流更高效。在（近）实时处理无限事件流需要系统能够立即对事件起作用并产生中间结果（通常具有低延迟）。处理有界流通常不需要产生低延迟结果，因为无论如何数据都是旧的（相对而言）。这允许Flink以简单且更高效的方式处理数据。 DataStream API 捕获无界和有界的流的连续处理，以支持低等待时间的结果以及对事件和时间（包括事件时间）灵活反应的模型。 DataSet API 具有加快有界的数据流的处理的技术。将来，社区计划将这些优化与DataStream API中的技术相结合。 Flink如何与Hadoop栈相关联？ Flink独立于 Apache Hadoop， 并且在没有任何Hadoop依赖性的情况下运行。 但是，Flink与许多Hadoop组件集成得非常好，例如 HDFS ， YARN 或 HBase 。与这些组件一起运行时，Flink可以使用HDFS读取数据，或写入结果和检查点/快照。Flink可以通过YARN轻松部署，并与YARN和HDFS Kerberos安全模块集成。 Flink可运行的其他栈是什么？ 用户在 Kubernetes ， Mesos ， Docker 上运行Flink ，甚至作为独立服务运行。 使用Flink有哪些先决条件？ 您需要 Java 8 来运行Flink作业/应用程序。 Scala API（可选）基于Scala 2.11。 Apache ZooKeeper 需要高度可用且没有单点故障的设置。 对于可以从故障中恢复的高可用流处理设置，Flink需要某种形式的分布式存储用于检查点（HDFS / S3 / NFS / SAN / GFS / Kosmos / Ceph / ...）。 Flink支持多大的规模？ 用户可在非常小的配置（少于5个节点）和1000个节点以及TB级的状态上运行Flink作业。 Flink是否仅限于内存数据集？ 对于DataStream API，Flink支持大于内存的状态来配置RocksDB状态后端。 对于DataSet API，所有操作（delta迭代除外）都可以扩展到主内存之外。","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-flink-FAQ.html","loc":"https://jiang-hao.com/articles/2019/big-data-flink-FAQ.html"},{"title":"Flink Dataflow 编程模型","text":"Apache Flink是一个用于分布式流和批处理数据处理的开源平台。Flink的核心是流数据流引擎，为数据流上的分布式计算提供数据分发，通信和容错。Flink基于流引擎之上构建批处理，覆加本地迭代支持，内存托管和程序优化。 抽象层次 Flink提供不同级别的抽象来开发流/批处理应用程序。 最低级抽象只提供 stateful streaming 。它通过 Process Function 嵌入到 DataStream API中 。它允许用户自由处理来自一个或多个流的事件，并使用一致的容错 状态 。此外，用户可以注册事件时间和处理时间回调，允许程序实现复杂的计算。 在实践中，大多数应用程序不需要上述低级抽象，而是针对 Core API 编程， 如 DataStream API （有界/无界流）和 DataSet API （有界数据集）。这些流畅的API提供了用于数据处理的通用构建块，例如各种形式的用户指定的转换，连接，聚合，窗口，状态等（transformations, joins, aggregations, windows, state, etc.）。在这些API中处理的数据类型在相应的编程语言中表示为类。 低级 Process Function 与 DataStream API 集成在一起，因此只能对某些操作进行低级抽象。 DataSet API 提供有限数据集额外的原语支持，如循环/迭代。 Table API 是以 tables 为中心的声明性DSL ，此处的表是动态改变的表（当表示流时）。 Table API 遵循（扩展）关系模型：表有一个模式连接（类似于在关系数据库中的表）和API提供可比的操作，如select, project, join, group-by, aggregate等。Table API程序以声明方式定义 应该执行的逻辑操作， 而不是准确指定 操作代码的外观 。虽然Table API可以通过各种类型的用户定义函数进行扩展，但它的表现力不如 Core API ，但使用更简洁（编写的代码更少）。此外，Table API程序还会通过优化程序，在执行之前应用优化规则。 可以在 tables 和 DataStream / DataSet 之间无缝转换，允许程序混合 Table API 以及 DataStream 和 DataSet API。 Flink提供的最高级抽象是 SQL 。这种抽象在语义和表达方面类似于 Table API ，但是将程序表示为SQL查询表达式。 SQL 抽象与Table API紧密地相互作用，并且SQL语句可以作用在 Table API 定义的 tables 上。 程序和数据流 Flink程序的基本构建块是 streams 和 transformations 。（请注意，Flink的DataSet API中使用的DataSets其实内部也是streams - 稍后会详细介绍。）从概念上讲， stream 是（可能永无止境的）数据记录流，而 transformation 是将一个或多个流作为输入，并产生一个或多个输出流作为结果的操作。 执行时，Flink程序映射为 streaming dataflows ，由 流 和转换 算子 组成。每个 dataflow 都以一个或多个 sources 开头，并以一个或多个 sinks 结束。数据流类似于任意 有向无环图 （DAG） 。尽管通过 迭代 结构允许特殊形式的循环 ，但为了简单起见，我们将在大多数情况下不将其考虑其中。 通常，程序中的transformations与dataflow中的operators之间存在一对一的对应关系。但是，有时一个转换可能包含多个转换算子。 Sources和Sinks在 流连接器 和 批处理连接器 文档中有介绍。 DataStream算子 和 DataSet转换 中记录了 转换 有关介绍。 并行数据流 Flink中的程序本质上是并行和分布式的。在执行期间， stream 具有一个或多个 stream partitions ，并且每个 算子 具有一个或多个 算子子任务 。算子子任务彼此独立，并且可以在不同的线程中执行，并且可能在不同的机器或容器上执行。 算子子任务的数量是该特定算子的 并行 度。流的并行度始终是其生成算子的并行度。同一程序的不同算子可能具有不同的并行级别。 流可以 以一对一 （或 转发 ）模式或以 重新分发 模式在两个operator之间传输数据： 一对一 流（例如，在上图中的 Source 和 map（） 算子之间）保留元素的分区和排序。这意味着 map（） 算子的subtask [1] 将以 Source 算子的subtask [1]生成的相同顺序的相同元素作为输入。 重新分配 流（在上面的 map（） 和 keyBy / window 之间，以及 keyBy / window 和 Sink之间 ）重新分配流。每个 算子子任务 将数据发送到不同的目标子任务，具体取决于所选的transformation。实例是 keyBy（） （其通过散列密钥重新分区）， broadcast（） ，或 rebalance（） （随机地重新分区）。在 rebalance 交换中，元素之间的排序仅保留在每对发送和接收子任务中（例如， map（）的 子任务[1] 和子任务[2] keyBy / window ）。因此，在此示例中，保留了每个密钥内的排序，但并行性确实引入了关于不同密钥的聚合结果到达接收器的顺序的非确定性。 有关配置和控制并行性的详细信息，请参阅 并行执行 的文档。 窗口 聚合事件（例如，计数，求和）在流上的工作方式与批处理方式不同。例如，不可能计算流中的所有元素，因为流通常是无限的（无界）。相反，流上的聚合（计数，总和等）由 窗口 限定，例如 \"在最后5分钟内计数\" 或 \"最后100个元素的总和\" 。 Windows可以是 时间驱动的 （例如：每30秒）或 数据驱动 （例如：每100个元素）。人们通常区分不同类型的窗口，例如 翻滚窗口 （没有重叠）， 滑动窗口 （具有重叠）和 会话窗口 （由不活动间隙打断）。 可以在此 博客文章中 找到更多窗口示例。更多详细信息在 窗口文档中 。 时间 当在流程序中引用时间（例如定义窗口）时，可以参考不同的时间概念： 事件时间 是创建 事件的时间 。它通常由事件中的时间戳描述，例如由生产传感器或生产服务附加。Flink通过 时间戳分配器 访问事件时间戳。 摄取时间 是事件在Source算子处输入Flink数据流的时间。 处理时间 是执行基于时间的操作的每个算子的本地时间。 有关如何处理时间的更多详细信息，请参阅 事件时间文档 。 有状态的操作 虽然数据流中的许多操作只是一次查看一个单独的 事件 （例如事件解析器），但某些操作会记住多个事件（例如窗口算子）的信息。这些操作称为 有状态 。 状态操作的状态保持在可以被认为是嵌入式键/值存储的状态中。状态被分区并严格地与有状态算子读取的流一起分发。因此，只有在 keyBy（） 函数之后才能在 键控流 上访问键/值状态，并且限制为与当前事件的键相关联的值。对齐流和状态的密钥可确保所有状态更新都是本地操作，从而保证一致性而无需事务开销。此对齐还允许Flink重新分配状态并透明地调整流分区。 有关更多信息，请参阅有关 状态 的文档。 容错检查点 Flink使用 流重放 和 检查点 的组合实现容错。检查点与每个输入流中的特定点以及每个算子的对应状态相关。通过恢复算子的状态并从检查点重放事件，可以从检查点恢复流数据流，同时保持一致性 （恰好一次处理语义） 。 检查点间隔是在执行期间用恢复时间（需要重放的事件的数量）来折衷容错开销的手段。 容错内部 的描述提供了有关Flink如何管理检查点和相关主题的更多信息。有关启用和配置检查点的详细信息，请参阅 检查点API文档 。 批量流媒体 Flink以流程序的特殊情况执行 批处理程序 ，其中流是有界的（有限数量的元素）。 DataSet 在内部视为数据流。因此，上述概念以适用于流程序相同的方式应用于批处理程序，除了少数例外： 批处理程序的容错 不使用检查点(checkpointing)。而是通过完全重放流来进行恢复。这是可行的，因为输入的有限性。这会使成本更多地用于恢复，但使常规处理更轻松，因为它避免了检查点。 DataSet API中的有状态操作使用简化的内存/核外数据结构，而不是键/值索引。 DataSet API引入了特殊的同步（超级步骤）迭代，这些迭代只能在有界流上进行。有关详细信息，请查看 迭代文档 。","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-flink-programming-model.html","loc":"https://jiang-hao.com/articles/2019/big-data-flink-programming-model.html"},{"title":"Flink用例","text":"Apache Flink因其丰富的功能集而成为开发和运行多种不同类型应用程序的绝佳选择。Flink的功能包括支持流和批处理，复杂的状态管理，事件时间处理语义以及状态的精确一次一致性保证。此外，Flink可以部署在各种资源提供者（如YARN，Apache Mesos和Kubernetes）上，也可以作为裸机硬件上的独立群集。配置为高可用性，Flink没有单点故障。Flink已被证明可扩展到数千个核心和TB级的应用程序状态，提供高吞吐量和低延迟，并为世界上最苛刻的流处理应用程序提供支持。 下面，我们将探讨由Flink提供支持的最常见类型的应用程序，并指出实际示例。 事件驱动的应用程序 数据分析应用 数据管道应用 事件驱动的应用程序 什么是事件驱动的应用程序？ 事件驱动的应用程序是一个有状态的应用程序，它从一个或多个事件流中提取事件，并通过触发计算，状态更新或外部操作对传入事件做出反应。 事件驱动的应用程序是传统应用程序设计的演变。传统应用一般具有独立的计算和数据存储层，在此体系结构中，应用程序从远程事务数据库读取数据并将数据持久化。 相反，事件驱动的应用程序基于有状态流处理应用程序。在这种设计中，数据和计算是共同定位的，即本地（内存或磁盘）数据访问。通过定期将检查点写入远程持久存储来实现容错。下图描绘了传统应用程序体系结构和事件驱动应用程序之间的差异。 事件驱动的应用程序有哪些优点？ 事件驱动的应用程序不是查询远程数据库，而是在本地访问其数据，从而在吞吐量和延迟方面产生更好的性能。远程持久存储的定期检查点可以异步和递增完成。因此，检查点对常规事件处理的影响非常小。但是，事件驱动的应用程序设计提供的不仅仅是本地数据访问。在分层体系结构中，多个应用程序共享同一数据库是很常见的。因此，需要协调数据库的任何更改，例如由于应用程序更新或扩展服务而更改数据布局。由于每个事件驱动的应用程序都负责自己的数据，因此更改数据表示或扩展应用程序只需要较少的协调。 Flink如何支持事件驱动的应用程序？ 事件驱动应用程序的限制由流处理器处理时间和状态的程度来定义。Flink的许多杰出功能都围绕着这些概念。Flink提供了一组丰富的状态原语，可以管理非常大的数据量（最多几TB），并且具有精确一次性的一致性保证。此外，Flink支持事件时间，高度可定制的窗口逻辑，以及通过 ProcessFunction 实现高级业务逻辑提供的细粒度时间控制。此外，Flink还提供了一个用于复杂事件处理（CEP）的库，用于检测数据流中的模式。 然而，Flink在事件驱动应用程序方面的出色功能是savepoint。保存点是一致的状态快照，可用作兼容应用程序的起点。给定保存点，可以更新应用程序或调整其规模，或者可以启动应用程序的多个版本以进行A / B测试。 什么是典型的事件驱动应用程序？ 欺诈识别 异常检测 基于规则的警报 业务流程监控 Web应用程序（社交网络） 数据分析应用 什么是数据分析应用程序？ 分析工作从原始数据中提取信息和洞察力。传统上，分析在记录事件的有界数据集上作为批量查询或应用程序执行。为了将最新数据合并到分析结果中，必须将其添加到分析的数据集中，并重新运行查询或应用程序。结果将写入存储系统或作为报告发出。 借助先进的流处理引擎，还可以实时地执行分析。流式查询或应用程序不是读取有限数据集，而是摄取实时事件流，并在消耗事件时不断生成和更新结果。结果要么写入外部数据库，要么保持为内部状态。仪表板应用程序可以从外部数据库读取最新结果或直接查询应用程序的内部状态。 Apache Flink支持流式和批量分析应用程序，如下图所示。 流式分析应用程序有哪些优势？ 与批量分析相比，连续流分析的优势不仅限于因消除定期导入和查询执行而从事件到洞察的低得多的延迟。与批量查询相比，流式查询不必处理输入数据中的人为边界，这些边界是由定期导入和输入的有界性质引起的。 另一方面是更简单的应用程序架构。批处理分析管道由若干独立组件组成，以定期调度数据提取和查询执行。可靠地操作这样的管道并非易事，因为一个组件的故障会影响管道的后续步骤。相比之下，在像Flink这样的复杂流处理器上运行的流分析应用程序包含从数据摄取到连续结果计算的所有步骤。因此，它可以依赖于引擎的故障恢复机制。 Flink如何支持数据分析应用程序？ Flink为连续流式传输和批量分析提供了非常好的支持。具体来说，它具有符合ANSI标准的SQL接口，具有用于批处理和流式查询的统一语义。无论是在记录事件的静态数据集上还是在实时事件流上运行，SQL查询都会计算相同的结果。对用户定义函数的丰富支持可确保在SQL查询中执行自定义代码。如果需要更多的自定义逻辑，Flink的DataStream API或DataSet API提供更多的低级控制。此外，Flink的Gelly库为批量数据集上的大规模和高性能图形分析提供算法和构建块。 什么是典型的数据分析应用程序？ 电信网络的质量监控 分析 移动应用程序中 的产品更新和实验评估 对消费者技术中 的实时数据 进行 特别分析 大规模图分析 数据管道应用 什么是数据管道？ 提取 - 转换 - 加载（ETL）是在存储系统之间转换和移动数据的常用方法。通常会定期触发ETL作业，以将数据从事务数据库系统复制到分析数据库或数据仓库。 数据管道与ETL作业具有相似的用途。它们可以转换和丰富数据，并可以将数据从一个存储系统移动到另一个。但是，它们以连续流模式运行，而不是定期触发。因此，他们能够从连续生成数据的源中读取记录，并以低延迟将其移动到目的地。例如，数据管道可能会监视文件系统目录中的新文件，并将其数据写入事件日志。另一个应用程序可能会将事件流实现到数据库，或者逐步构建和优化搜索索引。 下图描述了定期ETL作业和连续数据管道之间的差异。 数据管道有哪些优势？ 连续数据流水线优于周期性ETL作业的明显优势是减少了将数据移动到目的地的延迟。此外，数据管道更通用，可用于更多用例，因为它们能够连续消耗和发送数据。 Flink如何支持数据管道？ Flink的SQL接口（或表API）可以解决许多常见的数据转换或丰富任务，并支持用户定义的函数。通过使用更通用的DataStream API，可以实现具有更高级要求的数据管道。Flink为各种存储系统（如Kafka，Kinesis，Elasticsearch和JDBC数据库系统）提供了丰富的连接器。它还具有连续的文件系统源，用于监视以时间分区方式写入文件的目录和接收器。 什么是典型的数据管道应用？ 电子商务中 的实时搜索索引构建 电子商务中 持续的ETL","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-flink-usecases.html","loc":"https://jiang-hao.com/articles/2019/big-data-flink-usecases.html"},{"title":"Flink入门","text":"一、架构 Apache Flink是一个分布式处理引擎和框架，用于对无界和有界数据流进行状态计算。Flink可在所有常见的集群环境中运行，可以内存级速度和任意规模执行计算。 接下来首先我们阐述Flink的架构。 处理无界和有界数据 任何类型的数据都是作为事件流产生的。信用卡交易，传感器测量，机器日志或网站或移动应用程序上的用户交互，所有这些数据都作为流生成。 数据可以作为 无界 或 有界 流处理。 无界流 有一个开始但没有明确定义的结束。它们不会终止，并且数据在生成时即提供。必须连续处理无界流，即必须在摄取事件后立即处理事件。无法等待所有输入数据到达，因为输入是无界的，并且在任何时间点都不会完成。处理无界数据通常要求以特定顺序摄取事件，例如事件发生的顺序，以便能够推断结果完整性。无界流的处理也称为流处理。 有界流 具有明确定义的开始和结束。可以通过在执行任何计算之前先摄取所有数据的方式来处理有界流。处理有界流不需要有序摄取，因为可以始终对有界数据集进行排序。有界流的处理也称为批处理。 Apache Flink擅长处理无界和有界数据集。 精确控制时间和状态使Flink的运行时能够在无界流上运行任何类型的应用程序。有界流由算法和数据结构内部处理，这些算法和数据结构专为固定大小的数据集而设计，从而产生出色的性能。 随处部署应用程序 Apache Flink是一个分布式系统，需要计算资源才能执行应用程序。Flink可与所有常见的集群资源管理器（Resource Manager, 如 Hadoop YARN ， Apache Mesos 和 Kubernetes）集成， 但也可以设置为作为独立集群运行。 Flink旨在很好地运作以上列出的每个资源管理器。这是通过与资源管理器对应的部署模式实现的，这些模式允许Flink以其惯用方式与每个资源管理器进行交互。 部署Flink应用程序时，Flink会根据应用程序配置的并行性自动识别所需资源，并从资源管理器请求它们。如果发生故障，Flink会通过请求新资源来替换发生故障的容器。提交或控制应用程序的所有通信都通过REST调用进行。这简化了Flink在许多环境中的集成。 以任何规模运行应用程序 Flink旨在以任何规模运行有状态流应用程序。应用程序并行化为数千个在集群中分布和同时执行的任务。因此，应用程序可以利用几乎无限量的CPU，主内存，磁盘和网络IO。而且，Flink很容易保持非常大的应用程序状态。其异步和增量检查点算法确保对处理延迟的影响最小，同时保证\"精确一次\"的状态一致性。 用户报告了 在其生产环境中运行的Flink应用程序 令人印象深刻的可扩展性的数字 ，例如： 应用程序 每天 处理 数万亿个事件 ， 应用程序维护 多个TB的状态 ， 应用程序 在数千个内核的运行 。 利用内存中性能 有状态Flink应用程序针对本地状态访问进行了优化。任务状态始终保留在内存中，如果状态大小超过可用内存，则保存在访问高效的磁盘上数据结构中。因此，任务通过访问本地（通常是内存中）状态来执行所有计算，从而产生非常低的处理延迟。Flink通过定期和异步地将本地状态checkpoint到持久存储来保证在出现故障时的\"精确一次\"的状态一致性。 二、应用 Apache Flink是一个用于对无界和有界数据流进行有状态计算的框架。Flink在不同的抽象级别提供多个API，并为常见用例提供专用库。 在这里，我们介绍Flink易于使用和富有表现力的API和库。 流处理应用的构建元素 可以由流处理框架构建和执行的应用程序的类型由框架控制 流 ， 状态 和 时间 的程度来定义。在下文中，我们描述了流处理应用程序的这些构建块，并解释了Flink处理它们的方法。 流 显然，流是流处理的一个基本元素。但是，流可以具有不同的特征，这些特征会影响流的处理方式。Flink是一个多功能的处理框架，可以处理任何类型的流。 有界 和 无界 流：流可以是无界的或有界的，即固定大小的数据集。Flink具有完美支持处理无界流的成熟功能，同时也有专门的算子来有效地处理有界流。 实时 和 记录 流：所有数据都作为流生成。有两种方法可以处理数据。在生成时实时处理它或将流持久保存到存储系统（例如，文件系统或对象存储库），并在以后处理它。Flink应用程序可以处理记录或实时流。 状态 每个有意义的流应用程序都是有状态的，只有对单个事件进行转换的应用才不需要状态。运行基本业务逻辑的任何应用程序都需要记住事件或中间结果，以便在以后的时间点访问它们，例如在收到下一个事件时或在特定持续时间之后。 应用状态是Flink中的\"一等公民\"。可以通过Flink在状态处理环境中提供的所有功能来确认这一点： 多状态基元 ：Flink为不同的数据结构提供状态基元，例如原子值，列表或映射。开发人员可以根据函数的访问模式选择最有效的状态原语。 可插拔状态后端 ：应用程序状态由可插拔状态后端管理和checkpoint。Flink具有不同的状态后端，可以在内存或 RocksDB 中存储状态， RocksDB 是一种高效的嵌入式磁盘数据存储。也可以插入自定义状态后端。 精确一次的状态一致性 ：Flink的checkpoint和恢复算法可确保在发生故障时应用程序状态的一致性。因此，故障是透明处理的，不会影响应用程序的正确性。 非常大的状态 ：由于其异步和增量检查点算法，Flink能够维持几兆兆字节的应用程序状态。 可扩展的应用程序 ：Flink通过将状态重新分配给更多或更少的workers来支持有状态应用程序的伸缩。 时间 时间是流应用程序的另一个重要组成部分，大多数事件流都具有固有的时间语义，因为每个事件都是在特定时间点生成的。此外，许多常见的流计算都基于时间，比如 windows aggregations, sessionization, pattern detection, 以及time-based joins。流处理的一个重要方面是应用程序如何测量时间，即事件时间和处理时间的差异。 Flink提供了一组丰富的与时间相关的功能。 事件时间模式 ：使用事件时间语义处理流的应用程序根据事件的时间戳计算结果。因此，无论是否处理记录的或实时的事件，事件时间处理都允许准确和一致的结果。 水印支持 ：Flink使用水印来推断事件时间应用中的时间。水印也是一种灵活的机制，可以权衡延迟和结果的完整性。 延迟数据处理 ：当使用水印在事件时间模式下处理流时，可能会在所有相关事件到达之前完成计算。这类事件被称为迟发事件。Flink具有多个选项来处理延迟事件，例如通过侧输出重新路由它们并更新以前完成的结果。 处理时间模式 ：除了事件时间模式之外，Flink还支持处理时间语义，该处理时间语义执行由处理机器的挂钟时间触发的计算。处理时间模式适用于具有严格的低延迟要求、可以容忍近似结果的某些应用。 分层API Flink提供三层API。每个API在简洁性和表达性之间提供不同的权衡，并针对不同的用例。 我们简要介绍每个API，讨论其应用，并显示代码示例。 ProcessFunctions ProcessFunctions 是Flink提供的最具表现力的功能接口。Flink提供ProcessFunction来处理来自一个或两个输入流的单个事件，或被分组在一个窗口中的事件。ProcessFunctions提供对时间和状态的细粒度控制。ProcessFunction可以任意修改其状态并注册将在未来触发回调函数的定时器。因此，ProcessFunctions可以根据许多 有状态事件驱动的应用的 需要实现复杂的每事件业务逻辑。 以下显示了一个 KeyedProcessFunction 对一个 KeyedStream 进行操作，匹配 START 以及 END 事件的示例。当一个 START 事件被接收，则该函数在状态中记住其时间戳并且注册一个4小时的计时器。如果在计时器触发之前收到 END 事件，则该函数计算事件 END 和 START 事件之间的持续时间，清除状态并返回值。否则，计时器只会超时并清除状态。 /** * Matches keyed START and END events and computes the difference between * both elements' timestamps. The first String field is the key attribute, * the second String attribute marks START and END events. */ public static class StartEndDuration extends KeyedProcessFunction < String , Tuple2 < String , String > , Tuple2 < String , Long >> { private ValueState < Long > startTime ; @Override public void open ( Configuration conf ) { // obtain state handle startTime = getRuntimeContext () . getState ( new ValueStateDescriptor < Long > ( \"startTime\" , Long . class )); } /** Called for each processed event. */ @Override public void processElement ( Tuple2 < String , String > in , Context ctx , Collector < Tuple2 < String , Long >> out ) throws Exception { switch ( in . f1 ) { case \"START\" : // set the start time if we receive a start event. startTime . update ( ctx . timestamp ()); // register a timer in four hours from the start event. ctx . timerService () . registerEventTimeTimer ( ctx . timestamp () + 4 * 60 * 60 * 1000 ); break ; case \"END\" : // emit the duration between start and end event Long sTime = startTime . value (); if ( sTime != null ) { out . collect ( Tuple2 . of ( in . f0 , ctx . timestamp () - sTime )); // clear the state startTime . clear (); } default : // do nothing } } /** Called when a timer fires. */ @Override public void onTimer ( long timestamp , OnTimerContext ctx , Collector < Tuple2 < String , Long >> out ) { // Timeout interval exceeded. Cleaning up the state. startTime . clear (); } } 这个例子说明了 KeyedProcessFunction 的表现力，但也强调了它是一个相当冗长的接口。 The DataStream API DataStream API 为诸如窗口等许多常见的流处理操作提供原语。DataStream API可用于Java和Scala，基于如 map() ， reduce() 和 aggregate() 等方法。可以通过扩展接口，或像Java或Scala中lambda函数一样来定义函数。 以下示例显示如何对点击流进行会话化并计算每个会话的点击次数。 // a stream of website clicks DataStream < Click > clicks = ... DataStream < Tuple2 < String , Long >> result = clicks // project clicks to userId and add a 1 for counting . map ( // define function by implementing the MapFunction interface. new MapFunction < Click , Tuple2 < String , Long >> () { @Override public Tuple2 < String , Long > map ( Click click ) { return Tuple2 . of ( click . userId , 1L ); } }) // key by userId (field 0) . keyBy ( 0 ) // define session window with 30 minute gap . window ( EventTimeSessionWindows . withGap ( Time . minutes ( 30L ))) // count clicks per session. Define function as lambda function. . reduce (( a , b ) -> Tuple2 . of ( a . f0 , a . f1 + b . f1 )); SQL & Table API Flink具有两个关系型API， Table API和SQL 。这两个API都是用于批处理和流处理的统一API，即，在无界的实时流或有界的记录流上以相同的语义执行查询，并产生相同的结果。Table API和SQL利用 Apache Calcite 进行解析，验证和查询优化。它们可以与DataStream和DataSet API无缝集成，并支持用户定义的标量，聚合和表值函数。 Flink的关系型API旨在简化 数据分析 ， 数据pipelining和ETL应用 的定义。 以下示例显示用于会话化点击流并计算每个会话的点击次数的SQL查询。这与DataStream API示例中的用例相同。 SELECT userId , COUNT ( * ) FROM clicks GROUP BY SESSION ( clicktime , INTERVAL '30' MINUTE ), userId 库 Flink具有几个用于常见数据处理用例的库。这些库通常嵌入在API中，而不是完全独立的。因此，他们可以从API的所有功能中受益，并与其他库集成。 复杂事件处理（CEP） ：模式检测是事件流处理的一个非常常见的用例。Flink的CEP库提供了一个API来指定事件的模式（想想正则表达式或状态机）。CEP库与Flink的DataStream API集成，以便在DataStream上评估模式。CEP库的应用包括网络入侵检测，业务流程监控和欺诈检测。 DataSet API ：DataSet API是Flink用于批处理应用程序的核心API。DataSet API的原语包括 map ， reduce ， （外部）join ， co-group 和 iterate 。所有操作都由算法和数据结构支持，这些算法和数据结构对内存中的序列化数据进行操作，并在数据大小超过内存预算时溢出到磁盘。Flink的DataSet API的数据处理算法是受传统数据库算子的启发，例如混合散列连接或外部合并排序。 Gelly ：Gelly是一个可扩展的图形处理和分析库。Gelly在DataSet API之上实现并与之集成。因此，它受益于其可扩展且强大的算子。Gelly具有 内置算法 ，例如标签传播，三角形枚举和页面排名，但也提供了一种 Graph API 从而简化自定义图算法的实现。 三、运行 由于许多流应用程序旨在以最短的停机时间连续运行，因此流处理器必须提供出色的故障恢复，以及在应用程序运行时监视和维护应用程序的工具。 Apache Flink非常关注流处理的运维方面。在这里，我们将解释Flink的故障恢复机制，并介绍其管理和监督正在运行的应用程序的功能。 全天候运行您的应用程序 机器和过程故障在分布式系统中无处不在。像Flink这样的分布式流处理器必须从故障中恢复，以便能够24/7全天候运行流应用程序。显然，这不仅意味着在故障后重新启动应用程序，而且还要确保其内部状态保持一致，以便应用程序可以继续处理，就像从未发生过故障一样。 Flink提供了多种功能，以确保应用程序保持运行并保持一致： 一致的检查点 ：Flink的恢复机制基于应用程序状态的一致检查点。如果发生故障，将重新启动应用程序并从最新检查点加载其状态。结合可重置流源，此功能可以保证 精确一次的状态一致性 。 高效检查点 ：如果应用程序保持TB级状态，则checkpoint应用程序的状态可能非常昂贵。Flink可以执行异步和增量检查点，以便将检查点对应用程序的延迟SLA的影响保持在非常小的水平。 端到端精确一次 ：Flink为特定存储系统提供事务接收器，保证数据只写出一次，即使出现故障。 与集群管理器集成 ：Flink与集群管理器紧密集成，例如 Hadoop YARN ， Mesos 或 Kubernetes 。当进程失败时，将自动启动一个新进程来接管其工作。 高可用性设置 ：Flink具有高可用性模式，可消除所有单点故障。HA模式基于 Apache ZooKeeper ，这是一种经过验证的可靠分布式协调服务。 更新，迁移，暂停和恢复您的应用程序 需要维护为关键业务服务提供支持的流应用程序。需要修复错误，并且需要实现改进或新功能。但是，更新有状态流应用程序并非易事。通常，人们不能简单地停止应用程序并重新启动固定版本或改进版本，因为人们无法承受丢失应用程序的状态。 Flink的 Savepoints 是一个独特而强大的功能，可以解决更新有状态应用程序和许多其他相关挑战的问题。保存点是应用程序状态的一致快照，因此与检查点非常相似。但是，与检查点不同，保存点需要手动触发，并且在应用程序停止时不会自动删除保存点。保存点可用于启动状态兼容的应用程序并初始化其状态。保存点具有以下功能： 应用程序演变 ：保存点可用于演进应用程序。一个应用程序的固定或改进版本可以从先前版本的保存点重新启动。也可以从较早的时间点（假设存在这样的保存点）启动应用程序，以修复由有缺陷的版本产生的错误结果。 群集迁移 ：使用保存点，可以将应用程序迁移（或克隆）到不同的群集。 Flink版本更新 ：可以使用保存点迁移应用程序以在新的Flink版本上运行。 应用程序扩展 ：保存点可用于增加或减少应用程序的并行性。 A / B测试和假设情景 ：可以通过启动同一保存点的所有版本来比较两个（或更多）不同版本的应用程序的性能或质量。 暂停和恢复 ：可以通过获取保存点并停止应用程序来暂停应用程序。在以后的任何时间点，都可以从保存点恢复应用程序。 存档 ：可以存档，以便能够将应用程序的状态重置为较早的时间点。 监控您的应用程序 与任何其他服务一样，需要对连续运行的流应用程序进行监督，并将其集成到组织的运营基础架构（即监控和日志记录服务）中。监控有助于预测问题并提前做出反应。通过日志记录可以进行根因分析调查失败。最后，通过一个易于访问的接口来控制运行应用程序的是一个重要特性。 Flink与许多常见的日志记录和监视服务很好地集成，并提供REST API来控制应用程序和查询信息。 Web UI ：Flink具有Web UI，可以检查，监视和调试正在运行的应用程序。它还可用于提交执行或取消执行。 日志记录 ：Flink实现了流行的slf4j日志记录界面，并与日志框架 log4j 或 logback 集成。 指标 ：Flink具有复杂的指标系统，可收集和报告系统和用户定义的指标。指标可以导出到多个报告器，包括 JMX ，Ganglia， Graphite ， Prometheus ， StatsD ， Datadog 和 Slf4j 。 REST API ：Flink公开REST API以提交新应用程序、生成正在运行的应用程序的保存点或取消应用程序。REST API还公开元数据和收集运行或已完成应用程序的指标。","tags":"Big Data","url":"https://jiang-hao.com/articles/2019/big-data-flink-intro.html","loc":"https://jiang-hao.com/articles/2019/big-data-flink-intro.html"},{"title":"OpenShift 详细教程 - 基础知识入门","text":"简介 自由和开放源码的云计算平台使开发人员能够创建、测试和运行他们的应用程序，并且可以把它们部署到云中。 OpenShift是红帽的云开发平台即服务（PaaS）。是一个基于主流的容器技术Docker和K8s构建的开源容器云平台。底层以Docker作为容器引擎驱动，以K8s作为容器编排引擎组件，并提供了开发语言，中间件，DevOps自动化流程工具和web console用户界面等元素，提供了一套完整的基于容器的应用云平台。 Openshift提供比任何PaaS更多的灵活性，它支持用于Java、Python、PHP、Perl、node.js、go和Ruby的更多的开发框架，包括 Spring、Seam、Weld、CDI、Rails、Rack、Symfony、Zend Framework、Twisted、Django和Java E。数据库语言则支持MySQL、MongoDB和PostgreSQL。 另外它还提供了多种集成开发工具如Eclipse integration，JBoss Developer Studio和 Jenkins等。 OpenShift Online服务构建在Red Hat Enterprise Linux上。Red Hat Enterprise Linux提供集成应用程序，运行库和一个配置可伸缩的多用户单实例的操作系统，以满足企业级应用的各种需求。 建立在红帽开源领导地位基础上的OpenShift旨在终结PaaS的厂商锁定，使用户可以选择自 己应用运行在哪个云提供商的云中。OpenShift将作为在线服务来提供。 OpenShift使用的架构由单个节点组成，以容纳应用程序代码和服务，同时还有一系列的单独代理来管理节点和提供服务。除此之外，OpenShift的架构还包括一个消息系统将节点和代理绑定到一起，并且使用 RESTful 的API同外部工具整合。 Openshift包括社区版和企业版： 社区版： Openshift Origin 企业版： Openshift Online/Openshift Enterprise 重要概念 system:admin为默认的集群管理员，拥有最高的权限。该用户没有密码，登陆依赖于证书密钥。 Service Account 是 Openshift 中专门供程序和组件使用的账号。不同的用户或组关联不同的角色，同时关联不同的SCC（security context constriant）安全上下文。 总体架构 自底而上包括几个层次：基础架构层，容器引擎层，容器编排层，PaaS服务层，界面及工具层。 基础架构层：为Openshift平台的运行提供基础的运行环境。Openshift支持运行在物理机，虚拟机（kvm,vmware,virtual box等），公有云（阿里云，AWS等），私有云，混合云上。 容器引擎层：以当前主流的Docker作为容器引擎。 容器编排层：以Google的k8s进行容器编排。 PaaS服务层：容器云平台的最终目的是为上层应用服务提供支持，提高开发，测试，部署，运维的速度和效率。用户在Openshift云平台上可以快速的获取和部署一个数据库，缓存等。 界面及工具层：Openshift提供了多种用户的接入渠道：Web控制台，命令行，RestFul接口等。 核心组件 Master节点：主控节点 集群内的管理组件都运行在Master节点上。Master节点负责集群的配置管理，维护集群的状态。 Master节点运行的服务组件： API Server：负责提供Web console和RESTful API。集群内所有节点都会访问API Server，更新节点的状态及其上的容器状态。 数据源（Data store）：集群内所有状态信息都会存储在后端的一个etcd的分布式数据库中。 调度控制器（Scheduler）：负责按用户输入的要求寻找合适的计算节点。 复制控制器（Replication Controller）：负责监控当前容器实例的数量和用户部署指定的数量是否匹配，若有容器异常退出，复制控制器发现实际数少于部署定义数，从而触发部署新的实例。 Node节点：计算节点 接收Master节点的指令，运行和维护Docker容器。Master节点也可以是Node节点，只是在一般环境中，其运行容器的功能是关闭的。 Project 在k8s中使用命名空间来分隔资源。同一个命名空间中，某一个对象的名称在其分类中必须唯一，但在不同命名空间中的对象则可以同名。Openshift集成了k8s命名空间的概念，而且在其上定义了Project对象的概念， 每一个Project会和一个namespace相关联 。 Pod 在Openshift中的容器都会Pod包裹，即容器都运行在Pod内部， 一个Pod可以运行一个或多个容器，绝大多少情况下，一个Pod内部运行一个容器 。 Service 由于容器是一个非持久化的对象，所有对容器的修改在容器销毁后都会丢失，而且每个容器的IP地址会不断变化。k8s提供了Service组件，当部署某个应用时，会创建一个Service对象，该对象与一个或多个Pod关联，同时每个Service分配一个相对恒定的IP，通过访问该IP及相应的端口，请求就会转发到对应Pod端口。除了可通过IP，也可以通过域名访问Service，格式为：..svc.cluster.local Router和Route Service提供了一个通往后端Pod集群的稳定入口，但是Service的IP地址只是集群内部的节点和容器可见。外部需通过Router（路由器）来转发。Router组件是Openshift集群中一个重要的组件，它是外界访问集群内容器应用的入口。用户可以创建Route（路由规则）对象，一个Route会与一个Service关联，并绑定一个域名。Route规则被Router加载。当集群外部的请求通过指定域名访问应用时，域名被解析并指向Router所在的计算机节点上，Router获取该请求，然后根据Route规则定义转发给与这个域名对应的Service后端所关联的Pod容器实例。上述转发流程类似于nginx。Router负责将集群外的请求转发到集群的容器，Service则负责把来自集群内部的请求转发到指定的容器中。 Persistent Storage 容器默认是非持久化的，所有的修改在容器销毁时都会丢失。Docker提供了持久化卷挂载的能力，Openshift除了提供持久化卷挂载的能力，还提供了一种持久化供给模型即PV（Persistent Volume）和PVC（Persistent Volume Claim）。在PV和PVC模型中，集群管理员会创建大量不同大小和不同特性的PV。用户在部署应用时显式的声明对持久化的需求，创建PVC，在PVC中定义所需要的存储大小，访问方式。Openshift集群会自动寻找符合要求的PV与PVC自动对接。 Registry Openshift内部的镜像仓库，主要用于存放内置的S2I构建流程所产生的镜像。 S2I Source to Image，负责将应用源码构建成镜像。步骤： 1）用户输入源代码仓库的地址 2）选择S2I构建的基础镜像 3）触发构建 4）S2I构建执行器从指定的源码仓库地址下载代码 5）S2I构建执行器实例化Builder镜像，并将代码注入到Builder镜像 6）S2I构建执行器按照预定义的逻辑执行源代码的编译，构建 7）生成新的镜像 8）S2I构建执行器将新镜像Push到Registry 9）更新相关的Image Stream信息 核心流程 1）创建应用：用户通过web控制台或oc命令创建应用，Openshift平台根据用户输入的源码地址和Builder镜像，生成构建配置Builder config和部署配置Deployment config，Service，Route等。 2）触发构建 3）实例化构建：平台根据Builder config实例化Builder对象，下载代码，并将代码注入到Builder对象，执行编译，构建 4）生成新镜像并Push到Registry 5）更新相关的Image Stream信息 6）触发部署：当Image Stream更新后，触发平台部署镜像 7）实例化镜像部署：平台根据Deployment config实例化部署，生成Deploy对象 8）生成Replication Controller 9）部署容器：通过Replication Controller，平台将pod及容器部署到各个节点上 10）用户访问：用户通过浏览器访问Route对象中定义的应用域名 11）请求处理并返回：请求到达Router组件后，通过Route转发给相关联的Service，最终到对应的容器实例。 优点 支持快速部署，实现敏捷开发。 提供动态伸缩功能，将过程简化至只需更改一个值。 管理资源，为容器分配合适的资源，提高资源利用率。 有对应的平台自动化运维工具，大大减少运维负担。 在大规模集群时提供方便高效的管理方法。 有完善的结构，部署以后能快速地测试应用。 丰富的接口，提供给各种插件与二次开发使用 上手难度：是基于docker和k8s的开源项目，有丰富的社区技术支持。还有关于openshift中文参考书。","tags":"Cloud","url":"https://jiang-hao.com/articles/2019/cloud-openshift-basics.html","loc":"https://jiang-hao.com/articles/2019/cloud-openshift-basics.html"},{"title":"详解Java中的final关键字","text":"final 简介 1 final 关键字可用于多个场景，且在不同场景具有不同的作用。首先， final 是一个 非访问修饰符 ， 仅 适用 于变量，方法或类 。下面是使用final的不同场景： 上面这张图可以概括成： 当 final 修饰 变量 时，被修饰的变量必须被初始化(赋值)，且后续不能修改其值，实质上是常量； 当 final 修饰 方法 时，被修饰的方法无法被所在类的子类重写（覆写）； 当 final 修饰 类 时，被修饰的类不能被继承，并且 final 类中的所有成员方法都会被隐式地指定为 final 方法，但成员变量则不会变。 final 修饰变量 当使用 final 关键字声明类成员变量或局部变量后，其值不能被再次修改；也经常和 static 关键字一起，作为 类常量 使用。很多时候会容易把 static 和 final 关键字混淆， static 作用于成员变量用来表示只保存一份副本，而 final 的作用是用来保证变量不可变 。如果 final 变量是引用，这意味着该变量不能重新绑定到引用另一个对象，但是可以更改该引用变量指向的对象的内部状态，即可以从 final 数组 或 final 集合中添加或删除元素。最好用全部大写来表示 final 变量，使用下划线来分隔单词。 例子 ： //一个final成员常量 final int THRESHOLD = 5 ; //一个空的final成员常量 final int THRESHOLD ; //一个静态final类常量 static final double PI = 3.141592653589793 ; //一个空的静态final类常量 static final double PI ; 初始化final变量 ： 我们必须初始化一个 final 变量，否则编译器将抛出编译时错误。 final 变量只能通过 初始化器 或赋值语句初始化一次。初始化 final 变量有三种方法： 可以在声明它时初始化 final 变量。这种方法是最常见的。如果在声明时 未 初始化，则该变量称为 空 final 变量 。下面是初始化空 final 变量的两种方法。 可以在 instance-initializer块 或内部构造函数中 初始化 空的 final 变量。如果您的类中有多个构造函数，则必须在所有构造函数中初始化它，否则将抛出编译时错误。 可以在 静态块 内初始化空的 final 静态变量。 这里注意有一个很普遍的误区。 很多人会认为static修饰的final常量必须在声明时就进行初始化，否则会报错。但其实则不然，我们可以先使用 static final 关键字声明一个类常量，然后再在 静态块 内初始化空的 final 静态变量。 让我们通过一个例子看上面初始化 final 变量的不同方法。 // Java program to demonstrate different // ways of initializing a final variable class Gfg { // a final variable direct initialize // 直接赋值 final int THRESHOLD = 5 ; // a blank final variable // 空final变量 final int CAPACITY ; // another blank final variable final int MINIMUM ; // a final static variable PI direct initialize // 直接赋值的静态final变量 static final double PI = 3.141592653589793 ; // a blank final static variable // 空的静态final变量，此处并不会报错，因为在下方的静态代码块内对其进行了初始化 static final double EULERCONSTANT ; // instance initializer block for initializing CAPACITY // 用来赋值空final变量的实例初始化块 { CAPACITY = 25 ; } // static initializer block for initializing EULERCONSTANT // 用来赋值空final变量的静态初始化块 static { EULERCONSTANT = 2.3 ; } // constructor for initializing MINIMUM // Note that if there are more than one // constructor, you must initialize MINIMUM // in them also // 构造函数内初始化空final变量；注意如果有多个 // 构造函数时，必须在每个中都初始化该final变量 public GFG () { MINIMUM = - 1 ; } } 何时使用 final 变量： 普通变量和 final 变量之间的唯一区别是我们可以将值重新赋值给普通变量；但是对于 final 变量，一旦赋值，我们就不能改变 final 变量的值。因此， final 变量必须仅用于我们希望在整个程序执行期间保持不变的值。 final 引用变量： 当 final 变量是对象的引用时，则此变量称为 final 引用变量。例如， final 的 StringBuffer 变量： final StringBuffer sb ; final 变量无法重新赋值。但是对于 final 的引用变量，可以更改该引用变量指向的对象的内部状态。请注意，这不是重新赋值。 final的 这个属性称为 非传递性 。要了解对象内部状态的含义，请参阅下面的示例： // Java program to demonstrate // reference final variable class Gfg { public static void main ( String [] args ) { // a final reference variable sb final StringBuilder sb = new StringBuilder ( \"Geeks\" ); System . out . println ( sb ); // changing internal state of object // reference by final reference variable sb // 更改final变量sb引用的对象的内部状态 sb . append ( \"ForGeeks\" ); System . out . println ( sb ); } } 输出： Geeks GeeksForGeeks 非传递 属性也适用于数组，因为在Java中 数组也是对象 。带有 final 关键字的数组也称为 final 数组 。 注意 ： 如上所述， final 变量不能重新赋值，这样做会抛出编译时错误。 // Java program to demonstrate re-assigning // final variable will throw compile-time error class Gfg { static final int CAPACITY = 4 ; public static void main ( String args [] ) { // re-assigning final variable // will throw compile-time error CAPACITY = 5 ; } } 输出： Compiler Error: cannot assign a value to final variable CAPACITY 当在方法/构造函数/块中创建 final 变量时，它被称为局部 final 变量，并且必须在创建它的位置初始化一次。参见下面的局部 final 变量程序： // Java program to demonstrate // local final variable // The following program compiles and runs fine class Gfg { public static void main ( String args [] ) { // local final variable final int i ; i = 20 ; System . out . println ( i ); } } 输出： 20 注意C ++ const 变量和Java final 变量之间的区别。声明时，必须为C ++中的const变量赋值。对于Java中的 final 变量，正如我们在上面的示例中所看到的那样，可以稍后赋值，但只能赋值一次。 final 在 foreach循环 中：在foreach语句中使用 final 声明存储循环元素的变量是合法的。 // Java program to demonstrate final // with for-each statement class Gfg { public static void main ( String [] args ) { int arr [] = { 1 , 2 , 3 }; // final with for-each statement // legal statement for ( final int i : arr ) System . out . print ( i + \" \" ); } } 输出： 1 2 3 说明： 由于i变量在循环的每次迭代时超出范围，因此实际上每次迭代都重新声明，允许使用相同的标记（即i）来表示多个变量。 final 修饰类 当使用 final 关键字声明一个类时，它被称为 final 类。被声明为 final 的类不能被扩展（继承）。 final 类有两种用途： 一个是彻底防止被 继承 ，因为 final 类不能被扩展。例如，所有 包装类 如 Integer ， Float 等都是 final 类。我们无法扩展它们。 final 类的另一个用途是 创建一个 类似于 String 类的不可变类。只有将一个类定义成为 final 类，才能使其不可变。 final class A { // methods and fields } // 下面的这个类B想要扩展类A是非法的 class B extends A { // COMPILE-ERROR! Can't subclass A } Java支持把class定义成 final ，似乎违背了面向对象编程的基本原则，但在另一方面，封闭的类也保证了该类的所有方法都是固定不变的，不会有子类的覆盖方法需要去动态加载。这给编译器做优化时提供了更多的可能，最好的例子是String，它就是 final 类，Java编译器就可以把字符串常量（那些包含在双引号中的内容）直接变成String对象，同时对运算符\"+\"的操作直接优化成新的常量，因为final修饰保证了不会有子类对拼接操作返回不同的值。 对于所有不同的类定义一顶层类(全局或包可见)、嵌套类(内部类或静态嵌套类)都可以用final来修饰。但是一般来说final多用来修饰在被定义成全局(public)的类上，因为对于非全局类，访问修饰符已经将他们限制了它们的也可见性，想要继承这些类已经很困难，就不用再加一层final限制。 final 与匿名内部类 匿名类(Anonymous Class)虽然说同样不能被继承，但它们并没有被编译器限制成final。另外要提到的是，网上有许多地方都说因为使用内部类，会有两个地方必须需要使用 final 修饰符： 在内部类的方法使用到方法中定义的局部变量，则该局部变量需要添加 final 修饰符 在内部类的方法形参使用到外部传过来的变量，则形参需要添加 final 修饰符 原因大多是说当我们创建匿名内部类的那个方法调用运行完毕之后，因为局部变量的生命周期和方法的生命周期是一样的，当方法弹栈， 这个局部变量就会消亡了，但内部类对象可能还存在。 此时就会出现一种情况，就是我们调用这个内部类对象去访问一个不存在的局部变量，就可能会出现空指针异常。而此时需要使用 final 在类加载的时候进入常量池，即使方法弹栈，常量池的常量还在，也可以继续使用，JVM 会持续维护这个引用在回调方法中的生命周期。 但是 JDK 1.8 取消了对匿名内部类引用的局部变量 final 修饰的检查 对此， theonlin 专门通过实验做出了总结：其实局部内部类并不是直接调用方法传进来的参数，而是内部类将传进来的参数通过自己的构造器备份到了自己的内部，自己内部的方法调用的实际是自己的属性而不是外部类方法的参数。外部类中的方法中的变量或参数只是方法的局部变量，这些变量或参数的作用域只在这个方法内部有效，所以方法中被 final 的变量的仅仅作用是表明这个变量将作为内部类构造器参数， 其实 final 不加也可以，加了可能还会占用内存空间，影响 GC 。最后结论就是，需要使用 final 去持续维护这个引用在回调方法中的生命周期这种说法应该是错误的，也没必要。 final 修饰方法 下面这段话摘自《Java编程思想》第四版第143页： 使用 final 方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。 当使用 final 关键字声明方法时，它被称为 final 方法。 final 方法无法被 覆盖 （重写）。比如 Object类 ，它的一些方法就被声明成为了 final 。如果你认为一个方法的功能已经足够完整了，子类中不需要改变的话，你可以声明此方法为 final 。以下代码片段说明了用 final 关键字修饰方法： class A { // 父类的ml方法被使用了final关键字修饰 final void m1 () { System . out . println ( \"This is a final method.\" ); } } class B extends A { // 此处会报错，子类B尝试重写父类A的被final修饰的ml方法 @override void m1 () { // COMPILE-ERROR! Can't override. System . out . println ( \"Illegal!\" ); } } 而关于高效，是因为在java早期实现中，如果将一个方法指明为final，就是同意编译器将针对该方法的调用都转化为内嵌调用（内联）。大概就是，如果是内嵌调用，虚拟机不再执行正常的方法调用（参数压栈，跳转到方法处执行，再调回，处理栈参数，处理返回值），而是直接将方法展开，以方法体中的实际代码替代原来的方法调用。这样减少了方法调用的开销。所以有一些程序员认为： 除非有足够的理由使用多态性，否则应该将所有的方法都用 final 修饰。这样的认识未免有些偏激 ，因为在最近的java设计中，虚拟机（特别是hotspot技术）可以自己去根据具体情况自动优化选择是否进行内联，只不过使用了 final 关键字的话可以显示地影响编译器对被修饰的代码进行内联优化。所以请切记，对于Java虚拟机来说编译器在编译期间会自动进行内联优化，这是由编译器决定的，对于开发人员来说，一定要设计好时空复杂度的平衡，不要滥用final。 注1：类的 private 方法会隐式地被指定为 final 方法，也就同样无法被重写。可以对private方法添加final修饰符，但并没有添加任何额外意义。 注2：在java中，你永远不会看到同时使用 final 和 abstract 关键字声明的类或方法。对于类， final 用于防止 继承 ，而抽象类反而需要依赖于它们的子类来完成实现。在修饰方法时， final 用于防止被 覆盖 ，而抽象方法反而需要在子类中被重写。 有关 final 方法和 final 类的更多示例和行为 ，请参阅 使用final继承 。 final 优化编码的艺术 final 关键字在效率上的作用主要可以总结为以下三点： 缓存： final 配合 static 关键字提高了代码性能，JVM和Java应用都会缓存 final 变量。 同步： final 变量或对象是只读的，可以安全的在多线程环境下进行共享，而不需要额外的同步开销。 内联：使用 final 关键字，JVM会 显式地 主动对方法、变量及类进行内联优化。 更多关于 final 关键字对代码的优化总结以及注意点可以参考IBM的 《Is that your final answer?》 这篇文章。 本文由笔者参考多篇博文汇总作成，因数量众多不一一列出，主体部分从GeeksforGeeks网站翻译，实际由 Gaurav Miglani 撰写。如果您发现任何不正确的内容，或者您想要分享有关上述主题的更多信息，请撰写评论。 ↩","tags":"Backend","url":"https://jiang-hao.com/articles/2019/backend-java-final-keyword.html","loc":"https://jiang-hao.com/articles/2019/backend-java-final-keyword.html"},{"title":"一种通过网盘实现多终端桌面同步和云化存储的方法","text":"简介 方法其实很简单，而且很多人可能已经想到或者在用了。一言以蔽之，就是把桌面文件夹设置为网盘的同步文件夹。之所以要这么做，因为很多人习惯使用一些程序搜索工具来启动程序（比如wox, everything, 甚至系统自带的搜索功能等等），不在系统桌面保留桌面图标，而且通常为了平时工作方便，会直接把桌面当做文档库或者workshop来用，也就是把平时常用的一些文档直接保存在桌面。这个时候如果直接用网盘把桌面设置为同步文件夹，就可以直接实时备份桌面上的文件了。而许多人可能平时会用到诸多不同设备（比如工作场所的电脑，私人电脑，手机，ipad等等），这种方法就可以实现多个电脑之间桌面的实时文件共享，同时其他移动端设备也能实时进行同步了。平时工作或者收藏的文件或者个人材料，在外临时要用的时候随时随处都可以拿到，而不用刻意事先进行上传或者分享。 效果 以下是大致效果: 工具 程序启动 如果您不喜欢应用程序图标，并且只希望在桌面上放置文件和文件夹（如图所示），但仍然希望能够以一种方便的方式启动应用程序，则可以删除所有图标，然后安装 WOX ，用于快速访问应用程序。 网盘同步 这里的网盘可以使用MEGASync或者坚果云，可以在多个设备之间同步桌面，并可以通过网页或者客户端随时随地访问文档。 MEGASync 提供以下功能： 具有50GB免费存储空间的安全云网络磁盘 通过端到端加密进行快速传输 多个设备之间的文件夹同步 如我们所见，MEGASync的一个非常有用的功能是在多个设备之间同步文件夹。 但是，当我们使用它将桌面放在云中时，它将变得更加有趣。 配置 配置非常简单，安装软件后设置MEGASync同步文件夹时只需将桌面目录设置为同步文件夹即可。","tags":"Tools","url":"https://jiang-hao.com/articles/2019/tools-Cloud-Desktop-Based-On-MegaSync.html","loc":"https://jiang-hao.com/articles/2019/tools-Cloud-Desktop-Based-On-MegaSync.html"},{"title":"A Java TFTP Server","text":"简介 一个完全多线程的tftp服务器。可以同时处理多个客户端。实现 RFC 1350 并包装块号以获得大文件支持。 通过判断监听到的请求tftpPacket_的类型是TFTPReadRequestPacket（读）或者TFTPWriteRequestPacket（写），将其对应交由handleRead()或者handleWrite()方法处理。 要启动，只需创建该类的实例。如果服务器由于正在使用的端口，端口被拒绝等原因而无法启动，则将抛出IOException。 要停止，请使用shutdown方法。 要检查服务器是否仍在运行（或者由于错误而停止），请调用isRunning方法。 默认情况下，事件不会记录到stdout/stderr。可以使用setLog和setLogError方法更改此设置。 示例用法如下： public static void main ( String [] args ) throws Exception { if ( args . length != 1 ) { System . out . println ( \"You must provide 1 argument - the base path for the server to serve from.\" ); System . exit ( 1 ); } TFTPServer ts = new TFTPServer ( new File ( args [ 0 ] ), new File ( args [ 0 ] ), GET_AND_PUT ); ts . setSocketTimeout ( 2000 ); System . out . println ( \"TFTP Server running. Press enter to stop.\" ); new InputStreamReader ( System . in ). read (); ts . shutdown (); System . out . println ( \"Server shut down.\" ); System . exit ( 0 ); } 代码 /* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements. See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the \"License\"); you may not use this file except in compliance with * the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an \"AS IS\" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ package org.apache.commons.net.tftp ; import java.io.BufferedInputStream ; import java.io.BufferedOutputStream ; import java.io.File ; import java.io.FileInputStream ; import java.io.FileNotFoundException ; import java.io.FileOutputStream ; import java.io.IOException ; import java.io.InputStream ; import java.io.OutputStream ; import java.io.PrintStream ; import java.net.InetAddress ; import java.net.NetworkInterface ; import java.net.SocketTimeoutException ; import java.util.HashSet ; import java.util.Enumeration ; import java.util.Iterator ; import org.apache.commons.net.io.FromNetASCIIOutputStream ; import org.apache.commons.net.io.ToNetASCIIInputStream ; /** * A fully multi-threaded tftp server. Can handle multiple clients at the same time. Implements RFC * 1350 and wrapping block numbers for large file support. * * To launch, just create an instance of the class. An IOException will be thrown if the server * fails to start for reasons such as port in use, port denied, etc. * * To stop, use the shutdown method. * * To check to see if the server is still running (or if it stopped because of an error), call the * isRunning() method. * * By default, events are not logged to stdout/stderr. This can be changed with the * setLog and setLogError methods. * * <p> * Example usage is below: * * <code> * public static void main(String[] args) throws Exception * { * if (args.length != 1) * { * System.out * .println(\"You must provide 1 argument - the base path for the server to serve from.\"); * System.exit(1); * } * * TFTPServer ts = new TFTPServer(new File(args[0]), new File(args[0]), GET_AND_PUT); * ts.setSocketTimeout(2000); * * System.out.println(\"TFTP Server running. Press enter to stop.\"); * new InputStreamReader(System.in).read(); * * ts.shutdown(); * System.out.println(\"Server shut down.\"); * System.exit(0); * } * * </code> * * @since 2.0 */ public class TFTPServer implements Runnable { private static final int DEFAULT_TFTP_PORT = 69 ; public static enum ServerMode { GET_ONLY , PUT_ONLY , GET_AND_PUT ; } private final HashSet < TFTPTransfer > transfers_ = new HashSet < TFTPTransfer > (); private volatile boolean shutdownServer = false ; private TFTP serverTftp_ ; private File serverReadDirectory_ ; private File serverWriteDirectory_ ; private final int port_ ; private final InetAddress laddr_ ; private Exception serverException = null ; private final ServerMode mode_ ; /* /dev/null output stream (default) */ private static final PrintStream nullStream = new PrintStream ( new OutputStream () { @Override public void write ( int b ){} @Override public void write ( byte [] b ) throws IOException {} } ); // don't have access to a logger api, so we will log to these streams, which // by default are set to a no-op logger private PrintStream log_ ; private PrintStream logError_ ; private int maxTimeoutRetries_ = 3 ; private int socketTimeout_ ; private Thread serverThread ; /** * Start a TFTP Server on the default port (69). Gets and Puts occur in the specified * directories. * * The server will start in another thread, allowing this constructor to return immediately. * * If a get or a put comes in with a relative path that tries to get outside of the * serverDirectory, then the get or put will be denied. * * GET_ONLY mode only allows gets, PUT_ONLY mode only allows puts, and GET_AND_PUT allows both. * Modes are defined as int constants in this class. * * @param serverReadDirectory directory for GET requests * @param serverWriteDirectory directory for PUT requests * @param mode A value as specified above. * @throws IOException if the server directory is invalid or does not exist. */ public TFTPServer ( File serverReadDirectory , File serverWriteDirectory , ServerMode mode ) throws IOException { this ( serverReadDirectory , serverWriteDirectory , DEFAULT_TFTP_PORT , mode , null , null ); } /** * Start a TFTP Server on the specified port. Gets and Puts occur in the specified directory. * * The server will start in another thread, allowing this constructor to return immediately. * * If a get or a put comes in with a relative path that tries to get outside of the * serverDirectory, then the get or put will be denied. * * GET_ONLY mode only allows gets, PUT_ONLY mode only allows puts, and GET_AND_PUT allows both. * Modes are defined as int constants in this class. * * @param serverReadDirectory directory for GET requests * @param serverWriteDirectory directory for PUT requests * @param port the port to use * @param mode A value as specified above. * @param log Stream to write log message to. If not provided, uses System.out * @param errorLog Stream to write error messages to. If not provided, uses System.err. * @throws IOException if the server directory is invalid or does not exist. */ public TFTPServer ( File serverReadDirectory , File serverWriteDirectory , int port , ServerMode mode , PrintStream log , PrintStream errorLog ) throws IOException { port_ = port ; mode_ = mode ; log_ = ( log == null ? nullStream : log ); logError_ = ( errorLog == null ? nullStream : errorLog ); laddr_ = null ; launch ( serverReadDirectory , serverWriteDirectory ); } /** * Start a TFTP Server on the specified port. Gets and Puts occur in the specified directory. * * The server will start in another thread, allowing this constructor to return immediately. * * If a get or a put comes in with a relative path that tries to get outside of the * serverDirectory, then the get or put will be denied. * * GET_ONLY mode only allows gets, PUT_ONLY mode only allows puts, and GET_AND_PUT allows both. * Modes are defined as int constants in this class. * * @param serverReadDirectory directory for GET requests * @param serverWriteDirectory directory for PUT requests * @param port The local port to bind to. * @param localaddr The local address to bind to. * @param mode A value as specified above. * @param log Stream to write log message to. If not provided, uses System.out * @param errorLog Stream to write error messages to. If not provided, uses System.err. * @throws IOException if the server directory is invalid or does not exist. */ public TFTPServer ( File serverReadDirectory , File serverWriteDirectory , int port , InetAddress localaddr , ServerMode mode , PrintStream log , PrintStream errorLog ) throws IOException { port_ = port ; mode_ = mode ; laddr_ = localaddr ; log_ = ( log == null ? nullStream : log ); logError_ = ( errorLog == null ? nullStream : errorLog ); launch ( serverReadDirectory , serverWriteDirectory ); } /** * Start a TFTP Server on the specified port. Gets and Puts occur in the specified directory. * * The server will start in another thread, allowing this constructor to return immediately. * * If a get or a put comes in with a relative path that tries to get outside of the * serverDirectory, then the get or put will be denied. * * GET_ONLY mode only allows gets, PUT_ONLY mode only allows puts, and GET_AND_PUT allows both. * Modes are defined as int constants in this class. * * @param serverReadDirectory directory for GET requests * @param serverWriteDirectory directory for PUT requests * @param port the port to use * @param localiface The local network interface to bind to. * The interface's first address wil be used. * @param mode A value as specified above. * @param log Stream to write log message to. If not provided, uses System.out * @param errorLog Stream to write error messages to. If not provided, uses System.err. * @throws IOException if the server directory is invalid or does not exist. */ public TFTPServer ( File serverReadDirectory , File serverWriteDirectory , int port , NetworkInterface localiface , ServerMode mode , PrintStream log , PrintStream errorLog ) throws IOException { mode_ = mode ; port_ = port ; InetAddress iaddr = null ; if ( localiface != null ) { Enumeration < InetAddress > ifaddrs = localiface . getInetAddresses (); if ( ifaddrs != null ) { if ( ifaddrs . hasMoreElements ()) iaddr = ifaddrs . nextElement (); } } log_ = ( log == null ? nullStream : log ); logError_ = ( errorLog == null ? nullStream : errorLog ); laddr_ = iaddr ; launch ( serverReadDirectory , serverWriteDirectory ); } /** * Set the max number of retries in response to a timeout. Default 3. Min 0. * * @param retries number of retries, must be &gt; 0 */ public void setMaxTimeoutRetries ( int retries ) { if ( retries < 0 ) { throw new RuntimeException ( \"Invalid Value\" ); } maxTimeoutRetries_ = retries ; } /** * Get the current value for maxTimeoutRetries * @return the max allowed number of retries */ public int getMaxTimeoutRetries () { return maxTimeoutRetries_ ; } /** * Set the socket timeout in milliseconds used in transfers. Defaults to the value here: * http://commons.apache.org/net/apidocs/org/apache/commons/net/tftp/TFTP.html#DEFAULT_TIMEOUT * (5000 at the time I write this) Min value of 10. * @param timeout the timeout; must be larger than 10 */ public void setSocketTimeout ( int timeout ) { if ( timeout < 10 ) { throw new RuntimeException ( \"Invalid Value\" ); } socketTimeout_ = timeout ; } /** * The current socket timeout used during transfers in milliseconds. * @return the timeout value */ public int getSocketTimeout () { return socketTimeout_ ; } /* * start the server, throw an error if it can't start. */ private void launch ( File serverReadDirectory , File serverWriteDirectory ) throws IOException { log_ . println ( \"Starting TFTP Server on port \" + port_ + \". Read directory: \" + serverReadDirectory + \" Write directory: \" + serverWriteDirectory + \" Server Mode is \" + mode_ ); serverReadDirectory_ = serverReadDirectory . getCanonicalFile (); if ( ! serverReadDirectory_ . exists () || ! serverReadDirectory . isDirectory ()) { throw new IOException ( \"The server read directory \" + serverReadDirectory_ + \" does not exist\" ); } serverWriteDirectory_ = serverWriteDirectory . getCanonicalFile (); if ( ! serverWriteDirectory_ . exists () || ! serverWriteDirectory . isDirectory ()) { throw new IOException ( \"The server write directory \" + serverWriteDirectory_ + \" does not exist\" ); } serverTftp_ = new TFTP (); // This is the value used in response to each client. socketTimeout_ = serverTftp_ . getDefaultTimeout (); // we want the server thread to listen forever. serverTftp_ . setDefaultTimeout ( 0 ); if ( laddr_ != null ) { serverTftp_ . open ( port_ , laddr_ ); } else { serverTftp_ . open ( port_ ); } serverThread = new Thread ( this ); serverThread . setDaemon ( true ); serverThread . start (); } @Override protected void finalize () throws Throwable { shutdown (); } /** * check if the server thread is still running. * * @return true if running, false if stopped. * @throws Exception throws the exception that stopped the server if the server is stopped from * an exception. */ public boolean isRunning () throws Exception { if ( shutdownServer && serverException != null ) { throw serverException ; } return ! shutdownServer ; } @Override public void run () { try { while ( ! shutdownServer ) { TFTPPacket tftpPacket ; tftpPacket = serverTftp_ . receive (); TFTPTransfer tt = new TFTPTransfer ( tftpPacket ); synchronized ( transfers_ ) { transfers_ . add ( tt ); } Thread thread = new Thread ( tt ); thread . setDaemon ( true ); thread . start (); } } catch ( Exception e ) { if ( ! shutdownServer ) { serverException = e ; logError_ . println ( \"Unexpected Error in TFTP Server - Server shut down! + \" + e ); } } finally { shutdownServer = true ; // set this to true, so the launching thread can check to see if it started. if ( serverTftp_ != null && serverTftp_ . isOpen ()) { serverTftp_ . close (); } } } /** * Stop the tftp server (and any currently running transfers) and release all opened network * resources. */ public void shutdown () { shutdownServer = true ; synchronized ( transfers_ ) { Iterator < TFTPTransfer > it = transfers_ . iterator (); while ( it . hasNext ()) { it . next (). shutdown (); } } try { serverTftp_ . close (); } catch ( RuntimeException e ) { // noop } try { serverThread . join (); } catch ( InterruptedException e ) { // we've done the best we could, return } } /* * An instance of an ongoing transfer. */ private class TFTPTransfer implements Runnable { private final TFTPPacket tftpPacket_ ; private boolean shutdownTransfer = false ; TFTP transferTftp_ = null ; public TFTPTransfer ( TFTPPacket tftpPacket ) { tftpPacket_ = tftpPacket ; } public void shutdown () { shutdownTransfer = true ; try { transferTftp_ . close (); } catch ( RuntimeException e ) { // noop } } @Override public void run () { try { transferTftp_ = newTFTP (); transferTftp_ . beginBufferedOps (); transferTftp_ . setDefaultTimeout ( socketTimeout_ ); transferTftp_ . open (); if ( tftpPacket_ instanceof TFTPReadRequestPacket ) { handleRead ((( TFTPReadRequestPacket ) tftpPacket_ )); } else if ( tftpPacket_ instanceof TFTPWriteRequestPacket ) { handleWrite (( TFTPWriteRequestPacket ) tftpPacket_ ); } else { log_ . println ( \"Unsupported TFTP request (\" + tftpPacket_ + \") - ignored.\" ); } } catch ( Exception e ) { if ( ! shutdownTransfer ) { logError_ . println ( \"Unexpected Error in during TFTP file transfer. Transfer aborted. \" + e ); } } finally { try { if ( transferTftp_ != null && transferTftp_ . isOpen ()) { transferTftp_ . endBufferedOps (); transferTftp_ . close (); } } catch ( Exception e ) { // noop } synchronized ( transfers_ ) { transfers_ . remove ( this ); } } } /* * Handle a tftp read request. */ private void handleRead ( TFTPReadRequestPacket trrp ) throws IOException , TFTPPacketException { InputStream is = null ; try { if ( mode_ == ServerMode . PUT_ONLY ) { transferTftp_ . bufferedSend ( new TFTPErrorPacket ( trrp . getAddress (), trrp . getPort (), TFTPErrorPacket . ILLEGAL_OPERATION , \"Read not allowed by server.\" )); return ; } try { is = new BufferedInputStream ( new FileInputStream ( buildSafeFile ( serverReadDirectory_ , trrp . getFilename (), false ))); } catch ( FileNotFoundException e ) { transferTftp_ . bufferedSend ( new TFTPErrorPacket ( trrp . getAddress (), trrp . getPort (), TFTPErrorPacket . FILE_NOT_FOUND , e . getMessage ())); return ; } catch ( Exception e ) { transferTftp_ . bufferedSend ( new TFTPErrorPacket ( trrp . getAddress (), trrp . getPort (), TFTPErrorPacket . UNDEFINED , e . getMessage ())); return ; } if ( trrp . getMode () == TFTP . NETASCII_MODE ) { is = new ToNetASCIIInputStream ( is ); } byte [] temp = new byte [ TFTPDataPacket . MAX_DATA_LENGTH ] ; TFTPPacket answer ; int block = 1 ; boolean sendNext = true ; int readLength = TFTPDataPacket . MAX_DATA_LENGTH ; TFTPDataPacket lastSentData = null ; // We are reading a file, so when we read less than the // requested bytes, we know that we are at the end of the file. while ( readLength == TFTPDataPacket . MAX_DATA_LENGTH && ! shutdownTransfer ) { if ( sendNext ) { readLength = is . read ( temp ); if ( readLength == - 1 ) { readLength = 0 ; } lastSentData = new TFTPDataPacket ( trrp . getAddress (), trrp . getPort (), block , temp , 0 , readLength ); sendData ( transferTftp_ , lastSentData ); // send the data } answer = null ; int timeoutCount = 0 ; while ( ! shutdownTransfer && ( answer == null || ! answer . getAddress (). equals ( trrp . getAddress ()) || answer . getPort () != trrp . getPort ())) { // listen for an answer. if ( answer != null ) { // The answer that we got didn't come from the // expected source, fire back an error, and continue // listening. log_ . println ( \"TFTP Server ignoring message from unexpected source.\" ); transferTftp_ . bufferedSend ( new TFTPErrorPacket ( answer . getAddress (), answer . getPort (), TFTPErrorPacket . UNKNOWN_TID , \"Unexpected Host or Port\" )); } try { answer = transferTftp_ . bufferedReceive (); } catch ( SocketTimeoutException e ) { if ( timeoutCount >= maxTimeoutRetries_ ) { throw e ; } // didn't get an ack for this data. need to resend // it. timeoutCount ++ ; transferTftp_ . bufferedSend ( lastSentData ); continue ; } } if ( answer == null || ! ( answer instanceof TFTPAckPacket )) { if ( ! shutdownTransfer ) { logError_ . println ( \"Unexpected response from tftp client during transfer (\" + answer + \"). Transfer aborted.\" ); } break ; } else { // once we get here, we know we have an answer packet // from the correct host. TFTPAckPacket ack = ( TFTPAckPacket ) answer ; if ( ack . getBlockNumber () != block ) { /* * The origional tftp spec would have called on us to resend the * previous data here, however, that causes the SAS Syndrome. * http://www.faqs.org/rfcs/rfc1123.html section 4.2.3.1 The modified * spec says that we ignore a duplicate ack. If the packet was really * lost, we will time out on receive, and resend the previous data at * that point. */ sendNext = false ; } else { // send the next block block ++ ; if ( block > 65535 ) { // wrap the block number block = 0 ; } sendNext = true ; } } } } finally { try { if ( is != null ) { is . close (); } } catch ( IOException e ) { // noop } } } /* * handle a tftp write request. */ private void handleWrite ( TFTPWriteRequestPacket twrp ) throws IOException , TFTPPacketException { OutputStream bos = null ; try { if ( mode_ == ServerMode . GET_ONLY ) { transferTftp_ . bufferedSend ( new TFTPErrorPacket ( twrp . getAddress (), twrp . getPort (), TFTPErrorPacket . ILLEGAL_OPERATION , \"Write not allowed by server.\" )); return ; } int lastBlock = 0 ; String fileName = twrp . getFilename (); try { File temp = buildSafeFile ( serverWriteDirectory_ , fileName , true ); if ( temp . exists ()) { transferTftp_ . bufferedSend ( new TFTPErrorPacket ( twrp . getAddress (), twrp . getPort (), TFTPErrorPacket . FILE_EXISTS , \"File already exists\" )); return ; } bos = new BufferedOutputStream ( new FileOutputStream ( temp )); if ( twrp . getMode () == TFTP . NETASCII_MODE ) { bos = new FromNetASCIIOutputStream ( bos ); } } catch ( Exception e ) { transferTftp_ . bufferedSend ( new TFTPErrorPacket ( twrp . getAddress (), twrp . getPort (), TFTPErrorPacket . UNDEFINED , e . getMessage ())); return ; } TFTPAckPacket lastSentAck = new TFTPAckPacket ( twrp . getAddress (), twrp . getPort (), 0 ); sendData ( transferTftp_ , lastSentAck ); // send the data while ( true ) { // get the response - ensure it is from the right place. TFTPPacket dataPacket = null ; int timeoutCount = 0 ; while ( ! shutdownTransfer && ( dataPacket == null || ! dataPacket . getAddress (). equals ( twrp . getAddress ()) || dataPacket . getPort () != twrp . getPort ())) { // listen for an answer. if ( dataPacket != null ) { // The data that we got didn't come from the // expected source, fire back an error, and continue // listening. log_ . println ( \"TFTP Server ignoring message from unexpected source.\" ); transferTftp_ . bufferedSend ( new TFTPErrorPacket ( dataPacket . getAddress (), dataPacket . getPort (), TFTPErrorPacket . UNKNOWN_TID , \"Unexpected Host or Port\" )); } try { dataPacket = transferTftp_ . bufferedReceive (); } catch ( SocketTimeoutException e ) { if ( timeoutCount >= maxTimeoutRetries_ ) { throw e ; } // It didn't get our ack. Resend it. transferTftp_ . bufferedSend ( lastSentAck ); timeoutCount ++ ; continue ; } } if ( dataPacket != null && dataPacket instanceof TFTPWriteRequestPacket ) { // it must have missed our initial ack. Send another. lastSentAck = new TFTPAckPacket ( twrp . getAddress (), twrp . getPort (), 0 ); transferTftp_ . bufferedSend ( lastSentAck ); } else if ( dataPacket == null || ! ( dataPacket instanceof TFTPDataPacket )) { if ( ! shutdownTransfer ) { logError_ . println ( \"Unexpected response from tftp client during transfer (\" + dataPacket + \"). Transfer aborted.\" ); } break ; } else { int block = (( TFTPDataPacket ) dataPacket ). getBlockNumber (); byte [] data = (( TFTPDataPacket ) dataPacket ). getData (); int dataLength = (( TFTPDataPacket ) dataPacket ). getDataLength (); int dataOffset = (( TFTPDataPacket ) dataPacket ). getDataOffset (); if ( block > lastBlock || ( lastBlock == 65535 && block == 0 )) { // it might resend a data block if it missed our ack // - don't rewrite the block. bos . write ( data , dataOffset , dataLength ); lastBlock = block ; } lastSentAck = new TFTPAckPacket ( twrp . getAddress (), twrp . getPort (), block ); sendData ( transferTftp_ , lastSentAck ); // send the data if ( dataLength < TFTPDataPacket . MAX_DATA_LENGTH ) { // end of stream signal - The tranfer is complete. bos . close (); // But my ack may be lost - so listen to see if I // need to resend the ack. for ( int i = 0 ; i < maxTimeoutRetries_ ; i ++ ) { try { dataPacket = transferTftp_ . bufferedReceive (); } catch ( SocketTimeoutException e ) { // this is the expected route - the client // shouldn't be sending any more packets. break ; } if ( dataPacket != null && ( ! dataPacket . getAddress (). equals ( twrp . getAddress ()) || dataPacket . getPort () != twrp . getPort ())) { // make sure it was from the right client... transferTftp_ . bufferedSend ( new TFTPErrorPacket ( dataPacket . getAddress (), dataPacket . getPort (), TFTPErrorPacket . UNKNOWN_TID , \"Unexpected Host or Port\" )); } else { // This means they sent us the last // datapacket again, must have missed our // ack. resend it. transferTftp_ . bufferedSend ( lastSentAck ); } } // all done. break ; } } } } finally { if ( bos != null ) { bos . close (); } } } /* * Utility method to make sure that paths provided by tftp clients do not get outside of the * serverRoot directory. */ private File buildSafeFile ( File serverDirectory , String fileName , boolean createSubDirs ) throws IOException { File temp = new File ( serverDirectory , fileName ); temp = temp . getCanonicalFile (); if ( ! isSubdirectoryOf ( serverDirectory , temp )) { throw new IOException ( \"Cannot access files outside of tftp server root.\" ); } // ensure directory exists (if requested) if ( createSubDirs ) { createDirectory ( temp . getParentFile ()); } return temp ; } /* * recursively create subdirectories */ private void createDirectory ( File file ) throws IOException { File parent = file . getParentFile (); if ( parent == null ) { throw new IOException ( \"Unexpected error creating requested directory\" ); } if ( ! parent . exists ()) { // recurse... createDirectory ( parent ); } if ( parent . isDirectory ()) { if ( file . isDirectory ()) { return ; } boolean result = file . mkdir (); if ( ! result ) { throw new IOException ( \"Couldn't create requested directory\" ); } } else { throw new IOException ( \"Invalid directory path - file in the way of requested folder\" ); } } /* * recursively check to see if one directory is a parent of another. */ private boolean isSubdirectoryOf ( File parent , File child ) { File childsParent = child . getParentFile (); if ( childsParent == null ) { return false ; } if ( childsParent . equals ( parent )) { return true ; } else { return isSubdirectoryOf ( parent , childsParent ); } } } /** * Set the stream object to log debug / informational messages. By default, this is a no-op * * @param log the stream to use for logging */ public void setLog ( PrintStream log ) { this . log_ = log ; } /** * Set the stream object to log error messsages. By default, this is a no-op * * @param logError the stream to use for logging errors */ public void setLogError ( PrintStream logError ) { this . logError_ = logError ; } /* * Allow test code to customise the TFTP instance */ TFTP newTFTP () { return new TFTP (); } /* * Also allow customisation of sending data/ack so can generate errors if needed */ void sendData ( TFTP tftp , TFTPPacket data ) throws IOException { tftp . bufferedSend ( data ); } }","tags":"Backend","url":"https://jiang-hao.com/articles/2019/backend-AJavaTFTPServer.html","loc":"https://jiang-hao.com/articles/2019/backend-AJavaTFTPServer.html"},{"title":"Java代码优化35点总结","text":"前言 代码优化，一个很重要的课题。可能有些人觉得没用，一些细小的地方有什么好修改的，改与不改对于代码的运行效率有什么影响呢？这个问题我是这么考虑的，就像大海里面的鲸鱼一样，它吃一条小虾米有用吗？没用，但是，吃的小虾米一多之后，鲸鱼就被喂饱了。代码优化也是一样，如果项目着眼于尽快无BUG上线，那么此时可以抓大放小，代码的细节可以不精打细磨；但是如果有足够的时间开发、维护代码，这时候就必须考虑每个可以优化的细节了，一个一个细小的优化点累积起来，对于代码的运行效率绝对是有提升的。 代码优化的目标是： 1、减小代码的体积 2、提高代码运行的效率 代码优化细节 1、尽量指定类、方法的final修饰符 带有final修饰符的类是不可派生的。在Java核心API中，有许多应用final的例子，例如java.lang.String，整个类都是final的。为类指定final修饰符可以让类不可以被继承，为方法指定final修饰符可以让方法不可以被重写。如果指定了一个类为final，则该类所有的方法都是final的。Java编译器会寻找机会内联所有的final方法，内联对于提升Java运行效率作用重大，具体参见Java运行期优化。此举能够使性能平均提高50%。 2、尽量重用对象 特别是String对象的使用，出现字符串连接时应该使用StringBuilder/StringBuffer代替。由于Java虚拟机不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理，因此，生成过多的对象将会给程序的性能带来很大的影响。 3、尽可能使用局部变量 调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中速度较快，其他变量，如静态变量、实例变量等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃圾回收。 4、及时关闭流 Java编程过程中，进行数据库连接、I/O流操作时务必小心，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销，稍有不慎，将会导致严重的后果。 5、尽量减少对变量的重复计算 明确一个概念，对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等。所以例如下面的操作： for ( int i = 0 ; i < list . size (); i ++ ) {...} 建议替换为： for ( int i = 0 , int length = list . size (); i < length ; i ++ ) {...} 这样，在list.size()很大的时候，就减少了很多的消耗 6、尽量采用懒加载的策略，即在需要的时候才创建 例如： String str = \"aaa\" ; if ( i == 1 ) { list . add ( str ); } 建议替换为： if ( i == 1 ) { String str = \"aaa\" ; list . add ( str ); } 7、慎用异常 异常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为fillInStackTrace()的本地同步方法，fillInStackTrace()方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调用堆栈，因为在处理过程中创建了一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。 8、不要在循环中使用try...catch...，应该把其放在最外层 除非不得已。如果毫无理由地这么写了，只要你的领导资深一点、有强迫症一点，八成就要骂你为什么写出这种垃圾代码来了 9、如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度 比如ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet等等，以StringBuilder为例： StringBuilder () // 默认分配16个字符的空间 StringBuilder ( int size ) // 默认分配size个字符的空间 StringBuilder ( String str ) // 默认分配16个字符+str.length()个字符空间 可以通过类（这里指的不仅仅是上面的StringBuilder）的来设定它的初始化容量，这样可以明显地提升性能。比如StringBuilder吧，length表示当前的StringBuilder能保持的字符数量。因为当StringBuilder达到最大容量的时候，它会将自身容量增加到当前的2倍再加2，无论何时只要StringBuilder达到它的最大容量，它就不得不创建一个新的字符数组然后将旧的字符数组内容拷贝到新字符数组中----这是十分耗费性能的一个操作。试想，如果能预估到字符数组中大概要存放5000个字符而不指定长度，最接近5000的2次幂是4096，每次扩容加的2不管，那么： 在4096 的基础上，再申请8194个大小的字符数组，加起来相当于一次申请了12290个大小的字符数组，如果一开始能指定5000个大小的字符数组，就节省了一倍以上的空间 把原来的4096个字符拷贝到新的的字符数组中去 这样，既浪费内存空间又降低代码运行效率。所以，给底层以数组实现的集合、工具类设置一个合理的初始化容量是错不了的，这会带来立竿见影的效果。但是，注意，像HashMap这种是以数组+链表实现的集合，别把初始大小和你估计的大小设置得一样，因为一个table上只连接一个对象的可能性几乎为0。初始大小建议设置为2的N次幂，如果能估计到有2000个元素，设置成new HashMap(128)、new HashMap(256)都可以。 10、当复制大量数据时，使用System.arraycopy()命令 11、乘法和除法使用移位操作 例如： for ( val = 0 ; val < 100000 ; val += 5 ) { a = val * 8 ; b = val / 2 ; } 用移位操作可以极大地提高性能，因为在计算机底层，对位的操作是最方便、最快的，因此建议修改为： for ( val = 0 ; val < 100000 ; val += 5 ) { a = val << 3 ; b = val >> 1 ; } 移位操作虽然快，但是可能会使代码不太好理解，因此最好加上相应的注释。 12、循环内不要不断创建对象引用 例如： for ( int i = 1 ; i <= count ; i ++ ) { Object obj = new Object (); } 这种做法会导致内存中有count份Object对象引用存在，count很大的话，就耗费内存了，建议为改为： Object obj = null ; for ( int i = 0 ; i <= count ; i ++ ){ obj = new Object ();} 这样的话，内存中只有一份Object对象引用，每次new Object()的时候，Object对象引用指向不同的Object罢了，但是内存中只有一份，这样就大大节省了内存空间了。 13、基于效率和类型检查的考虑，应该尽可能使用array 无法确定数组大小时才使用ArrayList 14、尽量使用HashMap、ArrayList、StringBuilder 除非线程安全需要，否则不推荐使用Hashtable、Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销 15、不要将数组声明为public static final 因为这毫无意义，这样只是定义了引用为static final，数组的内容还是可以随意改变的，将数组声明为public更是一个安全漏洞，这意味着这个数组可以被外部类所改变 16、尽量在合适的场合使用单例 使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率，但并不是所有地方都适用于单例，简单来说，单例主要适用于以下三个方面： 控制资源的使用，通过线程同步来控制资源的并发访问 控制实例的产生，以达到节约资源的目的 控制数据的共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信 17、尽量避免随意使用静态变量 要知道，当某个对象被定义为static的变量所引用，那么gc通常是不会回收这个对象所占有的堆内存的，如： public class A { private static B b = new B (); } 此时静态变量b的生命周期与A类相同，如果A类不被卸载，那么引用B指向的B对象会常驻内存，直到程序终止 18、及时清除不再需要的会话 为了清除不再活动的会话，许多应用服务器都有默认的会话超时时间，一般为30分钟。当应用服务器需要保存更多的会话时，如果内存不足，那么操作系统会把部分数据转移到磁盘，应用服务器也可能根据MRU（最近最频繁使用）算法把部分不活跃的会话转储到磁盘，甚至可能抛出内存不足的异常。如果会话要被转储到磁盘，那么必须要先被序列化，在大规模集群中，对对象进行序列化的代价是很昂贵的。因此，当会话不再需要时，应当及时调用HttpSession的invalidate()方法清除会话。 19、实现RandomAccess接口的集合比如ArrayList，应当使用最普通的for循环而不是foreach循环来遍历 这是JDK推荐给用户的。JDK API对于RandomAccess接口的解释是：实现RandomAccess接口用来表明其支持快速随机访问，此接口的主要目的是允许一般的算法更改其行为，从而将其应用到随机或连续访问列表时能提供良好的性能。实际经验表明，实现RandomAccess接口的类实例，假如是随机访问的，使用普通for循环效率将高于使用foreach循环；反过来，如果是顺序访问的，则使用Iterator会效率更高。可以使用类似如下的代码作判断： if ( list instanceof RandomAccess ) { for ( int i = 0 ; i < list . size (); i ++ ){} } else { Iterator <?> iterator = list . iterable (); while ( iterator . hasNext ()){ iterator . next ()} } foreach循环的底层实现原理就是迭代器Iterator，参见Java语法糖1：可变长度参数以及foreach循环原理。所以后半句\"反过来，如果是顺序访问的，则使用Iterator会效率更高\"的意思就是顺序访问的那些类实例，使用foreach循环去遍历。 20、使用同步代码块替代同步方法 这点在多线程模块中的synchronized锁方法块一文中已经讲得很清楚了，除非能确定一整个方法都是需要进行同步的，否则尽量使用同步代码块，避免对那些不需要进行同步的代码也进行了同步，影响了代码执行效率。 21、将常量声明为static final，并以大写命名 这样在编译期间就可以把这些内容放入常量池中，避免运行期间计算生成常量的值。另外，将常量的名字以大写命名也可以方便区分出常量与变量 22、不要创建一些不使用的对象，不要导入一些不使用的类 这毫无意义，如果代码中出现\"The value of the local variable i is not used\"、\"The import java.util is never used\"，那么请删除这些无用的内容 23、程序运行过程中避免使用反射 关于，请参见反射。反射是Java提供给用户一个很强大的功能，功能强大往往意味着效率不高。不建议在程序运行过程中使用尤其是频繁使用反射机制，特别是Method的invoke方法，如果确实有必要，一种建议性的做法是将那些需要通过反射加载的类在项目启动的时候通过反射实例化出一个对象并放入内存----用户只关心和对端交互的时候获取最快的响应速度，并不关心对端的项目启动花多久时间。 24、使用数据库连接池和线程池 这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程 25、使用带缓冲的输入输出流进行IO操作 带缓冲的输入输出流，即BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream，这可以极大地提升IO效率 26、顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList 这个，理解ArrayList和LinkedList的原理就知道了 27、不要让public方法中有太多的形参 public方法即对外提供的方法，如果给这些方法太多形参的话主要有两点坏处： 违反了面向对象的编程思想，Java讲求一切都是对象，太多的形参，和面向对象的编程思想并不契合 参数太多势必导致方法调用的出错概率增加 至于这个\"太多\"指的是多少个，3、4个吧。比如我们用JDBC写一个insertStudentInfo方法，有10个学生信息字段要插如Student表中，可以把这10个参数封装在一个实体类中，作为insert方法的形参 28、字符串变量和字符串常量equals的时候将字符串常量写在前面 这是一个比较常见的小技巧了，如果有以下代码： String str = \"123\" ; if ( str . equals ( \"123\" )){ ... } 建议修改为： String str = \"123\" ; if ( \"123\" . equals ( str )) { ... } 这么做主要是可以避免空指针异常 29、请知道，在java中if (i == 1)和if (1 == i)是没有区别的，但从阅读习惯上讲，建议使用前者 平时有人问， if (i == 1) 和 if (1== i) 有没有区别，这就要从C/C++讲起。 在C/C++中， if (i == 1) 判断条件成立，是以0与非0为基准的，0表示false，非0表示true，如果有这么一段代码： int i = 2 ; if ( i == 1 ) { ... } else { ... } C/C++判断\"i==1\"不成立，所以以0表示，即false。但是如果： int i = 2 ; if ( i = 1 ){ ...} else { ...} 万一程序员一个不小心，把\"if (i == 1)\"写成\"if (i = 1)\"，这样就有问题了。在if之内将i赋值为1，if判断里面的内容非0，返回的就是true了，但是明明i为2，比较的值是1，应该返回的false。这种情况在C/C++的开发中是很可能发生的并且会导致一些难以理解的错误产生，所以，为了避免开发者在if语句中不正确的赋值操作，建议将if语句写为： int i = 2 ; if ( 1 == i ){ ...} else { ...} 这样，即使开发者不小心写成了 1 = i ，C/C++编译器也可以第一时间检查出来，因为我们可以对一个变量赋值i为1，但是不能对一个常量赋值1为i。 但是，在Java中，C/C++这种 if (i = 1) 的语法是不可能出现的，因为一旦写了这种语法，Java就会编译报错\"Type mismatch: cannot convert from int to boolean\"。但是，尽管Java的 if (i == 1) 和 if (1 == i) 在语义上没有任何区别，但是从阅读习惯上讲，建议使用前者会更好些。 30、不要对数组使用toString()方法 看一下对数组使用toString()打印出来的是什么： public static void main ( String [] args ) { int [] is = new int [] { 1 , 2 , 3 }; System . out . println ( is . toString ()); } 结果是： [ I @ 18 a992f 本意是想打印出数组内容，却有可能因为数组引用is为空而导致空指针异常。不过虽然对数组toString()没有意义，但是对集合toString()是可以打印出集合里面的内容的，因为集合的父类AbstractCollections 重写了Object的toString()方法。 31、不要对超出范围的基本数据类型做向下强制转型 这绝不会得到想要的结果： public static void main ( String [] args ) { long l = 12345678901234L ; int i = ( int ) l ; System . out . println ( i ); } 我们可能期望得到其中的某几位，但是结果却是： 1942892530 解释一下。Java中long是8个字节64位的，所以12345678901234在计算机中的表示应该是： 0000 0000 0000 0000 0000 1011 0011 1010 0111 0011 1100 1110 0010 1111 1111 0010 一个int型数据是4个字节32位的，从低位取出上面这串二进制数据的前32位是： 0111 0011 1100 1110 0010 1111 1111 0010 这串二进制表示为十进制1942892530，所以就是我们上面的控制台上输出的内容。从这个例子上还能顺便得到两个结论： 整型默认的数据类型是int; long l = 12345678901234L ，这个数字已经超出了int的范围了，所以最后有一个L，表示这是一个long型数。顺便，浮点型的默认类型是double，所以定义float的时候要写成 float f = 3.5f 接下来再写一句 int ii = l + i; 会报错，因为long + int是一个long，不能赋值给int 32、公用的集合类中不使用的数据一定要及时remove掉 如果一个集合类是公用的（也就是说不是方法里面的属性），那么这个集合里面的元素是不会自动释放的，因为始终有引用指向它们。所以，如果公用集合里面的某些数据不使用而不去remove掉它们，那么将会造成这个公用集合不断增大，使得系统有内存泄露的隐患。 33、把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式、String.valueOf(数据)次之、数据+\"\"最慢 把一个基本数据类型转为一般有三种方式，我有一个Integer型数据i，可以使用i.toString()、String.valueOf(i)、i+\"\"三种方式，三种方式的效率如何，看一个测试： public static void main ( String [] args ) { int loopTime = 50000 ; Integer i = 0 ; long startTime = System . currentTimeMillis (); for ( int j = 0 ; j < loopTime ; j ++ ) { String str = String . valueOf ( i ); } System . out . println ( \"String.valueOf()：\" + ( System . currentTimeMillis () - startTime ) + \"ms\" ); startTime = System . currentTimeMillis (); for ( int j = 0 ; j < loopTime ; j ++ ) { String str = i . toString (); } System . out . println ( \"Integer.toString()：\" + ( System . currentTimeMillis () - startTime ) + \"ms\" ); startTime = System . currentTimeMillis (); for ( int j = 0 ; j < loopTime ; j ++ ) { String str = i + \"\" ; } System . out . println ( \"i + \"\"：\" + ( System . currentTimeMillis () - startTime ) + \"ms\" ); } 运行结果为： String . valueOf () ： 11 msInteger . toString () ： 5 msi + \"\" ： 25 ms 所以以后遇到把一个基本数据类型转为String的时候，优先考虑使用toString()方法。至于为什么，很简单： String.valueOf()方法底层调用了Integer.toString()方法，但是会在调用前做空判断 Integer.toString()方法就不说了，直接调用了 i + \"\"底层使用了StringBuilder实现，先用append方法拼接，再用toString()方法获取字符串 三者对比下来，明显是2最快、1次之、3最慢 34、使用最有效率的方式去遍历Map 遍历Map的方式有很多，通常场景下我们需要的是遍历Map中的Key和Value，那么推荐使用的、效率最高的方式是： public static void main ( String [] args ) { HashMap < String , String > hm = new HashMap < String , String > (); hm . put ( \"111\" , \"222\" ); Set < Map . Entry < String , String >> entrySet = hm . entrySet (); Iterator < Map . Entry < String , String >> iter = entrySet . iterator (); while ( iter . hasNext ()) { Map . Entry < String , String > entry = iter . next (); System . out . println ( entry . getKey () + \" \" + entry . getValue ()); } } 如果你只是想遍历一下这个Map的key值，那用 Set<String> keySet = hm.keySet(); 会比较合适一些 35、对资源的close()建议分开操作 意思是，比如我有这么一段代码： try { XXX . close (); YYY . close (); } catch ( Exception e ) { ... } 建议修改为： try { XXX . close ();} catch ( Exception e ){ ...} try { YYY . close ();} catch ( Exception e ){ ...} 虽然有些麻烦，却能避免资源泄露。我们想，如果没有修改过的代码，万一XXX.close()抛异常了，那么就进入了cath块中了，YYY.close()不会执行，YYY这块资源就不会回收了，一直占用着，这样的代码一多，是可能引起资源句柄泄露的。而改为下面的写法之后，就保证了无论如何XXX和YYY都会被close掉。","tags":"Backend","url":"https://jiang-hao.com/articles/2019/backend-Java代码优化35点总结.html","loc":"https://jiang-hao.com/articles/2019/backend-Java代码优化35点总结.html"},{"title":"人之一生","text":"热爱生命 我不去想， 是否能够成功 ， 既然选择了远方 ， 便只顾风雨兼程。 我不去想， 能否赢得爱情 ， 既然钟情于玫瑰 ， 就勇敢地吐露真诚 。 我不去想， 身后会不会袭来寒风冷雨 ， 既然目标是地平线， 留给世界的只能是背影 。 我不去想， 未来是平坦还是泥泞 ， 只要热爱生命 ， 一切，都在意料之中。 决心 人之一生，总会有许多困惑不已、纠缠不清的琐事，难免受其影响，绝不为其左右。 此时所需的就是断然的取舍与明智的抉择，唯一会限制我们的，是我们自己的决心。 延续 万物善变，人生泛滥的是那些冲动和急躁：即兴的热情、肤浅的思考、仓促的决定、敷衍的搪塞和最终的草草了事； 而珍贵的是生命中那些经久和坚持，一种信仰，一段情感，一个习惯。一句独白自视为约定，一段感情权当作余生。 动力 如果说不清追逐的动力源于何处，就至少要让优秀成为自己的习惯，要乐观阳光，要知道自己身在何处，路在何方。 初心 愿我们在心底埋下的勇气、乐观和向善的种子，最后都成长为自己一直所追寻的最喜欢的样子。","tags":"Notes","url":"https://jiang-hao.com/articles/2019/notes-人之一生.html","loc":"https://jiang-hao.com/articles/2019/notes-人之一生.html"},{"title":"JQCloud: 一个前端生成美化标签云的简单JQuery插件","text":"因为博客需要，发现了一个生成美化简约风格的标签云的JQuery插件。 官网地址： http://mistic100.github.io/jQCloud/index.html 使用方法很简单，可以把JS和CSS文件下载到本地，也可以直接通过Script标签src=\"\"的方法在线引用。 具体的使用方法官网都能查到。 贴出自己微博使用JQCloud的前端代码： < script src = \"{{ SITEURL }}/theme/jqcloud.js\" ></ script > < link href = \"{{ SITEURL }}/theme/jqcloud.css\" rel = \"stylesheet\" > < script > var words = []; { % for tag , articles in tags | sort % } words . push ({ text : \"{{tag}}\" , weight : Math . random (), link : '{{ SITEURL }}/{{ tag.url }}' }); { % endfor % } { % for category , articles in categories % } words . push ({ text : \"{{category}}\" , weight : Math . random (), link : '{{ SITEURL }}/{{ category.url }}' }); { % endfor % } $ ( function () { $ ( \"#tagcloud\" ). jQCloud ( words , { autoResize : true }); }); </ script > < div id = \"tagcloud\" style = \"width: 80%; height: 450px; align-self: center;\" ></ div > 需要注意的是要包含标签云的div模块需要显示指定width和height，否则需要在JavaScript中进行相关设置。 踩坑1：因为要基于JQuery，注意引用的JQuery库可用。由于之前引用的是外网谷歌的库，国内被墙导致标签云一直没有刷出来，后来换成了bootcdn的JQuery库就成功了： < script src = \"https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js\" ></ script >","tags":"Frontend","url":"https://jiang-hao.com/articles/2018/frontend-JQCloud.html","loc":"https://jiang-hao.com/articles/2018/frontend-JQCloud.html"},{"title":"使用Pelican在Github(国外)和Coding(国内)同步托管博客","text":"介绍： Github Pages 禁用了百度爬虫，因此百度搜索引擎经常抓取不到在Github上托管的博客链接。本文介绍一种可行的解决方法： - 注册Coding用来托管一份和Github上一样的博客仓库专门服务国内的索引 - 配置DNS解析，将国内的线路解析到Coding，国外的线路解析到Github - 配置Pelican，支持一键将同一份本地博客仓库同时发布到Github和Coding ​ 一、 《Pelican＋Github博客搭建详细教程》 按照标题链接给出的教程先搭建出一个基于Github托管的博客系统。接下来将说明如何将博客同步到Coding。 二、在Coding创建一个新的项目 在 Coding首页 进行注册并登陆，创建项目的方法与Github类似，不同之处在于coding新建的公开项目名和用户名相同，而不像Github那样是<用户名>.github.io。创建完成后，生成的新的项目链接应该类似于： https://coding.net/<usrname>/<username>.git 。 将本地SSH公钥拷贝到coding。操作同样与Github类似。由于本地已经为Github生成了一个公钥，这里只用cd进入~/.ssh文件夹查看一个名为 id_rsa.pub 文件的内容，类似于如下。我们只拷贝 邮箱之前 的所有内容到coding的公钥管理页面。 ssh-rsa AAAAfafjIJGOF+FDA。。(省略)。。Ksap Heriam@users.noreply.github.com 三、将仓库拷贝到Coding 进入Pelican的output目录下的本地博客仓库，打开.git/config，修改远程仓库，将 origin 改为 github，并添加 coding： [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true [remote \"github\"] url = git@github.com:Heriam/heriam.github.io.git fetch = +refs/heads/*:refs/remotes/github/* [remote \"coding\"] url = git@git.coding.net:Heriam/heriam.git fetch = +refs/heads/*:refs/remotes/coding/* [branch \"master\"] remote = origin merge = refs/heads/master 2. 然后将仓库 push 到 Coding上，在Coding新建一个 coding-pages 分支： git push -u coding master:coding-pages 3. 这时登录Coding就可以看到博客内容已经被拷贝到coding-pages分支。 四、配置域名 登录到网站的域名解析管理页面（我用的是DNSPOD，后来转向Cloudxns），然后添加两条域名解析记录： @ CNAME 国内 coding.me www CNAME 国内 coding.me 在Coding 上\"项目管理\"中找到\"自定义域名／Pages\"，添加要绑定的域名，比如我是 jiang-hao.com 和 www.jiang-hao.com 。注意这些域名也就是我们刚刚在dnspod中设置的解析域名。 五、配置Pelican实现同步提交 设置一键上传：（如有疑问参见 《Pelican＋Github博客搭建详细教程》 第三部分第4点）打开根目录下的Makefile文件，修改以下三个地方： OUTPUTDIR OUTPUTDIR=$(BASEDIR)/output/<username>.github.io #本地博客仓库路径 - publish publish: $(PELICAN) $(INPUTDIR) -o $(OUTPUTDIR) -s $(CONFFILE) $(PELICANOPTS) - github: publish github : publish cd $ ( OUTPUTDIR ) ; git add . ; git commit - am '<添加自己的备注>' ; git push github master : master ; git push coding master : coding - pages 这样 ，通过 make github 命令就能一键发布博客更新到Github和Coding了。","tags":"Frontend","url":"https://jiang-hao.com/articles/2018/frontend-使用Pelican在Github和Coding同步托管博客.html","loc":"https://jiang-hao.com/articles/2018/frontend-使用Pelican在Github和Coding同步托管博客.html"},{"title":"使用Pelican基于Github Pages搭建博客教程","text":"操作系统： Mac OS / Linux 工具集： 1.Pelican——基于Python的静态网页生成器 2.马克飞象——Evernote出的Markdown文本编辑器 3.GoDaddy——域名供应商 4.DNSPod——提供免费域名解析注册服务 5.Github Pages——Github为每个注册用户提供300M的站点空间 6.Python——Pelican工具需要Python运行环境 7.Google Analytics——谷歌站点数据监测分析工具 8.Google Custom Search——谷歌自定义搜索引擎可用作站内搜索工具 9.Google Webmasters——谷歌站长工具 10.Disqus——用来提供博客评论功能 11.Sitemap——站点地图，供谷歌，百度等搜索引擎收录 12.七牛云存储——静态资源管理，上传自动生成网盘直链 最终效果展示： 欢迎访问我的博客 ：https://jiang-hao.com 一、使用Github Pages创建个人博客页面 Git是一个开源的分布式版本控制系统，用以有效、高速的处理从很小到非常大的项目版本管理。GitHub可以托管各种git库的站点。通过GitHub Pages生成的静态站点，可以免费托管、自定义主题、并且自制网页界面。 ​ 1.首先到Github进行账号注册： https://github.com/ 。 2.注册后登录Github，右上角点击\"Creat a new repo\"，跳转到新页面后填写相关内容，注意版本库名使用'username.github.io'的格式，这里将username替换成自己的用户名即可。 3.设置和选择好页面模板后就可以生成然后发布新网页了。 4.创建SSH密钥并上传到Github。 ​ ​ *以上内容都很简单，有问题可以参照： 关于Github注册登录： 通过GitHub创建个人技术博客图文详解1 关于Github页面生成： 通过GitHub创建个人技术博客图文详解2 关于SSH认证： Windows/Mac下使用SSH密钥连接Github 官方文档： Github官方文档在这里 二、安装Python、Pelican和Markdown Pelican是一套开源的使用Python编写的博客静态生成, 可以添加文章和和创建页面, 可以使用MarkDown reStructuredText 和 AsiiDoc 的格式来抒写, 同时使用 Disqus评论系统, 支持 RSS和Atom输出, 插件, 主题, 代码高亮等功能, 采用Jajin2模板引擎, 可以很容易的更改模板。 ​ 1.安装Python。最新的Mac OS 一般都自带Python环境。在终端输入\"python\"即可确认Python版本。如有需要可以到官网安装：http://www.python.org/。 ​ 2.安装Pelican。可以从github克隆最新的代码安装, 并且建议在virtualenv下使用。首先建立 virtualenv（Python虚拟环境）: virtualenv pelican # 创建 cd pelican sh bin/activate # 激活虚拟环境 从github克隆最新代码安装Pelican： git clone git://github.com/getpelican/pelican.git # 下载代码 cd pelican python setup.py install 3.安装Markdown: pip install markdown 三、创建博客骨架 接下来将通过初始化Pelican设置来生成一个基本的博客框架。 ​ 1.搭建博客目录： mkdir blog cd blog pelican-quickstart 2.根据提示一步步输入相应的配置项，不知道如何设置的接受默认即可，后续可以通过编辑pelicanconf.py文件更改配置。完成后将会在根目录生成以下文件： . |-- content # 所有文章放于此目录 │ └── (pages) # 存放手工创建的静态页面 |-- develop_server.sh # 用于开启测试服务器 |-- Makefile # 方便管理博客的Makefile |-- output # 静态生成文件 |-- pelicanconf.py # 配置文件 |-- publishconf.py # 配置文件 3.进入output文件夹，把自己刚刚建好的username.github.io版本库clone下来，注意这里以及后文中的username要替换成自己的Github用户名： cd output git clone https://github.com/username/username.github.io.git 4.设置一键上传部署到Github。打开根目录下的Makefile文件，修改以下三个地方： OUTPUTDIR=$(BASEDIR)/output/username.github.io publish: $(PELICAN) $(INPUTDIR) -o $(OUTPUTDIR) -s $(CONFFILE) $(PELICANOPTS) github: publish cd OUTPUTDIR ; git add . ; git commit -am 'your comments' ; git push 5.设置完后，以后写完文章就可以通过在blog根目录下执行\"make github\"进行一键部署了。 四、通过Markdown试写博文并上传Github发布 Markdown是当下非常流行的一种文本编辑语法，支持HTML转换，书写博文排版也方便快捷。 ​ 1.写一篇文章：用 马克飞象 编辑器用Markdown语法来写一篇文章保存为.md格式放在content目录下。写完后，执行以下命令，即可在本机http://127.0.0.1:8000看到效果。 make publish make serve 2.创建一个页面：这里以创建 About页面为例。在content目录创建pages子目录： mkdir content/pages *然后创建About.md并填入下面内容： title : About Me date : 2013 - 04 - 18 About me content *注意上面title和date是.md文件的重要参数，需要写在文档开头。比如： Title : Pelican + Github Date : 2014 - 10 - 07 22 : 20 Modified : 2014 - 10 - 07 23 : 04 Tags : python , pelican Slug : build - blog - system - by - pelican Authors : Joey Huang Summary : blablablablablablablabla ... Status : draft 相关介绍请参见官方文档：http://pelican-zh.readthedocs.org/en/latest/zh-cn/ 。完成后同样可以在本机http://127.0.0.1:8000看效果。 ​ 3.创建导航目录项：Menu Item设置。在你的博客中，可设置相应的菜单项，菜单项是通过pelicanconf.py设置的，具体如下所示： MENUITEMS = ((\"ITEM1\",\"http://github.com\"), (\"ITEM2\",URL), ......) 五、安装主题 这里以主题bootstrap2为例，同样还在blog目录下： git clone https://github.com/getpelican/pelican-themes.git cd pelican-themes pelican-themes -i bootstrap2 对应在在pelicanconf.py中添加主题选择条目： THEME = 'bootstrap2' 六、安装第三方评论系统Disqus 在Disqus上申请一个站点，记住shortname。 在pelicanconf.py添加： DISQUS_SITENAME = Shortname 七、添加Google Analytics 去Google Analytics申请账号并通过验证，记下跟踪ID（Track ID）， 在pelicanconf.py添加： GOOGLE_ANALYTICS = '跟踪ID' 八、添加Google Webmasters和百度站长收录 为了让博客被Google更好的收录，比如手动让Googlebot抓取、提交Robots、更新Sitemap等等。 ​ 1.在Google Webmasters上注册并通过验证。 ​ 2.添加sitemap插件。还是到/blog目录下执行： cd ~/blog git clone git://github.com/getpelican/pelican-plugins.git *然后在pelicanconf.py里配置如下： PLUGIN_PATH = u\"pelican-plugins\" PLUGINS = [\"sitemap\"] SITEMAP = { \"format\": \"xml\", \"priorities\": { \"articles\": 0.7, \"indexes\": 0.5, \"pages\": 0.3, }, \"changefreqs\": { \"articles\": \"monthly\", \"indexes\": \"daily\", \"pages\": \"monthly\", } } 3.将make github命令后在output目录下生成的sitemap文件上传到Google Webmasters。 ​ 4.对于百度。它是宣称支持sitemap的，但是网上相关问题一大堆，要么格式不对要么就是抓取失败，要么突然不开放支持。在几次尝试失败以后，我是通过添加JavaScript代码来自动推送网站链接的。具体是在主题模板（base.html）面最后添加代码： <script> (function(){ var bp = document.createElement('script'); bp.src = '//push.zhanzhang.baidu.com/push.js'; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(bp, s); })(); </script> *我还是比较推崇这种方法的，因为比sitemap方法被抓取收录的时间短很多。谷歌的sitemap是xml格式。 九、添加谷歌／百度站内搜索 谷歌站内搜索 1.修改主题。找到这个主题的templates文件夹中的base.html，在 <div class=\"nav-collapse\"> 的最后，添加以下内容： <form class= \"navbar-search pull-right\" action= \"/search.html\" > <input type= \"text\" class= \"search-query\" placeholder= \"Search\" name= \"q\" id= \"s\" > </form> 2.创建search.html。之后，在output目录下，新建一个名为search.html的文件，写入下面的内容，其中需要你自己修改的是google站内搜索的ID号，需要自己在 google站内搜索 的网站上自己申请。 < html lang = \"zh_CN\" > < head > < meta charset = \"utf-8\" > < title > 站内搜索 </ title > </ head > < body > < style > #search - box { position : relative ; width : 50 % ; margin : 0 ; padding : 1 em ; } #search - form { height : 30 px ; border : 1 px solid #999 ; - webkit - border - radius : 5 px ; - moz - border - radius : 5 px ; border - radius : 5 px ; background - color : #fff ; overflow : hidden ; } #search - text { font - size : 14 px ; color : #ddd ; border - width : 0 ; background : transparent ; } #search - box input [ type=\"text\" ] { width : 90 % ; padding : 4 px 0 12 px 1 em ; color : #333 ; outline : none ; } </ style > < div id = 'search-box' > < form action = '/search.html' id = 'search-form' method = 'get' target = '_top' > < input id = 'search-text' name = 'q' placeholder = 'Search' type = 'text' /> </ form > </ div > < div id = \"cse\" style = \"width: 100%;\" > Loading </ div > < script src = \"http://www.google.com/jsapi\" type = \"text/javascript\" ></ script > < script type = \"text/javascript\" > google . load ( 'search' , '1' , { language : 'zh-CN' , style : google . loader . themes . V2_DEFAULT } ); google . setOnLoadCallback ( function () { var customSearchOptions = {} ; var customSearchControl = new google . search . CustomSearchControl ( '012191777864628038963:**********<!写入你申请的google站内搜索的ID号>）' , customSearchOptions ); customSearchControl . setResultSetSize ( google . search . Search . FILTERED_CSE_RESULTSET ); var options = new google . search . DrawOptions (); options . enableSearchResultsOnly (); customSearchControl . draw ( 'cse' , options ); function parseParamsFromUrl () { var params = {} ; var parts = window . location . search . substr ( 1 ). split ( '\\x26' ); for ( var i = 0 ; i < parts . length ; i ++ ) { var keyValuePair = parts [ i ] . split ( '=' ); var key = decodeURIComponent ( keyValuePair [ 0 ] ); params [ key ] = keyValuePair [ 1 ] ? decodeURIComponent ( keyValuePair [ 1 ] . replace ( / \\ +/ g , ' ' )) : keyValuePair [ 1 ] ; } return params ; } var urlParams = parseParamsFromUrl (); var queryParamName = \"q\" ; if ( urlParams [ queryParamName ] ) { customSearchControl . execute ( urlParams [ queryParamName ] ); } } , true ); </ script > </ body > </ html > 3.将GOOGLE_CUSTOM_SEARCH_SIDEBAR = \"001578481551708017171:axpo6yvtdyg\" 添加到pelicanconf.py文件。注意, 引号里的那一串字符是之前申请的自定义搜索引擎的id。 4.最后发布后就可以看到搜索框了。 ​ 百度站内搜索 1.在百度站长平台中注册一个账号，之后添加网站，按照提示验证网站。之后左侧 其他工具 中找到 站内搜索 ，按照提示填写基本信息，选择搜索框样式，之后点击 查看代码 ，复制其中内容，留用。 2.同样在base.html的这个 <div class=\"nav-collapse\"> 的最后，新建一个 div ，刚才注册最后复制的代码粘贴到这个 div 中： <div class= \"navbar-search pull-right\" > <script> <!略> </script> </div> 3.发布验证。 十、添加Tags侧边栏 在其他一些pelican主题中，看到有标签云，想到Tags的链接可能比Categories的链接更有用，通过更改主题，添加了侧栏中红框内的Tags链接框。 ​ 1.还是找到base.html，找到categories部分： {% if categories %} <div class= \"well\" style= \"padding: 8px 0; background-color: #FBFBFB;\" > <ul class= \"nav nav-list\" > <li class= \"nav-header\" > Categories </li> {% for cat , null in categories %} <li><a href= \" {{ SITEURL }} / {{ cat.url }} \" > {{ cat }} </a></li> {% endfor %} </ul> </div> {% endif %} 2.在这段后面添加： {% if tags %} <div class= \"well\" style= \"padding: 8px 0; background-color: #FBFBFB;\" > <ul class= \"nav nav-list\" > <li class= \"nav-header\" > Tags </li> {% for name , tag in tags %} <li><a href= \" {{ SITEURL }} / {{ name.url }} \" > {{ name }} </a></li> {% endfor %} </ul> </div> {% endif %} 3.保存，重新发布网页验证。 十一、插入视频 其实很简单, 只需要把html代码放进markdown源文件就行了! 而视频的html代码在视频网站上一般都会提供。复制下来放进源文件即可。 十二、拷贝静态文件 如果我们定义静态的文件，该如何将它在每次生成的时候拷贝到 output 目录呢，我们以网站logo图片sitelogo.ico为例，在我们的 content/extra 下放置网站的静态资源文件：sitelogo.ico，在pelicanconf.py更改或添加 FILES_TO_COPY项： FILES_TO_COPY = ( (\"extra/sitelogo.ico\", \"sitelogo.ico\"), ) 这样在每次生成html的时候都会把 content/extra下的 sitelogo.ico 拷贝到 output目录下。 十三、资源目录管理 使用目录名作为文章的分类名 USE_FOLDER_AS_CATEGORY = True 使用文件名作为文章或页面的 slug（url） FILENAME_METADATA = '(?P<slug>.*)' 页面的显示路径和保存路径，推荐下面的方式 ARTICLE_URL = '{category}/{slug}.html' ARTICLE_SAVE_AS = ARTICLE_URL PAGE_URL = '{slug}.html' PAGE_SAVE_AS = PAGE_URL CATEGORY_URL = '{slug}/index.html' CATEGORY_SAVE_AS = CATEGORY_URL TAG_URL = 'tag/{slug}.html' TAG_SAVE_AS = TAG_URL TAGS_SAVE_AS = 'tag/index.html' 十四、指定文章或页面URL 在需要指定URL的文章或者页面中包括两个元数据url与save_as，例如： url : pages /url/ save_as : pages /url/i ndex . html *这个代码指定了本篇文章的url为pages/url/index.html ​ ​ 根据上面很容易推断如何将一篇文章设置为网站的主页，如下代码即可实现将 content/pages/home.md 设为主页： Title: [www.yanyulin.info](http://www.yanyulin.info) Date: 2014-01-08 URL: save_as: index.html *另外还可以通过template:关键字来指定要使用的模板。 十五、独立域名设置 详见：http://www.jianshu.com/p/252b542b1abf Godaddy上购买专属域名，用dnspod进行动态域名解析，步骤如下: 步骤1：修改Godaddy中的NameServers的两个地址为dnspod的DNS地址： f1g1ns1.dnspod.net f1g1ns2.dnspod.net 步骤2：在Dnspod中添加一条A记录，指向Github URL username.github.io 步骤3：在Pelican主目录，即上面创建的blog/output/username.github.io目录，添加CNAME文件，在文件中添加你的独立域名。 ​ ​ *注意这里的CNAME建议放在第十二步提到的content目录下的静态子目录 content/extra 下，并在配置文件中添加相关条目。 十六、相关文章、上下文导航 1.打开pelicanconf.py，定义插件目录和启用插件： #加载plugins PLUGIN_PATH = \"plugins\" PLUGINS = [\"sitemap\",\"neighbors\",\"related_posts\"] #sitemap SITEMAP = { 'format': 'xml', 'priorities': { 'articles': 0.7, 'indexes': 0.8, 'pages': 0.5 }, 'changefreqs': { 'articles': 'monthly', 'indexes': 'daily', 'pages': 'monthly' } } #相关文章 RELATED_POSTS_MAX = 10 2.邻居导航，在主题模版中调用如下代码，可根据自己的情况修改： <div class= \"pagination\" > <ul> {% if article.prev_article %} <li class= \"prev\" ><a href= \" {{ SITEURL }} / {{ article.prev_article.url }} \" > ← Previous </a></li> {% else %} <li class= \"prev\" ><a href= \"/\" > ← Previous </a></li> {% endif %} <li><a href= \"/archives.html\" > Archive </a></li> {% if article.next_article %} <li class= \"next\" ><a href= \" {{ SITEURL }} / {{ article.next_article.url }} \" > Next → </a></li> {% else %} <li class= \"next\" ><a href= \"/\" > Next → </a></li> {% endif %} </ul> </div> 3.相关文章： {% if article.related_posts %} <h4> Related Articles </h4> <ul> {% for related_post in article.related_posts %} <li><a href= \" {{ SITEURL }} / {{ related_post.url }} \" > {{ related_post.title }} </a></li> {% endfor %} </ul> {% endif %} 十七、最后，一些比较占空间的资源文件（图片、媒体等）可以用七牛来进行存储管理","tags":"Frontend","url":"https://jiang-hao.com/articles/2018/frontend-使用Pelican基于GithubPages搭建博客教程.html","loc":"https://jiang-hao.com/articles/2018/frontend-使用Pelican基于GithubPages搭建博客教程.html"},{"title":"Build and Install OpenDaylight on Ubuntu","text":"Operating System：Linux x64 / Ubuntu 14.04 Prerequisites：Linux system with Java and Maven installed Chinese version is also available at Ubuntu系统下OpenDaylight源码编译安装 STEP 1, Environment Tuning 1. Install Git tool by command line: sudo apt-get install git-core 2. After the installation of Java and Maven, you need to edit a very important file for OpenDaylight which is named \"settings.xml\". It can customize the behavior of Maven at system level. But we often choose to make it in ~/.m2 folder under your home directory to limit it in user scope： (under ~/ directory) mkdir .m2 cp -n ~/.m2/settings.xml{,.orig} ; \\wget -q -O - https://raw.githubusercontent.com/opendaylight/odlparent/master/settings.xml > ~/.m2/settings.xml You can also use this command instead: curl https://raw.githubusercontent.com/opendaylight/odlparent/master/settings.xml --create-dirs -o ~/.m2/settings.xml 3. A new settings.xml file should now appear in the folder you just created, go and check the content, which should be something similar as below： # gedit ~/.m2/settings.xml <settings xmlns= \"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\" > <profiles> <profile> <id> opendaylight-release </id> <repositories> <repository> <id> opendaylight-mirror </id> <name> opendaylight-mirror </name> <url> http://nexus.opendaylight.org/content/repositories/public/ </url> <releases> <enabled> true </enabled> <updatePolicy> never </updatePolicy> </releases> <snapshots> <enabled> false </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> opendaylight-mirror </id> <name> opendaylight-mirror </name> <url> http://nexus.opendaylight.org/content/repositories/public/ </url> <releases> <enabled> true </enabled> <updatePolicy> never </updatePolicy> </releases> <snapshots> <enabled> false </enabled> </snapshots> </pluginRepository> </pluginRepositories> </profile> <profile> <id> opendaylight-snapshots </id> <repositories> <repository> <id> opendaylight-snapshot </id> <name> opendaylight-snapshot </name> <url> http://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </repository> </repositories> <pluginRepositories> <pluginRepository> <id> opendaylight-snapshot </id> <name> opendaylight-snapshot </name> <url> http://nexus.opendaylight.org/content/repositories/opendaylight.snapshot/ </url> <releases> <enabled> false </enabled> </releases> <snapshots> <enabled> true </enabled> </snapshots> </pluginRepository> </pluginRepositories> </profile> </profiles> <activeProfiles> <activeProfile> opendaylight-release </activeProfile> <activeProfile> opendaylight-snapshots </activeProfile> </activeProfiles> </settings> STEP 2, Build and Install OpenDaylight Controller Project Please keep in mind that here controller really means core controller without many other additional features, such as WebUI(dlux). As for the development of other features in OpenDaylight and if you need dlux, please refer to next STEP. 1.Create a directory for your project and get the source code of OpenDaylight controller: mkdir openDayLight cd openDayLight git clone https://git.opendaylight.org/gerrit/p/controller.git 2.Specify the version of OpenDaylight you want to build and check: cd controller git checkout stable/lithium //here I specify stable/lithium version git branch 3.Make sure your settings.xml file is right in place. Build the code with Internet connecdtion: mvn clean install -DskipTests 4.Now run your controller: cd controller/karaf/opendaylight-karaf/target/assembly ./bin/karaf 5.And after a while you will enter the OpenDaylight command line mode as shown below: opendaylight-user@root> 6.Some useful command lines to check and install features: feature : list - i //show the features which are already installed feature : list //show all available features (installed ones are marked with \"x\") feature : list | grep < keyword > //show features that contains <keyword> feature : install < feature > //install a <feature> STEP 3, Build and Install OpenDaylight Integration Project Integration Project is more like a framework project which is to integrate all other projects into OpenDaylight. With Integration project you can modify or put your own features under this project directory and test with the controller. 1.Download the Integration source code: git clone https://git.opendaylight.org/gerrit/p/integration.git 2.Get into the integration directory and specify the version you want: cd integration git checkout stable/lithium mvn clean install -DskipTests 3.After previous step is done, you may would like to run the controller: cd integration/distributions/karaf/target/assembly ./bin/karaf 4.Finally you can now begin your development and replace original features with your own ones under this directory, after which you would be able to build and run the controller for testing: username@ubuntu:~/developApps/openDayLight/integration/distributions/karaf/target/assembly/system/org/opendaylight$ ls aaa integration neutron sdninterfaceapp usc bgpcep iotdm nic sfc vpnservice capwap l2switch odlparent snmp vtn controller lacp sxp yangtools coretutorials lispflow mapping tcpmd5 didm mdsal ovsdb topoprocessing dlux nemo packetcable tsdr groupbasedpolicy netconf reservation ttp （END）","tags":"Backend","url":"https://jiang-hao.com/articles/2018/backend-BuildandInstallOpenDaylightonUbuntu.html","loc":"https://jiang-hao.com/articles/2018/backend-BuildandInstallOpenDaylightonUbuntu.html"},{"title":"Windows系统配置WiFi无线热点","text":"Windows 版本： Windows 7/8/10 前提：电脑装配无线网卡 方法：通过Dos命令行创建WiFi热点，然后启用共享 1.首先确定无线网卡是否支持承载网络（Hosted Network）。在管理员模式的CMD窗口输入命令： netsh wlan show drivers 在输出信息中找到 \"支持承载网络：是\" 则继续。 2.确定电脑是否已经配置承载网络。同样在CMD窗口分别输入命令： netsh wlan show hostednetwork netsh wlan show hostednetwork setting=security 如果看到第一条命令输出已经配置好的WiFi热点的SSID，第二条输出WiFi热点的密码，直接跳到第四步。 3.创建WiFi热点。命令行输入： netsh wlan set hostednetwork mode=allow ssid=WiFi名称 key=WiFi密码 完成后提示承载网络设置成功。 4.启用WiFi热点。在命令行输入： netsh wlan start hostednetwork 完成后提示已启动承载网络。 5.启用WiFi热点共享。打开 \"网络和共享中心\"，在窗口左边栏找到 \"更改适配器设置\"，再在窗口右侧找到刚刚创建的WiFi网络，一般显示为 \"本地连接\"，记住。如下所示 在以太网的网络连接图标上点击右键选择属性，在弹出的窗口上方标签栏点击 \"共享\"。然后在下方确认框中启用 \"允许其它网络用户通过此计算机的 Internet连接来连接(N)\"。如下所示，下拉框中选择刚刚创建的WiFi热点，确定，完成。 （完）","tags":"Tools","url":"https://jiang-hao.com/articles/2017/tools-WifiHotSpotOnWindows.html","loc":"https://jiang-hao.com/articles/2017/tools-WifiHotSpotOnWindows.html"},{"title":"Ubuntu系统Apache Maven安装","text":"操作系统：Linux x64 / Ubuntu 14.04 Apache Maven版本：3.3.9 建议预先搭建Java开发环境：详见 《Linux Ubuntu系统下Java开发环境搭建》 1. 前往Apache Maven官网下载最新版本：https://maven.apache.org/download.cgi，本文以apache-maven-3.3.9-bin.tar.gz为例。 2. 在合适的路径下创建文件夹用来存储Maven，本例选择在/opt目录下新建MVN子文件夹。打开Terminal（后文成为T1），输入： cd /opt #进入到opt目录 sudo mkdir mvn #新建一个mvn文件夹 ls #显示成功新建的mvn文件夹 cd mvn #进入mvn文件夹 3.将下载的MVN压缩包拷贝到mvn目录下。新建另一个Terminal窗口（T2）并输入： cd Downloads #进入Downloads文件夹 ls #显示刚刚下载的MVN文件， sudo cp apache-maven-3.3.9-bin.tar.gz /opt/mvn #将文件拷贝到刚刚新建的mvn文件夹中(这里将\"< >\"部分替代为自己对应的MVN文件名，后同) sudo rm apache-maven-3.3.9-bin.tar.gz #删除本目录下的安装包（可选） 4.解压安装MVN，配置环境变量。回到第一个Terminal（T1），输入： ls #显示拷贝过来的MVN安装包 sudo tar -zxvf apache-maven-3.3.9-bin.tar.gz #将安装包解压 ls #显示解压出的MVN文件夹，以及原安装包 sudo rm apache-maven-3.3.9-bin.tar.gz #删除原安装包 sudo gedit /etc/profile #打开etc目录下的profile文件 5.配置全局环境变量。在打开的profile文档末尾添加MVN安装路径（需仔细确认）： #set maven environment export M2_HOME=/opt/mvn/apache-maven-3.3.9 export MAVEN_OPTS=\"-Xmx1024m\" #避免内存溢出错误（可选） export PATH= ${ M2_HOME } /bin: ${ PATH } 6.保存并关闭文档。（注：也可以通过vim 命令编辑etc/profile，打开命令：sudo vim /etc/profile，按 键进入编辑模式， 键退出编辑模式，接着按\":\"再输入\"wq!\"保存并退出；输入\"q!\"不保存退出） 7.启用配置并验证。在Terminal输入： mvn -v 8.显示效果类似如下： Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T08:41:47-08:00) Maven home: /opt/developTools/jvm/apache-maven-3.3.9 Java version: 1.8.0_65, vendor: Oracle Corporation Java home: /opt/developTools/jvm/jdk1.8.0_65/jre Default locale: en_US, platform encoding: UTF-8 OS name: \"linux\", version: \"3.19.0-25-generic\", arch: \"amd64\", family: \"unix\" （完）","tags":"Backend","url":"https://jiang-hao.com/articles/2017/backend-Ubuntu系统ApacheMaven安装.html","loc":"https://jiang-hao.com/articles/2017/backend-Ubuntu系统ApacheMaven安装.html"},{"title":"Ubuntu系统Java开发环境的搭建","text":"操作系统：Linux x64 / Ubuntu 14.04 Java JDK版本：jdk-8u65-linux-x64.tar.gz 1. 前往ORACLE官网下载最新版本的Java JDK：http://www.oracle.com/technetwork/java/javase/downloads/index.html，默认下载到Downloads文件夹。 2. 在合适的路径下创建文件夹用来存储Java JDK，本例选择在/opt目录下新建JVM子文件夹。打开Terminal（后文成为T1），输入： cd /opt sudo mkdir jvm ls cd jvm 3.将下载的JDK压缩包拷贝到jvm目录下。新建另一个Terminal窗口（T2）并输入： cd Downloads ls sudo cp jdk-8u65-linux-x64.tar.gz /opt/jvm sudo rm jdk-8u65-linux-x64.tar.gz 4.解压安装Java JDK，配置环境变量。回到第一个Terminal（T1），输入： ls sudo tar -zxvf jdk-8u65-linux-x64.tar.gz ls sudo rm jdk-8u65-linux-x64.tar.gz sudo gedit /etc/profile 5.配置全局环境变量。在打开的profile文档末尾添加JDK安装路径（需仔细确认）： #set java environment export JAVA_HOME=/opt/jvm/jdk1.8.0_65 export JRE_HOME= ${ JAVA_HOME } /jre export CLASSPATH=.: $JAVA_HOME /lib: $JRE_HOME /lib: $CLASSPATH export PATH= $JAVA_HOME /bin: $JRE_HOME /bin: $PATH 6.保存并关闭文档。（注：也可以通过vim 命令编辑etc/profile，打开命令：sudo vim /etc/profile，按 键进入编辑模式， 键退出编辑模式，接着按\":\"再输入\"wq!\"保存并退出；输入\"q!\"不保存退出） 7.启用配置并验证。在Terminal输入： java -version 8.显示效果类似如下： java version \"1.8.0_65\" Java(TM) SE Runtime Environment (build 1.8.0_65-b17) Java HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode) （完）","tags":"Backend","url":"https://jiang-hao.com/articles/2017/backend-Ubuntu系统Java开发环境的搭建.html","loc":"https://jiang-hao.com/articles/2017/backend-Ubuntu系统Java开发环境的搭建.html"},{"title":"Install & Run Gedit from Terminal on Mac","text":"App description: gedit (App: gedit.app) App website: https://wiki.gnome.org/Apps/Gedit Install from Terminal 1.Run: ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" < / dev / null 2 > / dev / null ; brew install caskroom / cask / brew-cask 2 > / dev / null 2.After the command finishes, run: brew cask install gedit Now Gedit is installed. Run Gedit from Terminal Solution 1. Add the following line to ~/.profile or ~/.bash_profile: export PATH=/Users/<Username>/Applications/gedit.app/Contents/MacOS/gedit: $ PATH Solution 2. Create a script named gedit in /usr/local/bin and make it executable: a. Create a new file: sudo vim /usr/local/bin/gedit b. Add content as below, save and quit: 1 2 #!/bin/bash /Users/<Username>/Applications/gedit.app/Contents/MacOS/gedit c. Make it executable: sudo chmod 755 /usr/local/bin/gedit (END)","tags":"Tools","url":"https://jiang-hao.com/articles/2017/tools-InstallAndRunGeditOnMac.html","loc":"https://jiang-hao.com/articles/2017/tools-InstallAndRunGeditOnMac.html"},{"title":"网页 BacktoTop 返回顶部按钮的简单实现","text":"在较长的网页页面中往往需要一个固定漂浮在显示屏右下侧位置的返回顶部按钮。 下面介绍一种简单实现： HTML 部分： < body > < a href = \"javascript:void(0);\" id = \"scroll\" title = \"Scroll to Top\" style = \"display: none;\" > Top < span ></ span ></ a > ... </ body > CSS 部分： # scroll { position : fixed ; right : 10 px ; bottom : 10 px ; cursor : pointer ; width : 50 px ; height : 50 px ; background-color : #2E435E ; text-indent : -9999 px ; display : none ; -webkit- border-radius : 5 px ; -moz- border-radius : 5 px ; border-radius : 5 px ; } # scroll span { position : absolute ; top : 50 % ; left : 50 % ; margin-left : -8 px ; margin-top : -12 px ; height : 0 ; width : 0 ; border : 8 px solid transparent ; border-bottom-color : #ffffff } # scroll : hover { background-color : #3498db ; opacity : 1 ; filter : \"alpha(opacity=100)\" ; -ms- filter : \"alpha(opacity=100)\" ; } JavaScript 部分： $ ( document ). ready ( function (){ $ ( window ). scroll ( function (){ if ( $ ( this ). scrollTop () > 100 ){ $ ( '#scroll' ). fadeIn (); } else { $ ( '#scroll' ). fadeOut (); } }); $ ( '#scroll' ). click ( function (){ $ ( \"html, body\" ). animate ({ scrollTop : 0 }, 600 ); return false ; }); }); 最后的显示效果可以参照本博客：）","tags":"Frontend","url":"https://jiang-hao.com/articles/2017/frontend-网页BackToTop返回顶部按钮的简单实现.html","loc":"https://jiang-hao.com/articles/2017/frontend-网页BackToTop返回顶部按钮的简单实现.html"},{"title":"CSS伪类content: url放图片如何改变图的大小","text":"遇到过一个问题：用before after 之类的伪类的content里放一个图的链接，如何去改图的大小？比如： . nav ul li : after { content : url ( ../img/nav_fg.png ); } 事实上，如果想要设置前端页面通过content：url显示出来的图片大小，那只能修改图片的大小。因为它是直接读取的图片，并不是代入到html中再显示出来。但可以采用background的方式调整图片的大小，比如本博客中学术社交网站ResearchGate的Logo的CSS显示代码如下： . social a [ href *= 'researchgate.net' ] : before { background-image : url ( './images/icons/researchgate.png' ); background-size : 100 % ; display : inline-block ; margin-right : 2 px ; vertical-align : -3 px ; height : 16 px ; width : 16 px ; content : \"\" ; } 其中 content=\"\", height, width, background-size, display, background-image 都必须显示指定。这样，就可以通过 height, width 来分别设置图片的长和宽了。","tags":"Frontend","url":"https://jiang-hao.com/articles/2017/frontend-CSS伪类contenturl放图片如何改变图的大小.html","loc":"https://jiang-hao.com/articles/2017/frontend-CSS伪类contenturl放图片如何改变图的大小.html"},{"title":"Install Wireshark on Ubuntu","text":"1. Download WIreshark source code on website: https://www.wireshark.org/download.html 2. Extract files into targeted folder: tar -xvf wireshark-1.10.7.tar.bz2 3. Install compiling tools and dependencies: sudo apt-get install build-essential sudo apt-get install libgtk2.0-dev libglib2.0-dev sudo apt-get install checkinstall sudo apt-get install flex bison sudo apt-get build-dep wireshark sudo apt-get install qt5-default sudo apt-get install libssl-dev sudo apt-get install libgtk-3-dev 4. Go to www.tcpdump.org and find newest version of libpcap(e.g., libpcap-1.5.3.tar.gz): #tar -xvf libpcap-1.5.3.tar.gz #cd libpcap-1.5.3.tar.gz #./configure #make #make install 5. Go to wireshark folder: ./autogen.sh ./configure --with-ssl --enable-setcap-install make make install","tags":"Tools","url":"https://jiang-hao.com/articles/2016/tools-InstallWiresharkonUbuntu.html","loc":"https://jiang-hao.com/articles/2016/tools-InstallWiresharkonUbuntu.html"},{"title":"法国的一些著名的精油品牌","text":"法国精油品牌： Florial (Florihana) (芙梦丽娜) L'OCCITANE ( 欧舒丹 ) Sanoflore (圣芙兰) CAMENAE (嘉媚乐) NUXE ( 欧树 ) SISLEY ( 希思黎 ) 1. Florial (Florihana) —— F家 品牌： 在欧洲被视为法国第一医疗等级的有机认证植物精油品牌，多年来一直深受着各国芳疗界的喜爱。拥有世界上独一无二的特殊蒸馏技术，采用人工采集和产油率极低的低温、低压、缓慢的蒸馏技术来提炼精油。包装瓶选用一种特殊的绿色玻璃来装载精油，此种瓶子不但可阻挡一般的阳光，还有过滤紫外线和红外线的作用，方便精油更好的保持原型状态。此外，F家的有机精油品种丰富，其中尤其纯露做的非常好，属于世界顶级行列。唯一的一点瑕疵是这家的产地有些并不是非常好（其实也很好理解，算是多品种的机会成本吧）。 公司： J.E Internatioanl (Florihana、Florial商标所有人)公司总部设立在法国的南部，于国家级自然保护区内的科斯高山（Caussols plateau）上。创办人MR. Durante Alain 系工程师出身。自1993年开始从事精油萃取及芳疗推广事业，用近15年的时间，终于创立出Florial和Florihana品牌。 明星产品： 永久花纯露 ( HELICHRYSUM ITALIAN ORGANIC ) 标签： 法国知名精油品牌 2. L'OCCITANE—— 欧舒丹 品牌： 全称L'OCCITANE EN PROVENCE（法语发音：[lɔksiˈtan ɑ ̃pʁɔvɑ̃s]，意即\"普罗旺斯的欧舒丹\")。产品是以普罗旺斯丰富的自然草本植物为原料，用优质的植物由传统方法制造开发而成。每一个产品系列都有其独特传奇：薰衣草、橄榄、马鞭草及蜂蜜节发扬法国普罗旺斯的传统，蜡菊细诉科西嘉岛的故事，乳木果油是非洲的传奇瑰宝。今天， 欧舒丹已成为在全球近60个国家开设逾550家分店的国际知名香氛护理品牌。 公司： 是一家专门制造及售卖个人护理产品及家居产品的国际零售企业，主要生产基地设于法国马诺斯克（Manosque）。 公司成立于1976年， 创办人为奥利维埃·博桑（Olivier Baussan）， 他希望建立一家保留并弘扬家乡普罗旺斯传统的公司。公司名字L'OCCITANE在法语中的意思是\"来自欧西坦尼亚的女人\"。欧舒丹希望\"透过提供独特的个人护理及家居产品，成为提倡地中海式舒适安康感觉的国际模范\"，并以\"舒适愉悦\"、\"真实纯净\"及\"关怀尊重\"等为企业理念。 明星产品： \"Aromachology\" 芳香身心疗法系列：以多种精油混合制成，将\"冥想\"的意境贯穿其中，能帮助身体与大自然沟通。整个系列有沐浴、洗发、润肤、按摩油和蜡烛等产品，其中以沐浴品最为畅销。 标签： 法国知名护理品牌 3. Sanoflore —— 圣芙兰 品牌： 法国芳香界一个很有地位的品牌，所有的原料都采自以有机种植的方式培育出的植物，是全球唯一全系列商品皆获得欧盟Ecocert与Cosmebio有机认证的品牌。SANOFLOR还有很多美容护肤类的产品如：玫瑰面油，按摩油，日霜，晚霜，眼霜等都用的有机植物的精华，而且最值得一提的是：它家产品里凡是需要添加水份的，都是添加的100%有机的花水。SANOFLORE共有6种花水，玫瑰，薰衣草，洋甘菊，橙花，金缕梅，矢车菊。目前，SANOFLORE产品涉及花草类（花草茶，花草药包）、芳香疗法（精油，花水）、有机美容护肤品和天然香料。 公司： 全世界最大有机植物原料供机商，就连法国SISLEY、DARPHIN，甚至是澳洲AESOP的精油成分及原料都来自于它。Sanoflore法文的原意指的是：\"健康的花朵\"。1972年，瑞士籍的地球及自然科学与地质学与商业管理研究所博士RodolpheBALZ，在法国普罗旺斯Drome的核心地带一片零污染的山丘上成立了第一座实验性的花园SanofloreLaboratory，生产出第一瓶花水；1986年，SANOFLORE正式成立了专门研究有机产品的实验室；1998年，Daniel RICHARD家族加入经营，将SANOFLORE介绍给全世界。 明星产品： 花水系列 标签： 法国知名精油品牌，世界最大有机植物原料提供商 4. CAMENAE —— 嘉媚乐 品牌： 源自法国普罗旺斯纯粹的人文精髓的化妆品品牌，应该算是最接中国\"地气\"的法国精油品牌之一了。自2003年进入中国市场以来，在一年的时间不下200余家专卖店和专柜相继开业，至今CAMENAE应该算是国内精油护肤品领域的佼佼者。2007年CAMENAE嘉媚乐成功获得欧盟ECO-CERT国际有机认证。品牌理念：善用精油，关注心灵，回归天然。 公司： CAMENAE，法国知名精油品牌，1970年创立于法国的普罗旺斯。从1970年创立起，至今已发展成为拥有逾3000家门店的超级连锁体系。2003年8月，CAMENAE在北京国贸开张了第一家中国旗舰店，宣告这一欧洲个人护理品牌正式挺进中国，同时启动中国区特许经营项目。 明星产品： \"橄榄精华系列\" 标签： 法国知名护理品牌，中国知名品牌 5. NUXE —— 欧树 品牌： 法国纯植物美容品牌，名字取自NATURE（自然）+LUXE（奢华），意喻该品牌是自然与奢华的完美的结合。NUXE 崇尚自然，创立伊始便坚持独创，注重优选成分，不一味追逐潮流，成为天然美学，回归自然的领导品牌。品牌理念：自然和大胆，效率和真实，性感与奢华，力求将植物的功效发挥到极致，结合\"自然、健康、美丽\"三大护肤要素，共同复兴先锋化妆品理念。在媒体和娱乐圈内对其给予的评价颇高。 公司： 由巴黎的一位药技师兼芳疗及植物疗法专家在1957年所创立，成立以来，研发了许多简单、温和、有效的美容保养品。企业精神：超越流行的限制，而秉持着绝对独立自主。1989 年由崇尚植物与芳香疗法的知名法国女企业家Aliza Jabes收购，经医疗级别的精密制作过程和严密的企业行销与品质塑造，更促使NUXE成为天然美学的教主品牌。 明星产品： 蜂蜜洁面系列，睡莲面霜，植物鲜奶面霜，花水系列等 标签： 法国知名纯植物美容品牌 6. SISLEY —— 希思黎 品牌： 品牌名称Sisley来自於19世纪法国印象派画家Alfred Sisley，因此可以想像这是个流著热血以及多情艺术的品牌。Sisley所有产品均以植物萃取精华与植物香精油作为主要成分，配以其独有配方研制而成，在品质、绝对的安全性和适用性上享有盛誉。产品主要涉及护肤、彩妆、美发和香水（希思黎夜幽情怀女士香水）。理念和定位：\"用科学印证植物美容的传说，以优质尊贵的产品，献给讲究的人士\"（通俗的说就是坚持高品质，然后高价位，护肤品中尊贵与优雅的经典代表）。 公司： 在1976年由法国修伯特．多纳诺伯爵创立，以当时欧洲最新的植物美容学为基础，成功地研创出来的植物性护肤品牌。是现今极少数仍由家族拥有、经营的化妆品品牌。全世界所有的Sisley护肤产品均出自法国巴黎工厂，以确保品牌产品的一致性。产品上市前必先经过皮肤科医生的测试，以确保产品的安全性。Sisley是少数被皮肤医学家认定为最安全的护肤品；即使是过敏性与敏感性肌肤，也可安心使用。 明星产品： Ecological Compound，Botanical D-TOX Detoxifying，Express Flower Gel, etc. 标签： 法国知名植物美容品牌 参考: 1. 十六番：法国购物攻略 2. 各品牌百度百科 3. 各品牌Wikipedia 4. 新欧洲.战斗在法国 5. 各品牌官网","tags":"Notes","url":"https://jiang-hao.com/articles/2016/notes-法国的一些精油品牌.html","loc":"https://jiang-hao.com/articles/2016/notes-法国的一些精油品牌.html"},{"title":"Install VMware Workstation in Ubuntu 14.04","text":"1. Use apt-get update system: linuxidc@localhost:~$ sudo apt-get update linuxidc@localhost:~$ sudo apt-get upgrade 2. Download VMware Workstation bundle. 3. Make bundle executable: linuxidc@localhost:~$ chmod a+x VMware-Workstation-Full-11.0.0-2305329.x86_64.bundle 4. Run the bundle: linuxidc@localhost:~$ sudo ./VMware-Workstation-Full-11.0.0-2305329.x86_64.bundle 5. Installation:","tags":"Tools","url":"https://jiang-hao.com/articles/2016/tools-InstallVMwareWorkstationinUbuntu14.04.html","loc":"https://jiang-hao.com/articles/2016/tools-InstallVMwareWorkstationinUbuntu14.04.html"},{"title":"Apache Shiro Multi-tenancy with JDBC MySQL","text":"0. GOALS - Provide user authentication and authorization for multi-tenant scenarios - Provide easy-to-maintain data storage with only one database - Provide domain-differentiated, credential-based authentication - Provide domain-differentiated, role-based, service-specific authorization; 1. QuickStart with Apache Shiro - English Documentation - Chinese Documentation - Example Applications - Architecture: 2. Environment Prerequisites Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T17:41:47+01:00) Maven home: /Library/Maven Java version: 1.7.0_79, vendor: Oracle Corporation Java home: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jre Default locale: en_US, platform encoding: UTF-8 OS name: \"mac os x\", version: \"10.11.2\", arch: \"x86_64\", family: \"mac\" 3. Apache Shiro Maven Dependency <dependency> <groupId> org.apache.shiro </groupId> <artifactId> shiro-core </artifactId> <version> 1.1.0 </version> </dependency> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-simple </artifactId> <version> 1.6.1 </version> <scope> test </scope> </dependency> 4. MySQL QuickStart 1. Install MySQL on Mac 2. 修改Root密码 3. W3Schools SQL Tutorial 4. W3School中文SQL教程 5. RUNOOB MySQL教程 5. Create Tables 1.User Table: 2.Domain_User Table: 3.User_Role Table: 4.Permission_Domain_Role Table: 6. JDBC Setup and Code Customization 1.Maven Dependency: <dependency> <groupId> mysql </groupId> <artifactId> mysql-connector-java </artifactId> <version> 5.1.25 </version> </dependency> <dependency> <groupId> com.alibaba </groupId> <artifactId> druid </artifactId> <version> 0.2.23 </version> </dependency> 2.Rewrite getPermissions method in jdbcRealm protected Set < String > getPermissions ( Connection conn , String username ) throws SQLException { PreparedStatement ps = null ; Set < String > permissions = new LinkedHashSet < String >(); try { ps = conn . prepareStatement ( permissionsQuery ); ps . setString ( 1 , username ); ResultSet rs = null ; try { // Execute query rs = ps . executeQuery (); // Loop over results and add each returned role to a set while ( rs . next ()) { String permissionString = rs . getString ( 1 ); // Add the permission to the set of permissions permissions . add ( permissionString ); } } finally { JdbcUtils . closeResultSet ( rs ); } } finally { JdbcUtils . closeStatement ( ps ); } return permissions ; } 3.Add getUserDomain method in jdbcRealm public Set < String > getUserDomain ( Connection conn , String username ){ PreparedStatement ps = null ; Set < String > domains = new LinkedHashSet <>(); try { ps = conn . prepareStatement ( userDomainQuery ); ps . setString ( 1 , username ); ResultSet rs = null ; try { rs = ps . executeQuery (); while ( rs . next ()) { String domainID = rs . getString ( 1 ); domains . add ( domainID ); } } catch ( SQLException e ) { e . printStackTrace (); } finally { JdbcUtils . closeResultSet ( rs ); } } catch ( SQLException e ) { e . printStackTrace (); } finally { JdbcUtils . closeStatement ( ps ); } return domains ; } 4.Rewrite doGetAuthenticationInfo method in jdbcRealm protected AuthenticationInfo doGetAuthenticationInfo ( AuthenticationToken token ) throws AuthenticationException { VTNAuthNToken upToken = ( VTNAuthNToken ) token ; String username = upToken . getUsername (); String domainID = Integer . toString ( upToken . getDomainId ()); // Null username is invalid if ( username == null ) { throw new AccountException ( \"Null usernames are not allowed by this realm.\" ); } Connection conn = null ; SimpleAuthenticationInfo info = null ; try { conn = dataSource . getConnection (); Set < String > domains = getUserDomain ( conn , username ); if (!( domains . contains ( domainID ))){ throw new AuthenticationException ( \"Domain not found\" ); } String password = null ; String salt = null ; switch ( saltStyle ) { case NO_SALT : password = getPasswordForUser ( conn , username )[ 0 ]; break ; case CRYPT : // TODO: separate password and hash from getPasswordForUser[0] throw new ConfigurationException ( \"Not implemented yet\" ); //break; case COLUMN : String [] queryResults = getPasswordForUser ( conn , username ); password = queryResults [ 0 ]; salt = queryResults [ 1 ]; break ; case EXTERNAL : password = getPasswordForUser ( conn , username )[ 0 ]; salt = getSaltForUser ( username ); } if ( password == null ) { throw new UnknownAccountException ( \"No account found for user [\" + username + \"]\" ); } info = new SimpleAuthenticationInfo ( username , password . toCharArray (), getName ()); if ( salt != null ) { info . setCredentialsSalt ( ByteSource . Util . bytes ( salt )); } } catch ( SQLException e ) { final String message = \"There was a SQL error while authenticating user [\" + username + \"]\" ; if ( log . isErrorEnabled ()) { log . error ( message , e ); } // Rethrow any SQL errors as an authentication exception throw new AuthenticationException ( message , e ); } finally { JdbcUtils . closeConnection ( conn ); } return info ; } 7. Setup Shiro.ini Configuration File [main] #authenticator authenticator = aaa.authn.VTNAuthenticator #(Customized) authenticationStrategy = org.apache.shiro.authc.pam.AtLeastOneSuccessfulStrategy authenticator.authenticationStrategy = $authenticationStrategy securityManager.authenticator = $authenticator #authorizer authorizer = aaa.authz.VTNAuthorizer #(Customized) permissionResolver = org.apache.shiro.authz.permission.WildcardPermissionResolver authorizer.permissionResolver = $permissionResolver securityManager.authorizer = $authorizer #Realm jdbcRealm = aaa.realms.MySQLRealm #(Customized) dataSource = com.alibaba.druid.pool.DruidDataSource dataSource.driverClassName = com.mysql.jdbc.Driver dataSource.url = jdbc:mysql://localhost:3306/vtn dataSource.username = root jdbcRealm.dataSource = $dataSource securityManager.realms = $jdbcRealm jdbcRealm.permissionsLookupEnabled = true #SQL Queries jdbcRealm.authenticationQuery = SELECT password FROM user WHERE user_name = ? jdbcRealm.userRolesQuery = SELECT role_id FROM user_role left join user using(user_id) WHERE user_name = ? jdbcRealm.permissionsQuery = SELECT distinct permission_id FROM perm_domain_role left join domain_user using(domain_id) left join user using(user_id) WHERE (domain_id, role_id) IN ( SELECT domain_id, role_id From user left join user_role using(user_id) left join domain_user using(user_id) WHERE user_name = ?) 8. Tips about SQL permissionsQuery in INI file: 1. Query with same parameter at two places: SELECT T . P FROM ( SELECT distinct permission_id as P , role_id AS R FROM perm_domain_role left join domain_user using ( domain_id ) left join user using ( user_id ) WHERE user_name = ? ) AS T WHERE T . R IN ( SELECT role_id FROM user_role left join user using ( user_id ) WHERE user_name = ? ) 2.Optimization with only one parameter: SELECT DISTINCT permission_id FROM perm_domain_role left join domain_user using ( domain_id ) left join user using ( user_id ) WHERE ( domain_id , role_id ) IN ( SELECT domain_id , role_id FROM user left join user_role using ( user_id ) left join domain_user using ( user_id ) WHERE user_name = ? ) 9. Result: Finally, you can easily test that each user has different services authorized by Shiro according to its tenant domain and its role. for ( VTNAuthNToken token : userTokenList ) { Mappable userRequest = new MappableMsg ( null , null , token ); for ( String service : servList ){ userRequest . setServID ( service ); if ( IShiro . getInstance (). isAuthorized ( userRequest )){ String entry = \"Domain \" + token . getDomainId ()+ \": \" + token . getUsername ()+ \": \" + service ; authZResult . add ( entry ); } } } for ( String i : authZResult ){ System . out . println ( i ); } Output: Domain 1: admin: vtn:topo:create Domain 1: admin: vtn:topo:read Domain 1: admin: vtn:topo:update Domain 1: admin: vtn:topo:delete Domain 1: admin: system:vtn:create Domain 1: admin: system:vtn:update Domain 1: admin: system:vtn:delete Domain 1: admin: serv:firewall:create Domain 1: admin: serv:firewall:read Domain 1: admin: serv:firewall:update Domain 1: admin: serv:firewall:delete Domain 1: boss: system:vtn:read Domain 2: tenant1: vtn:topo:create Domain 2: tenant1: vtn:topo:read Domain 2: tenant1: vtn:topo:update Domain 2: tenant1: vtn:topo:delete Domain 2: tenant1: serv:firewall:create Domain 2: tenant1: serv:firewall:read Domain 2: tenant1: serv:firewall:update Domain 2: tenant1: serv:firewall:delete Domain 2: guest1: vtn:topo:read Domain 2: guest1: serv:firewall:read Domain 3: tenant2: vtn:topo:create Domain 3: tenant2: vtn:topo:read Domain 3: tenant2: vtn:topo:update Domain 3: tenant2: vtn:topo:delete Domain 3: guest2: vtn:topo:read","tags":"Backend","url":"https://jiang-hao.com/articles/2016/backend-Shiro.html","loc":"https://jiang-hao.com/articles/2016/backend-Shiro.html"},{"title":"在难搞的日子里他们这样对你说","text":"城市：雷恩 2016年2月1日晚，距国内过新年还有7天。原本只是想要找一封早时候的项目电邮，结果不小心没把持住，泛滥着感慨时光飞逝的小情绪翻阅了一遍以往的邮件，感觉就像是在看旧照片，就像把从大一开始到现在的生活重新走了一遍。至今有很多需要感谢的人，值得纪念的事，我不想在忙碌中就这样让它们随时间流走。因为手里的东西总是忙不完，那些让你成长的却不总有机会不被遗忘。 2012-09-01/2013-08-27 大三 2012年大二暑假，由于本专业大类被限制转专业，我决定通过考取思科认证来自学网络技术。11月，虽然国创(SIETP)项目才刚立项一个月，SRTP项目已经立项半年，但是学习的重心从十月份起已经向网络方向偏移，整天脑子里除了思科的路由交换就是国创的建筑涂料，闲暇之余才能稍微顾及一下专业课程实习和考试，而SRTP项目已经打算彻底水漂过去了。这个过程持续了一年，准备出国又花了一年，期间发生了许多事——得到了许多人的帮助，也犯了不少傻事。 2012-09-Inquiry to Prof. Bai 我希望在本科毕业后往网络工程方向走。我的专业是农业资源与环境，但出于个人兴趣并且经过了慎重考虑后，我想在大学接下来的两年内考取CCIE，可自己目前几乎是零基础，暂时打算到欧朋兰博先报一个CCNA的培训班作为入门。我有一位高中同学（专业与计算机网络无关）在今年暑假拿到了CCIE认证，虽然有了他的建议和引导可以少走些弯路，但他毕竟不在自己身边许多事情还是需要自己去摸索。下面是我想咨询您的问题： 1. 学校有开设相关的培训课程吗？如果没有我又该如何充分利用本校的设备或者资源呢？ 2. 浙大有与CCIE对口的网络工程方面的硕士学位吗？或者其它与CCIE相关的深造项目或计划？ 3. 同学说CCIE的工作经验（项目资历）很重要，花两年时间去读研和工作那种更利于自己今后发展？ 4. 不考虑能力问题，拿到CCIE后出国是否是最佳选择？如果这就是我的规划，自己应该早作哪些准备？ 建议: 我印象中没有这种培训，不过为保险起见你可以打电话问问计算机学院办公室。社会上倒是有，但培训费用有点贵。我记得CCIE认证有面试的，要求当场调试网络的，所以肯定要有设备进行实验，但是学校机房里并没有这些设备的，估计要去问问计算机学院的相关实验室，具体哪里有我也不清楚。CCIE只是一个认证，硕士学位的培养不可能只局限于此的。具体有关计算机学院的硕士专业方向你可以查询计算机学院网站。CCIE认证拿到一般就是去工作赚钱了吧，没有必要再去读什么研了。因为读研主要就是学术方向，CCIE主要还是动手能力。如果出国去工作的话，是可以考虑的，不过去大城市如上海也一样可以赚大钱；如果出国去读研，那CCIE没有什么用。我印象中前几年CCIE很吃香，因为拿到这个认证的人非常少，现在什么行情我就不太清楚了。我觉得你以后的方向不能仅局限于这个CCIE，可以考虑把面放得更广一些，搞计算机主要是时效性太短，学东西花了很多精力很快就淘汰了，又得不断地学新东西，很累的。这一点不像医学、外语，可以吃老本。 2013-05-Inquiry to Prof. Wu 我对网络技术很感兴趣，今后想要成为一名网络工程师。但在就业之前，我渴望自己能够是\"CCIE+网络工程硕士\"。但是我在网络工程领域的硬件储备基本为零，而作为敲门砖的CCIE证书，虽然我在很努力地准备，但也要等到暑假才能考到。我想申请贵院\"本校其他专业免试研究生\"的资格…… 虽然你以前的专业和你想转换的不同，但你对网络研究方向感兴趣的话肯定能有所建树的，我倒很愿意推荐你来我实验室研究、学习。你的英语考级情况如何？保送研究生的资格是否可以争取到？你们学院的老师我倒有些熟悉的，可以寻求一些帮助的。你若情况明朗的话可以来我实验室学习了，了解一下基础研究情况，并推荐你看一些基础性的教程，并与师兄们讨论、求教，相信你会很快有所提高的。我实验室在研的下一代网络前沿技术今后将会非常之普及的，这方面人才的储备的含金量会愈来愈高的。建议可以进一步进行硕博连读的计划。近期有诸多大公司来我们这里合作，其中需要我们这个方向的博士研究生，我这里在学院申请到了3位硕博连读的招生指标，其中1个我想到时给你，这样你后面的研究工作和今后的就业就比较吻合一致的，目标也更加清晰了；另外需要到国外进修的话我这里也是比较便捷的，美国加州大学、西北大学、阿拉巴马大学都有老师在这里合作研究。硕博连读的保研可以申请的吧，目前说要招收导师的确认方可。 2013-05-Kind Remind from Prof. Pan 你花了四年学专业, 却要从零开始学网络, 这种执业证书计算机专业学生不看重, 培训机构兼钱看重，只是浪费了你爸的血汗钱！真正要学网络要学一个计算机学科的知识，改行而出成绩要比別人化多倍的精力和辛勤汗水！行行出状元, 为何要换专业？新材料研究是一很需要方向！ 因此，要三思而行，除非所学专业的确很难找到工作？！ 2013-09/2014-06 大四 2013-09-Inquiry to Dr. Ning 暑假期间我还在备考，所以没来得及联系您，前不久刚刚考完，下一步打算着手准备出国。出国的这个决定下得比较仓促，所以对出国资金，选校定位，文书套磁，奖学金等都认识不深，有关的一些准备工作以及学业规划也并不成熟。因此希望能听取你的指点和引导，从而少走弯路。我以后打算从事IT（网络）方面的工作，所以希望最好能够直接申请到美国CS方面的硕士OFFER，但是由于是跨专业，而且托福和GRE才刚刚开始准备，所以时间非常紧张，并且应该可能会要拖个半年一年，来准备英语成绩，选修计算机专业课，还有积累相关的项目或者实习经历。如果英语成绩能够顺利考出来的话，今年12月底到明年1月份初试申几所院校，如果计划不顺利或者录取结果不理想的话再等明年春季那一批招生，并继续冲刺英语考试，同时可以去积累一下实习经历或者可能的话跟着计院老师获取科研经历。关于费用的问题，我们家里的经济条件并不宽裕，所以我和爸妈非常关心这一点，当然选校的时候也必须要考虑这一点。但是目前为止我对留学美国的花费还没有一个非常清楚的认识和概念，您可以向我具体的介绍一下吗？鉴于经费的问题和选择的空间，听同学说加拿大的花费稍微低一些，我是否有必要也同时申请加拿大的院校呢？另外同时以自己本科的专业去申请几所院校的环境类专业，然后再视情况考虑转到CS是否是一种可能的合理的选择？ 建议： As you understood, your background is inconsistent with what you try to pursue and your family is not able to provide full financial support for your graduate study oversea. In general, the cost for each credit of a graduate course is about $1000 - $2000 for international students and at least 12 credits are required for a full-time graduate student. Lodging and boarding costs additional $10k per year. That's reality. So you may think about it around the way or alternate approach(es). \"以自己本科的专业去申请几所院校的环境类专业，然后再视情况考虑转到CS\" might be the alternate approach, through which you could get a school financial support. I like your attitude for planning your long-run goals. For now, however, you should concentrate on getting as high as possible scores on TOEFL and GRE, which will help you get admitted into a college graduate program and financial support from the college. Once you get high enough scores with them, you can think of what colleges and programs you should apply for. 关于套磁, you should have done certain research on particular professional fields through these you should frequently refer the articles published in professional journals. Then you can naturally get in touch with those authors of the articles to inquire their recent progress, etc. 2013-10-Inquiry to Mr. Li 很抱歉近期没能关注到Autodesk公司在我们学校的校招情况，对贵公司的职位需求不太了解，所以希望先把简历发给您并同您建立联系，望前辈多多批评指正。 建议： ……不过你开发编程方面经历较少。如果我这个理解没错，而且你又希望在IT业方面尝试一下发展的话，看来你比较适合在公司的IT部门工作，进行网络方面管理，不知道你是否同意。我们公司最近招人并不多，每两周会发布一次职位需求列表，最近的一次没有看到IT部门的职位，我会留意邮件，如果有合适的职位一定会帮你推荐。不过现在十月份，距离毕业还早，你大可以多尝试一些其他更加对口的公司，比如思科华为这些。或者准备考研（如果你想的话）。有问题就给我写信，祝好运！ 2013-11-Inquiry to Mr. Zhuliu & Mr. Yue 10月底已经拿到华为的offer了，但是还是非常想出国念IT，所以虽然转专业难度比较大，但还是想考英语再全力去试着申一申，如果实在时间来不及或者结果不合适的话就只能到华为工作几年再出国了。浙大这边有个和KTH的4+2的项目我已经报名了，12月17日对方会来我们学校面试，希望顺利吧!以上是我目前的状态和打算。CV就拜托你了，另外就你对美国大学的了解，能否对我的转专业申请提一些建议，比如说美国学校非常注重什么；我还可以怎样去弥补转专业这种情况带来的劣势；还有申硕士的话套磁对申请结果会有很大的影响吗，（比如要是我的毕设课题是软件定义网络SDN这一块，而某个教授也是研究这一块）。 Zhuliu： 在你面前有很多很好的选择，我相信无论你走哪一条路，都会一如既往的精彩。我自己不是跨专业申请的，只是借原来的专业入了学校的门，然后又背弃师门，转行做码农。所以对于你申请CS专业，我的帮助比较有限。我跟一个CS的同学讨论了你的情况，大家总结了一些想法。 第一，跨专业申请，尤其是跨度较大的申请确实难度很大，因为导师会顾虑学生的专业基本功。但同时，学校和院系也是很欣赏多样性的。我们这里有EE教授研做心理学课题的，语言学教授做自然语言计算处理的。包括我的那位同学，他本科是机械系做机器人和电路的。所以跨专业申请，硬攻CS的话，是要打diversity的牌。我觉得这点你已经做得比较好了，做了CS与你本专业结合的课题。我也相信CS技术可以在你所熟知的专业领域里有很多美妙的应用。（我自己对于GIS也很感兴趣，现在python的兴起正在改变Earth Science整个学科的面貌，很多地理信息的教授都感觉自己落伍了，在学校里找CS相关的学生做研究助理）。跨专业或许是一个短板，但如果你把它与CS结合得好，突出自己跨学科解决问题的能力和学习能力，并且强调自己应用CS的学术深度，就可以扬长避短。兴许有教授恰好有合你胃口的跨专业项目，这样就最好了。 第二，也得考虑\"曲线进入\"的方式。CS核心专业的录取量不大，而且竞争激烈。但以别的专业进入CS强校，不失为一种办法。美国大学有很大的自由度。尤其是对于硕士学生，只要修了符合要求的课程，就能转入CS相关的专业（有时候EE反而比较灵活合包容，现在EE的也都在coding）。 我身边有同学刚进来就修读CS的课程，第二年顺利从civil转到EE。也有同学直接从civil转到了CS。申请的时候违心地\"欺骗\"一下老师的感情也是无妨的。只要不是骗phd funding，套个硕士录取，然后进来就跳，我觉得也是无可非议的。从这个角度考虑，申请你的本专业（与CS结合的更好），或者CS边缘的专业（比如CMU有不少非CS核心的专业可以考虑），或者EE的某些方向（比如网络）可能会增加你进入学校的把握。 综合这两条，你的申请思路可以是两者结合的。很多学校都是以院系为单位招生录取的。所以你可以准备两种倾向性的材料分别投给CS和其他学院。只要有一种方式成功，便是胜利。 对于申请CS专业的CV和PS，你要把自己的主体内容写得跟科班出身的人差不多。你可以简要梳理一下你的专业基础，比如，会哪几门语言，分别什么程度（proficient, experienced)。算法设计的课程或项目。Object Oriented Programming方面的经验。还有就是CS某个子领域的研究。比如你擅长network那块，你可以把相关的课程经历和具体的project都梳理到一起。你能受到华为的青睐，肯定有拿得出手的相关项目，这个子领域的学识至关重要，要突出强调这个，让教授觉得你有干货，并且有志于研究下去（以申请phd的态度申请硕士）。教授在确定了你基础过关的情况下，就是看志趣相投了。然后，还是那一点，科班一样的简历之外，也不可能回避本专业的内容。这个和找工作不一样，我可以只字不提civil专业，说自己是Engineering的。学术录取对于你既往的专业还是会调查的详细清楚的。这就需要像前面所说的那样扬长避短，你要强调你的专业学习中融入的CS是多么的有深度。以你本专业做外壳，大讲你的CS内涵。 而对于申请与你专业比较相近的方向，则还是以本专业为坚实基础，CS作为你的拿手好戏。你取得了本专业的学位，有优秀的成绩，而且做了很多跨学科的课题都非常时髦。是的，现在美国整个学术圈都在追求量化和模拟，你的coding技能可能是你本专业很多老板所垂涎的。我想这种类型的简历，你写起来应该得心应手。再有一点就是投其所好。如果你是把CS作为锦上添花的，那么可以略写专业术语和具体内容，强调实用和宽度（怎么在你的专业里用的好）。比如你的Sql DB的经历对于GIS等信息类但非CS专业，是很加分的。但是对于CS专业，就要浓缩到你的干货上去（你的network方向），因为看简历的对方是行家，他所关心的是子专业的匹配。你最强势的，甚至有可能作为phd课题的CS项目就要详细的写，突出亮点。次要的可以省略和带过。 对于你现有的简历，我觉得这里已经有足够丰富的素材了，充分证明了你的勤奋和才能。接下来的就是为两种战术挑选素材, 量身定做了。至于找CS专业简历的模板，你可以google到很多专业人士的（码农的CV很多），你可以模仿他们的笔调去写自己内容，如果顺带用一下latex写的话，给人专业的感觉（这个不是很重要）。还有一点，除非是对方认识的知名教授，一般都不必列举你的指导老师的名字。这样占篇幅，而且更给对方疏离感，这里你是明星！还有详略的控制。要做的精简的基础上，让对方大概了解到你做了什么工作，用了什么技术。比如你的MySQL项目，你指出的GUI，一看就很明显了，确实不必多解释，但如果你说你用java swing或者php，ruby做web interface那就更令人信服。但main funciton modules就是很含糊的概念，你是负责DB和你们的program交互的module，还是数据与DB交互前的其他处理（如果是，那么可能用到什么核心算法或数据结构，你也可以做文章）。同理，你在implement intellecutal queuing system时候的主要解决的难题是什么，核心算法借鉴了什么。这些都是可以套用术语简要的交代清楚的。另外，你用动词开头的描述很好，确实是这样的规范。可以改进的地方在于把动词替换成高级的同义词，比如把helped换成assisted。 Yue： 华为offer比较不错，实在不行先在国内工作下也还好，国外很多人都是有几年工作经验再读硕士的。我稍微看了下，标注了一些地方可以改下，但还建议你可以自己再仔细修改，并且和更多人一起相互修改，然后找更专业的人士帮忙修改。另外注意写经历时尽量能量化成果，以便更好地differentiate yourself。还可以在网上搜下顶尖美国大学的CV模板，对照着自己的改下。你要转到CS/IT相关方向是吧，建议你在简历里再加上你熟练运用的编程语言、计算机软件吧。我感觉申美国硕士现在不是特别难，美国高校最近招硕士比较多（水）一些，虽然未来扩招的趋势不太可能持续。要转专业的话，相关专业的课程、科研项目、竞赛成果、实习工作经验、CS好教授的推荐信可能会比较有帮助（最好这些都是在国际上认可的），这些估计美国学校都会看重。陶瓷我估计对申硕士帮助不大，如果你想过去跟老师做点课题、争取RA的话，还是可以套的。 2014-04-From Mr. Chisyliu 我个人觉得 学习internet technology本身不错 不过不要只注重网络个体 而要同时学习相关的实现方式 例如 网络应用 java或者数据库 网页开发之类的编程 这样毕业时候自然较好找工作 法国不是非常了解 但学位本身并没有你想象那么重要 主要是你需要找到合适的公司实习或者论文 并且把编程学好 无论你学习什么专业 基本上大学都是教授技术本身 而一般较少教授实现的手段 你所需要的就是找公司实习去强化实现手段 就是所谓的写程序 工程师学位重点并不是学位 而是强制的intern跟法语","tags":"Notes","url":"https://jiang-hao.com/articles/2016/notes-心路.html","loc":"https://jiang-hao.com/articles/2016/notes-心路.html"}]};